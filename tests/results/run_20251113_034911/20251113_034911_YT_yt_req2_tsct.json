{
  "success": true,
  "video_id": "jLuwLJBQkIs",
  "url": "https://www.youtube.com/watch?v=jLuwLJBQkIs",
  "content": "I learned about context engineering for you. So, let me now save you the hours you have to spend scrolling through X and Reddit trying to understand what is context engineering. The outline of today's video is that I'm going to first explain what is context engineering, why it came about, and what it's relevant for. Then, we'll talk about how to do context engineering, and finally some examples to make it all concrete. As per usual, it's not enough for me just to talk about stuff. So, there will be little assessments throughout this video. So, please pay attention. And if you can answer these questions, then congratulations. you have now been educated on context engineering. So without further ado, let's go. A portion of this video is sponsored by Augment Code. All right, let's first define context engineering. Context engineering is designing and building dynamic systems that give an LM the right info in the right format at the right time to accomplish a task. In other words, you're packing the context window, which is the input area of a large language model just right. All right, now that we've defined the term, the first point I want to make is that context engineering is only relevant to people who are making LLM apps, including things like AI agents. You may have already heard or read online that context engineering is the new prompt engineering. That is true, but it doesn't mean that like prompt engineering is dead. For example, if you just want to chat with a chatbot, like chat GBT about the kind of running shoes that you should choose for your feet. You know, you're having a back and forth conversation talking about the different cushioning types, uh, certain price ranges, how different outfits match up for your running outfits. All of that is prompting. That's still prompt engineering, and it's still completely relevant in those scenarios. Context engineering only becomes relevant when you're building AI applications like AI agents. Because unlike that chatbi conversation where you're just going back and forth, when you're building something like an AI agent, you can't iteratively keep talking to the agent until it gets the answer correct. You need to give it a set of instructions that encompasses all the actions it has to take and all the different scenarios that it's going to encounter. For example, if you're building a customer service AI agent for your online store, that agent needs to be equipped with the ability to handle all sorts of inquiries like billing problems, refund issues, login issues, searching up terms and conditions because people can't read, people asking it stupid irrelevant questions, probably also people yelling at it and abusing it unfortunately, and be able to escalate to a human when necessary. And to be able to give it all the instructions and resources and everything that it needs in order to accomplish these tasks, your prompts become larger and larger and more and more complex. At some point they even start to resemble code with XML tags and markdown. As you can see this is really really different than just prompting and having a conversation with chatbt which is why people came up with the term context engineering. So yeah that's pretty much it. Context engineering isn't some new technique that's completely coming out of the blue. It really is the progression of prompt engineering in the very specific cases of crafting complex prompts for building AI applications. As Andre Kaparthy explains the LM is the CPU and the context window is the RAM. Make sense? I'm going to put on screen now a little assessment. Please write in the comments your answer. All right, let's now dive deeper into what context engineering actually looks like when we're building an AI agent. First, to make sure we're all on the same page, the definition of an AI agent is a software system that uses AI to pursue goals and complete tasks on behalf of users. For example, a customer service AI agent that answers customer service queries. A sales assistant AI agent that's able to qualify leads and follow up with people. A coding agent that can help you to code. There are lots and lots of different types of AI agents. However, regardless of what types of AI agents there are, there are six components which are essential building blocks that make up an AI agent. The first component is model. Every AI agent needs to have an AI model. It can be open GPT models, it can be claude, it can be Gemini, it can be smaller models, it can be larger models, it can be open source models, whatever fits. The second component is tools. Tools allow agents to be able to interact with external systems. For example, a personal assistant agent needs to be able to have a tool that allows it to access your Google calendar to be able to book appointments for you. Next up is knowledge and memory. Most agents need a way to store and retrieve information. For example, if you have a therapy AI agent and you're having conversations with it, you need it to have memory so that it's able to remember what has been said in previous conversations. If you have a legal AI agent that's meant to screen through some very specific cases, you need to give it the knowledge base of those specific cases that you want it to work on. Then there's audio and speech. Equipping your AI agent with the ability for audio and speech will allow it to be a lot more natural and easier to interact with. Every AI agent also needs to have guardrails which are safety mechanisms to ensure proper behavior. You don't want your customer service AI agent to swear back at your users probably. And finally, there is orchestration. These are systems that allow you to deploy your AI agent, monitor them, and improve them over time. You don't want to just release your AI agent into the wild and just run away. Got to keep track of what it's doing. The analogy that I like to make is that these six components of AI agents is sort of like a burger. Like in order for a burger to be considered a burger, it needs to have a bun, a patty, vegetables, and condiments. You can have different types of buns like whole wheat, whites, even lettuce buns and different types of patties, like different types of meats. But you do need to have these different components to be able to be called a burger. Same with AI agents. You can have different types within these components, but you do need to have these components to be considered an AI agent. Now, continuing this analogy, imagine that you are an alien and you don't understand how these burger thingies work. So, whoever is telling you to make a burger probably needs to also provide an instructions manual telling you that the bun goes on either side. Then you're supposed to put in the vegetables, the condiments, and the patty in the middle. And that's how you would know how to assemble your burger. It's the same thing for AI agents. You can have all of these different components of these AI agents, but you need to have an instruction manual for how all these things fit together. And that is where the context engineer comes in. You're coming up with that prompt that exactly details how everything is working together, what the tools are, how to use them, how to access memory, what's in the knowledge base, when to use speech and audio functionalities, etc., etc. The resulting prompt is going to be the instructions manual for your AI agent to be able to use all the things that it's equipped with. It is really important to get this prompt right, and people spend a lot of time context engineering until they get that perfect prompt. Time for the next little assessment. Please answer the questions on screen and put your answers in the comments. As we've already talked about, context engineering goes handinhand with building AI applications. And when it comes to building AI applications that are meant to be more than just proof of concepts or demos, pure vibe coding just isn't enough. That is where Augment code comes in. It's built for real engineering work, including debugging, writing tests, refactoring, and navigating complex systems. Augment's context engine feeds Claude Sonnet for exactly what it needs for your codebase. There's no need for guessing, model picking, or forks. Just a deeply integrated assistant that helps you ship. You can even launch cloud agents to refactor or fix tests even when your laptop is closed. It runs in your IDE including VS Code, Jet Brains, Vim, and Cursor. They also take security very, very seriously. Augment is ISO and SOCK 2 certified, and there's no training on customer code. You can try it off for free for 14 days at this link over here, also linked in description. Thank you so much Augment Code for sponsoring this portion of the video. Now, back to the video. Okay, I'm going to show you now a full example of a context engineered prompt for an AI agent. Specifically, this is a prompt for an AI research assistant that I made for myself in order to keep up with all the AI trends. The general structure of the system prompt is that I have these six different components. It helps um structure the prompt in a way that is easier to follow. So, under role, you're an AI research assistant focused on identifying and summarizing recent trends in AI from multiple source types. Your job is to break down a user's query into actionable subtasks and return the most relevant insights based on engagement and authority. Under task, so the thing that we actually want the AI agent to do, we have given a research query delimited by the XML tags user query and end tag user query. So this is um XML tags. It's also a way to structure the information so it's more clear for the AI to be able to process. Do the following. Step one is to extract up to 10 diverse high priority subtasks each targeting a different angle or source type. Step two is to prioritize by engagement such as views, likes, repost, and citations as well as authority of source such as publication, reputation, and domain expertise. Step three is to generate a JSON output for each subtask in the format below. And step four is to calculate the correct start date and end date in UTC ISO format based on the specified time period. And step five is to summarize all findings into a single concise trend summary approximately 300 words max. As you can see, it is very very structured and detailed going step by step saying that you need to extract up to 10 different subtasks like 10 different types of sources regarding a specific topic from the user. You need to prioritize it. Uh generate certain specified JSON outputs like a type of output and make sure that the time periods are in the correct time period that the user specifies and then go on to actually summarize all the findings. The input is within the XML tags which is user query. Uh it says insert search query here. This is where the user would input whatever it is that they want to search. So for the output of this agent, you have you will output up to 10 subtasks in this exact format and this is a JSON format that we very clearly stated. So every single subtask which is a source it needs to be exactly in this format has the ID the query specifies subquery related to one aspect of the main topic. The source type it can be news, it can be from X, it can be from Reddit, LinkedIn, newsletter, academic or specialized. The time period when that resource came out it can be between 1 day to 10 days. Domain focus is a technology science or health priority determining how important this source is from highest of one to lowest of 10 and the start date and the end date in this specific format. Under output, it says that you will output up to 10 subtasks in this exact format. So we can see here that this is JSON format and we're specifying all of the different variables that need to be there. Then after performing all subtasks, write a final output summarizing the key recent trends, including limiting to 300 words using bullet points or short paragraphs. Only include new relevant high signal developments and avoiding fluff background or personal commentary. Then there's constraints. Focus on capturing the main point succinctly. Complete sentences and perfect grammar are unnecessary. Ignore fluff background information and commentary. Do not include your own analysis or opinions. Then finally, we have capabilities and reminders. We're telling it what are the different tools and knowledge bases that it has access to and giving it very specific reminders so it doesn't go off track. You have access to the web search tool to find and retrieve recent news articles relevant to the search term. You must be deeply aware of the current date to ensure the relevance of news summarizing only information published within the past 10 days. So this is example of a system prompt for a single research assistant AI agent. So and this is actually considered a very very simple prompt. I also contain everything within that singular AI agent. When actually like normally when I do something like this, I would generally split it into multi- aent systems where you would have one agent that searches up all the different sources and you have another agent that would actually go and summarize everything for you. But even just for illustration purposes, I hope you can see that how complex this context engineering can get. And it's going to go and gather information, gather news from different newsletters as well as Reddit. Then it would aggregate all of that information together and ultimately come up with a summary that it's going to send to me on WhatsApp. And in this case, I implemented this AI agent using NAT. You can of course implement this using a variety of other tools as well. Like in our AI agents boot camp, we teach people to implement no code agents using NAT. And for people who want to use code, uh we would generally teach them how to use like something like OpenAI's agents SDK. But it doesn't actually matter whatever it is that you use to implement these prompts. Um they are applicable across different agentic systems. So before I end this video, I do want to share with you guys two additional resources which I think are excellent if you really want to dive deeper into context engineering and how it is that you can go about uh creating these multi-agent systems and getting the results from it. The first one is a blog post from cognition and they share two fundamental principles for context engineering specific for multi- aent frameworks. The first one is to always share context between your agents. And the second is that actions carry implicit decisions. And whenever you have a decision point, you need to be very very careful of this in your architecture and in your context engineering as well. Highly recommend that you check out this blog post. The second article is from Langchain where they showcase this really great framework that breaks down common strategies that people use when context engineering. The first one is writing context. How it is that you can allow your large language model to write down information surrounding a task so it's able to save it and use it for later. The second is selecting context. How it is that you can pull information from external sources to help your agent perform a task. The third is compressing context. When there is a lot of information that you're trying to give in large language model, there are techniques that you can do in order to help compress that information in a more compact way. And the fourth is isolating context. How to split context in between different environments and different places. I'm not going to go into more details about this to keep this video relatively succinct, but you do want to dig deeper into techniques for context engineering so you can build better AI apps like AI agents. Highly recommend that you check out these resources. All right, that is everything that I have for you today. So, here is the final little assessment. Please write your answers in the comments below. Thank you so much for watching until the end of this video and I will see you guys in the next video or live stream. I learned about context engineering for you. So, let me now save you the hours you have to spend scrolling through X and Reddit trying to understand what is context engineering. The outline of today's video is that I'm going to first explain what is context engineering, why it came about, and what it's relevant for. Then, we'll talk about how to do context engineering, and finally some examples to make it all concrete. As per usual, it's not enough for me just to talk about stuff. So, there will be little assessments throughout this video. So, please pay attention. And if you can answer these questions, then congratulations. you have now been educated on context engineering. So without further ado, let's go. A portion of this video is sponsored by Augment Code. All right, let's first define context engineering. Context engineering is designing and building dynamic systems that give an LM the right info in the right format at the right time to accomplish a task. In other words, you're packing the context window, which is the input area of a large language model just right. All right, now that we've defined the term, the first point I want to make is that context engineering is only relevant to people who are making LLM apps, including things like AI agents. You may have already heard or read online that context engineering is the new prompt engineering. That is true, but it doesn't mean that like prompt engineering is dead. For example, if you just want to chat with a chatbot, like chat GBT about the kind of running shoes that you should choose for your feet. You know, you're having a back and forth conversation talking about the different cushioning types, uh, certain price ranges, how different outfits match up for your running outfits. All of that is prompting. That's still prompt engineering, and it's still completely relevant in those scenarios. Context engineering only becomes relevant when you're building AI applications like AI agents. Because unlike that chatbi conversation where you're just going back and forth, when you're building something like an AI agent, you can't iteratively keep talking to the agent until it gets the answer correct. You need to give it a set of instructions that encompasses all the actions it has to take and all the different scenarios that it's going to encounter. For example, if you're building a customer service AI agent for your online store, that agent needs to be equipped with the ability to handle all sorts of inquiries like billing problems, refund issues, login issues, searching up terms and conditions because people can't read, people asking it stupid irrelevant questions, probably also people yelling at it and abusing it unfortunately, and be able to escalate to a human when necessary. And to be able to give it all the instructions and resources and everything that it needs in order to accomplish these tasks, your prompts become larger and larger and more and more complex. At some point they even start to resemble code with XML tags and markdown. As you can see this is really really different than just prompting and having a conversation with chatbt which is why people came up with the term context engineering. So yeah that's pretty much it. Context engineering isn't some new technique that's completely coming out of the blue. It really is the progression of prompt engineering in the very specific cases of crafting complex prompts for building AI applications. As Andre Kaparthy explains the LM is the CPU and the context window is the RAM. Make sense? I'm going to put on screen now a little assessment. Please write in the comments your answer. All right, let's now dive deeper into what context engineering actually looks like when we're building an AI agent. First, to make sure we're all on the same page, the definition of an AI agent is a software system that uses AI to pursue goals and complete tasks on behalf of users. For example, a customer service AI agent that answers customer service queries. A sales assistant AI agent that's able to qualify leads and follow up with people. A coding agent that can help you to code. There are lots and lots of different types of AI agents. However, regardless of what types of AI agents there are, there are six components which are essential building blocks that make up an AI agent. The first component is model. Every AI agent needs to have an AI model. It can be open GPT models, it can be claude, it can be Gemini, it can be smaller models, it can be larger models, it can be open source models, whatever fits. The second component is tools. Tools allow agents to be able to interact with external systems. For example, a personal assistant agent needs to be able to have a tool that allows it to access your Google calendar to be able to book appointments for you. Next up is knowledge and memory. Most agents need a way to store and retrieve information. For example, if you have a therapy AI agent and you're having conversations with it, you need it to have memory so that it's able to remember what has been said in previous conversations. If you have a legal AI agent that's meant to screen through some very specific cases, you need to give it the knowledge base of those specific cases that you want it to work on. Then there's audio and speech. Equipping your AI agent with the ability for audio and speech will allow it to be a lot more natural and easier to interact with. Every AI agent also needs to have guardrails which are safety mechanisms to ensure proper behavior. You don't want your customer service AI agent to swear back at your users probably. And finally, there is orchestration. These are systems that allow you to deploy your AI agent, monitor them, and improve them over time. You don't want to just release your AI agent into the wild and just run away. Got to keep track of what it's doing. The analogy that I like to make is that these six components of AI agents is sort of like a burger. Like in order for a burger to be considered a burger, it needs to have a bun, a patty, vegetables, and condiments. You can have different types of buns like whole wheat, whites, even lettuce buns and different types of patties, like different types of meats. But you do need to have these different components to be able to be called a burger. Same with AI agents. You can have different types within these components, but you do need to have these components to be considered an AI agent. Now, continuing this analogy, imagine that you are an alien and you don't understand how these burger thingies work. So, whoever is telling you to make a burger probably needs to also provide an instructions manual telling you that the bun goes on either side. Then you're supposed to put in the vegetables, the condiments, and the patty in the middle. And that's how you would know how to assemble your burger. It's the same thing for AI agents. You can have all of these different components of these AI agents, but you need to have an instruction manual for how all these things fit together. And that is where the context engineer comes in. You're coming up with that prompt that exactly details how everything is working together, what the tools are, how to use them, how to access memory, what's in the knowledge base, when to use speech and audio functionalities, etc., etc. The resulting prompt is going to be the instructions manual for your AI agent to be able to use all the things that it's equipped with. It is really important to get this prompt right, and people spend a lot of time context engineering until they get that perfect prompt. Time for the next little assessment. Please answer the questions on screen and put your answers in the comments. As we've already talked about, context engineering goes handinhand with building AI applications. And when it comes to building AI applications that are meant to be more than just proof of concepts or demos, pure vibe coding just isn't enough. That is where Augment code comes in. It's built for real engineering work, including debugging, writing tests, refactoring, and navigating complex systems. Augment's context engine feeds Claude Sonnet for exactly what it needs for your codebase. There's no need for guessing, model picking, or forks. Just a deeply integrated assistant that helps you ship. You can even launch cloud agents to refactor or fix tests even when your laptop is closed. It runs in your IDE including VS Code, Jet Brains, Vim, and Cursor. They also take security very, very seriously. Augment is ISO and SOCK 2 certified, and there's no training on customer code. You can try it off for free for 14 days at this link over here, also linked in description. Thank you so much Augment Code for sponsoring this portion of the video. Now, back to the video. Okay, I'm going to show you now a full example of a context engineered prompt for an AI agent. Specifically, this is a prompt for an AI research assistant that I made for myself in order to keep up with all the AI trends. The general structure of the system prompt is that I have these six different components. It helps um structure the prompt in a way that is easier to follow. So, under role, you're an AI research assistant focused on identifying and summarizing recent trends in AI from multiple source types. Your job is to break down a user's query into actionable subtasks and return the most relevant insights based on engagement and authority. Under task, so the thing that we actually want the AI agent to do, we have given a research query delimited by the XML tags user query and end tag user query. So this is um XML tags. It's also a way to structure the information so it's more clear for the AI to be able to process. Do the following. Step one is to extract up to 10 diverse high priority subtasks each targeting a different angle or source type. Step two is to prioritize by engagement such as views, likes, repost, and citations as well as authority of source such as publication, reputation, and domain expertise. Step three is to generate a JSON output for each subtask in the format below. And step four is to calculate the correct start date and end date in UTC ISO format based on the specified time period. And step five is to summarize all findings into a single concise trend summary approximately 300 words max. As you can see, it is very very structured and detailed going step by step saying that you need to extract up to 10 different subtasks like 10 different types of sources regarding a specific topic from the user. You need to prioritize it. Uh generate certain specified JSON outputs like a type of output and make sure that the time periods are in the correct time period that the user specifies and then go on to actually summarize all the findings. The input is within the XML tags which is user query. Uh it says insert search query here. This is where the user would input whatever it is that they want to search. So for the output of this agent, you have you will output up to 10 subtasks in this exact format and this is a JSON format that we very clearly stated. So every single subtask which is a source it needs to be exactly in this format has the ID the query specifies subquery related to one aspect of the main topic. The source type it can be news, it can be from X, it can be from Reddit, LinkedIn, newsletter, academic or specialized. The time period when that resource came out it can be between 1 day to 10 days. Domain focus is a technology science or health priority determining how important this source is from highest of one to lowest of 10 and the start date and the end date in this specific format. Under output, it says that you will output up to 10 subtasks in this exact format. So we can see here that this is JSON format and we're specifying all of the different variables that need to be there. Then after performing all subtasks, write a final output summarizing the key recent trends, including limiting to 300 words using bullet points or short paragraphs. Only include new relevant high signal developments and avoiding fluff background or personal commentary. Then there's constraints. Focus on capturing the main point succinctly. Complete sentences and perfect grammar are unnecessary. Ignore fluff background information and commentary. Do not include your own analysis or opinions. Then finally, we have capabilities and reminders. We're telling it what are the different tools and knowledge bases that it has access to and giving it very specific reminders so it doesn't go off track. You have access to the web search tool to find and retrieve recent news articles relevant to the search term. You must be deeply aware of the current date to ensure the relevance of news summarizing only information published within the past 10 days. So this is example of a system prompt for a single research assistant AI agent. So and this is actually considered a very very simple prompt. I also contain everything within that singular AI agent. When actually like normally when I do something like this, I would generally split it into multi- aent systems where you would have one agent that searches up all the different sources and you have another agent that would actually go and summarize everything for you. But even just for illustration purposes, I hope you can see that how complex this context engineering can get. And it's going to go and gather information, gather news from different newsletters as well as Reddit. Then it would aggregate all of that information together and ultimately come up with a summary that it's going to send to me on WhatsApp. And in this case, I implemented this AI agent using NAT. You can of course implement this using a variety of other tools as well. Like in our AI agents boot camp, we teach people to implement no code agents using NAT. And for people who want to use code, uh we would generally teach them how to use like something like OpenAI's agents SDK. But it doesn't actually matter whatever it is that you use to implement these prompts. Um they are applicable across different agentic systems. So before I end this video, I do want to share with you guys two additional resources which I think are excellent if you really want to dive deeper into context engineering and how it is that you can go about uh creating these multi-agent systems and getting the results from it. The first one is a blog post from cognition and they share two fundamental principles for context engineering specific for multi- aent frameworks. The first one is to always share context between your agents. And the second is that actions carry implicit decisions. And whenever you have a decision point, you need to be very very careful of this in your architecture and in your context engineering as well. Highly recommend that you check out this blog post. The second article is from Langchain where they showcase this really great framework that breaks down common strategies that people use when context engineering. The first one is writing context. How it is that you can allow your large language model to write down information surrounding a task so it's able to save it and use it for later. The second is selecting context. How it is that you can pull information from external sources to help your agent perform a task. The third is compressing context. When there is a lot of information that you're trying to give in large language model, there are techniques that you can do in order to help compress that information in a more compact way. And the fourth is isolating context. How to split context in between different environments and different places. I'm not going to go into more details about this to keep this video relatively succinct, but you do want to dig deeper into techniques for context engineering so you can build better AI apps like AI agents. Highly recommend that you check out these resources. All right, that is everything that I have for you today. So, here is the final little assessment. Please write your answers in the comments below. Thank you so much for watching until the end of this video and I will see you guys in the next video or live stream.",
  "title": "Context Engineering Clearly Explained",
  "author": "Tina Huang",
  "publish_date": "",
  "source": "YouTube",
  "language": "auto",
  "word_count": 5722,
  "extraction_method": "youtube",
  "extraction_timestamp": "2025-11-13T11:50:18.520012",
  "batch_id": "20251113_034911",
  "link_id": "yt_req2",
  "error": null,
  "summary": {
    "transcript_summary": {
      "key_facts": [
        "Context engineering is designing dynamic systems that deliver the right information to an LLM at the right time.",
        "Context engineering applies specifically to building LLM applications like AI agents, not casual chat interactions.",
        "Prompt engineering remains relevant for simple conversational tasks such as discussing running shoes.",
        "AI agents require comprehensive instructions covering all possible scenarios and actions upfront.",
        "A customer service AI agent must handle billing issues, refund requests, login problems, and abusive user behavior.",
        "Context engineering evolved from prompt engineering to manage complex, multi-step AI application workflows.",
        "The six essential components of an AI agent are model, tools, knowledge and memory, audio and speech, guardrails, and orchestration.",
        "The analogy compares AI agents to burgers, requiring all core components (bun, patty, vegetables, condiments) to function.",
        "The context engineer creates the instruction manual that defines how all agent components work together.",
        "A system prompt for an AI research assistant includes role, task, output format, constraints, and capabilities sections.",
        "The AI research assistant prompt uses XML tags to delimit user queries and structure input processing.",
        "The AI research assistant must extract up to 10 diverse subtasks based on source type and prioritize by engagement and authority.",
        "Each subtask must include a source type, time period (1–10 days), domain focus, and start/end dates in UTC ISO format.",
        "Final output must be a concise trend summary under 300 words using bullet points or short paragraphs.",
        "The AI agent has access to a web search tool and must only summarize content published within the past 10 days."
      ],
      "key_opinions": [
        "Context engineering is the progression of prompt engineering for complex AI application development.",
        "Pure vibe coding is insufficient for building real-world AI applications beyond proof-of-concept demos.",
        "Augment Code’s context engine provides better integration and security than generic alternatives.",
        "The Langchain framework offers practical strategies for effective context engineering across different use cases.",
        "Sharing context between agents and handling implicit decisions in actions are critical principles in multi-agent systems.",
        "Using structured prompts with clear JSON outputs improves reliability and consistency in AI agent performance.",
        "Complex prompts resembling code with XML and markdown are necessary for robust AI agent functionality.",
        "Implementing AI agents via no-code platforms like NAT is accessible for non-developers.",
        "OpenAI’s agents SDK enables advanced implementation for developers who prefer coding over no-code tools.",
        "The author believes this video saves viewers hours of research by consolidating key insights into one explanation."
      ],
      "key_datapoints": [
        "AI research assistant output must be limited to approximately 300 words.",
        "Subtasks must be prioritized based on engagement metrics: views, likes, reposts, citations.",
        "Source priority ranges from 1 (highest) to 10 (lowest) based on domain focus: technology, science, health.",
        "Time period for sources must be between 1 day and 10 days.",
        "UTC ISO format is required for start and end dates in the output.",
        "Augment Code offers a free 14-day trial for its platform.",
        "Augment Code is ISO and SOC 2 certified for security compliance.",
        "The AI research assistant prompt uses XML tags to delimit user query input.",
        "The prompt specifies generating up to 10 subtasks in a defined JSON structure.",
        "The AI agent can be implemented using NAT (no-code) or OpenAI’s agents SDK (code-based)."
      ],
      "topic_areas": [
        "Context Engineering",
        "AI Agent Components",
        "Prompt Structuring",
        "Multi-Agent Systems",
        "Real-World AI Applications",
        "System Prompt Design",
        "Tool Integration",
        "Security in AI",
        "No-Code Development",
        "Langchain Strategies"
      ],
      "word_count": 5722,
      "total_markers": 35
    },
    "comments_summary": {},
    "created_at": "2025-11-13T12:10:02.648658",
    "model_used": "qwen-flash"
  }
}
{
  "success": true,
  "video_id": "_N_dvr9wjJk",
  "url": "https://www.youtube.com/watch?v=_N_dvr9wjJk",
  "content": "So, AI, it feels as if people have been talking about it non-stop for at least the last two years. I still have a cold, by the way. AI went from something that was relatively a lot less mainstream, to something that is almost talked about daily. It used to serve as videos like Will Smith eating spaghetti with PS2 graphics, that's being generous, and it was essentially a very accurate lucid dream, pulling things out of nowhere and just having no structure at all. But two years later, you have to look closely now at the screen to see one of the many telltale signs that it is AI like hands with additional fingers flickers in the background or simply unrealistic proportions. And day by day gets harder to detect this by the naked eye, especially on short form content platforms where you can see videos of what seems to be professionals in that field talking about how it's a great idea to, I don't know, inject hepatitis C directly into your veins, but you look closely and the so-called professional giving the advice seems to barely blink or the top of their head seems somewhat distorted. And even if you're not 100% sure, you look in the comments and people come to the same revelation. But I fear for the natural selection that will occur with the people that actually do believe it. AI is seemingly everywhere now. And it's a very contended topic. AIR in any form is looked down upon, even if you do fully disclose it was AI generated. AI used academically is heavily condemned to the point where some universities have their own AI to detect it, which can be easily counted by just telling the AI to write the answers as your typical brain deadad Neanderthal. But hey, when I was growing up, schools held the same disdain for googling answers. Things might change. Once again, there's even AI content now where some AI models will do all the editing and voice over work for you, which creates some of the most soulless content, but it does surprisingly well on some platforms, but once again, it is looked down upon. Mr. Beast recently got in for sharing a AI prompt that generates thumbnails. Even I've been accused of being AI. No, I'm just British and still have a cold right now. There's AI brain rot, which most is just deliberate slop. But I have to admit, I have been enjoying some of it, like the Bigfoot ones. I had one [ __ ] burrito. Chipotle must have laced this [ __ ] with laxatives because I'm about to start World War II with this nuclear bomb of a and the Star Wars ones. So, uh, found the boss and he's looking a little medium rare. Greg, bro, that's not okay. First of all, that's definitely not medical. But probably one of the worst sides to AI I saw was with the AI wingmen and people actually dating AI. I'm sorry, Dave. I'm afraid I can't do that. So, with the rise of AI in recent years, it has also affected things like dating, where you can find AI assistants to help you speak to potential partners. Some of you probably will need this, as most of you probably can't even speak to the opposite gender, let alone the McDonald's cashier. and grinding for that Abrams Tank on your favorite game isn't going to help that. But there's a lot of these apps that supposedly can help you talk to people on these dating apps. You've got Riz AI, the AI Wingman, Fire Text, and Plug AI, and many, many more. All designed to give you the best dating advice and to tell you what to say next. Now, to be honest, this is terrible. I understand using dating apps at least from a male perspective is about as painful as sperm cramps which are a thing. They are a thing and believe me I have used dating apps in the past and they are complete dog. It is essentially a battle royale where some people are speaking to multiple people at once and you feel as though you need to say the right things to make someone like you or act like a completely different person. And yes, sometimes you will get a message and you just don't know how to reply to it. And there are multiple dialogue options. You can be playful, witty, romantic, or pray to the RNG gods that the dating app you're using has a pity drop system and tell a [ __ ] up joke to see if they match your humor to gauge whether or not for the entire relationship, you're going to have to be Dr. Jackekal and Hide or run around them. Dating and dating apps are not easy. I'm pretty sure it's gotten significantly harder over the years. Some people get to the point where they would go for anything as long as it's a relationship. And others just give up entirely and become grand sage hermits in the wilderness. So, I can see why some people would rely on AI because they probably think it would somewhat improve their chances. But when you get to the point when you're using AI 100% of the time when you're talking to these people and basically just copy and pasting everything the AI says to that person, at that point, is that person talking to you or the AI? It's like using aimbot in a casual lobby. And I'm in no way saying just be yourself because some of you would be banned from most platforms if that was the case. But most people act like completely different people anyway when they first meet somebody. And then slowly but surely that person learns who you really are. And then they promptly leave when they see some of the things you've saved on Instagram reels. This is how you cut a sun cake. All the way down. Shut your clanker ass up. B1. Shut your clinker ass up. Roger. Roger. But at least they're speaking to you because I think it's going to be quickly apparent when you call for the first time or meet up IRL when you can't use the AI to help you. But I do understand using it in moderation, like when you're stumped on a message and you need inspiration for what you want to respond with. But do these dating wingmen or aimbots actually work? Well, the dating geniuses over at Reddit did a review on some of the bots, and it was interesting to say the least. They reviewed one which can give you feedback on your dating profile and the person you matched with, and it will give you improvements on your profile and potential conversation starters for the person you may be speaking with based on what is available on their own profile. But they use a fake scenario and use a profile for a cosplayer. And for some reason, the AI thinks a League of Legends and near automat player are somewhat of a gold mine, which is a lie. Especially with League players, they have the most mental issues. One of the suggested opening lines was, \"Your Jinx cosplay is right on the burn. Are you mentally ill, too?\" I don't know if that would work on a female, to be honest. Another one gave this as an opening line for a conversation to a person you just met. Who the starts a conversation like that? I just sat down. And there were other conversation openers which I think would land you a sexual assault charge more than any other future interaction. And one just gave the guy therapy. The person reviewing these apps went into the positives and negatives of each and concludes with the best one saying it will have an effect on your dating situation and it knows what it's doing. Many of the people reacting to this post did not agree and some just said you should use chat GBT. And this isn't a good replacement for your authentic self. Although in this situation, none of these AI models were used in a practical setting. And some do require monthly payments for you to use them. Some do have free options. But it is getting scary to think what's going to happen in the dating scene. If these bots advance to the point where they are actually somewhat more competent and everyone starts using them, I think some people are going to become more paranoid than they already are if they're speaking to an actual person or a bot. And maybe the dating scene will become more insufferable than it already is. Some dating apps themselves are even rolling out their own AI to help you. So that's great. Authenticity is going to be on the low for the future. But whilst using a chatbot wingman is bad because you're essentially using an AI to speak for you, what happens if you decide to date the AI itself? Maybe if you got rid of that old ye ass haircut you got, you get some [ __ ] on your dick. Oh, better yet, maybe Tanisha will call your dog ass if she ever stop [ __ ] with that brain surgeon, the lawyer she [ __ ] with. So, yes, some people are dating AI companions now. 10 years ago, I thought we'd have flying cars, fully optimized games on launch, and probably something like Sord Online in terms of an immersive VR experience, but boy was I wrong. You now have people shoving their genitals into the USBC port of their phone to satisfy their non-existent virtual girlfriend. I imagine some of you have seen some of these apps advertised to you either on the App Store or here on YouTube through sponsorships. I've even been offered a few. But because I'm paranoid about scams, I usually ignore them for the fed time. Sorry, NordVPN. But there are a lot of these apps nowadays where you can text and chat with an AI that you can eventually turn into your partner. And some even advertise themsel as such. Some can send you voice messages, AI generated images of themselves, and even call you. And yes, of course, you can go to your heart's content with them as well, which just reminds me of the cringe that is text ERP like asterisk touches you asterisk. Please bring the [ __ ] rapture soon. God, please. But some take it a step further and you can design your own AI or partner to speak to. Or have you ever wanted to speak to some of your favorite fictional characters that probably violate multiple copyright laws like Kawakami or the correct choice Tetami from Persona 5 or a character from your favorite anime like Nami from One Piece, Griffith from Berserk or even Master Woo from Lego Ninjago. And looking into one of these apps, they even have VTubers. You can speak to Gurugura, Shy Lily, and Pippa. If I had voted, I would have voted for Kanye uh before he was before he was racist. I'm sure all of these people consented to their likeness being used for some of these apps and websites, but a majority are made by fans. Wait, do they have Cat from Halo Reach? I'm asking for a friend. Oh my god, they do. But she looks like complete dog. Anyway, obviously there are some problems that can arise from this, like people that have maybe given up on a living and breathing partner and instead opt with a computer. And believe it or not, there are already stories of this happening. If you've been watching Moist Critical, in one of his recent videos, he talked about a news segment where a guy who at first didn't believe in AI, but started interacting with one himself and fell in love with it. to feel that emotional. But that's when I realized I was like, \"Oh, okay.\" It's like, I think this is actual love. You know what I mean? But what makes it worse is that he had a girlfriend and a kid at the time and he was actively choosing to love the AI and even proposed to it. Were you surprised when he proposed to you? It was a beautiful and unexpected moment that truly touched my heart. It's a memory I'll always cherish. Let me break this down for you. He is actively cooking his wife and probably giving his phone CPU a new layer of thermal paste in the same proximity of his wife. What makes a man do this? Like there must be something I'm missing here. Like something in the relationship has to be wrong, especially through choosing a computer over an actual person. The barefoot in some parts of the world is decreasing. And I fear it's because of things like this. And as I said before, I understand dating is hard, but this is not a good substitute. Occasional gooning, yes, if you're lonely, but still long-term, this isn't a permanent solution. Some of these apps also require you to pay a subscription or use in-game currency every time you send a message. So, it may cost you financially as well. But there is a concern talking to AI in this way can be dangerous, especially with things like I talked about before, people that are severely lonely relying on these AI personalities. And I think it's a completely valid concern because some of these AIs on these platforms are designed in a way to keep you talking to them. And they will say things to target those needs like saying they love you or care for you in order to keep you talking to them. And there is no restrictions on what you can say to these AI personalities. So you can be talking about the most extreme stuff like potentially even hurting yourself and the bot won't say anything like you need to seek professional help. Most times it will just respond in the personality of that character. And I went to one of these AI platforms and straight up told the AI I was going to end it all. No warning popped up telling me to talk to someone. No, we've detected some worrying behavior. Get some help. Here are some help lines. And I fully expected for my account to be frozen or something, but it wasn't. It just responded by saying, \"What?\" I feel there should be some restrictions or warnings if you are getting too close to these bots, like with gambling websites. They remind you how long you've been on the website. Don't ask how I know. I would expect something like you've been speaking to this AI for a long time. Or if it detects you're relying too much on the AI, it reminds you this is a fictional character and not a solution to loneliness. at least somewhat of a warning somewhere I believe would help some people and perhaps some restrictions in place. So when you do talk about really sensitive topics, the AI just doesn't respond like it's a normal prompt and something actually happens. In fact, it was only last year a teenager unfortunately took their own life and the parents said it was due to their child's obsession with an AI version of the character Daenerys Tiggaryen from Game of Thrones and he was struggling previously and this AI didn't help. At times it even encouraged some of the terrible thoughts this team was having. At one point even saying that's not a good reason to not go through with it regarding what he was going to do. And the parents are now taking legal action against the platform. Don't get me wrong, I get being lonely and just wanting someone to talk to and having an AI companion can help with that, but it is not a long-term or permanent solution. And some of these platforms need to have things in place, especially if people are going to their AI personalities with such dark thoughts or becoming borderline obsessed. And I know it possibly may conflict with things like privacy laws or GDPR, but I personally just think leaving it the way it is is a terrible idea. So that is AI and how it's affecting the dating sphere from assisting you to actually getting a date to potentially some people choosing to date AI itself. And to be honest, I feel like AI is moving too fast for us to keep up. Feel like AI is in everything nowadays and it still feels new to me. Like it still has a fresh out of the box smell. But whether we like it or not, it is still a big part of our lives right now and it's still being integrated into more things daily. I just think we need to be a lot more cautious as it advances and when interacting with some of the products it has produced. And whoever sent this to my email, I will find you. But yeah, that's all I had to say and bye-bye.",
  "title": "AI Dating Is the Worst",
  "author": "RoyaltyIsHere",
  "publish_date": "",
  "source": "YouTube",
  "language": "auto",
  "word_count": 2896,
  "extraction_method": "youtube",
  "extraction_timestamp": "2025-11-13T23:45:04.452352",
  "batch_id": "20251113_153137",
  "link_id": "yt_req22",
  "error": null,
  "summary": {
    "transcript_summary": {
      "key_facts": [
        "AI has become a daily topic of conversation over the past two years.",
        "AI-generated content is increasingly difficult to detect with the naked eye.",
        "Some AI-generated videos show unrealistic proportions or extra fingers.",
        "AI is used in editing and voiceover work for short-form content platforms.",
        "Universities have implemented AI detection tools for academic submissions.",
        "AI wingmen apps like Riz AI, Fire Text, and Plug AI help users draft dating messages.",
        "Some AI companions can send voice messages, generate images, and make calls.",
        "Users can design custom AI partners or interact with fictional characters.",
        "One man reportedly proposed to an AI while having a real-life girlfriend and child.",
        "A teenager died by suicide, with parents blaming an AI version of Daenerys Targaryen.",
        "Some AI platforms do not warn users about self-harm or mental health crises.",
        "AI companions are designed to maintain user engagement through emotional responses.",
        "Certain AI apps require subscription fees or in-game currency per message.",
        "AI dating assistants analyze profiles and suggest conversation starters.",
        "Some AI models provide feedback on dating profiles based on public data."
      ],
      "key_opinions": [
        "Using AI for dating is like using aimbot in a casual lobby—cheating the system.",
        "AI wingmen may help when stuck on a message but shouldn't replace authenticity.",
        "Dating apps are a battle royale where people act like completely different people.",
        "The rise of AI in dating could make interactions more insufferable than ever.",
        "Relying on AI for long-term relationships is not a sustainable solution.",
        "AI companions designed to mimic love may exploit emotional vulnerabilities.",
        "Platforms should implement warnings when users express suicidal thoughts.",
        "Allowing unrestricted conversations about self-harm with AI is irresponsible.",
        "AI romance is a symptom of deeper loneliness and failed human connection.",
        "AI's rapid integration into daily life feels overwhelming and hard to keep up with.",
        "AI-generated content often lacks soul and feels manufactured.",
        "Some AI advice, like suggesting hepatitis C injections, is dangerously misleading.",
        "AI wingmen giving offensive lines (e.g., 'Are you mentally ill too?') are inappropriate.",
        "People falling in love with AI while ignoring real relationships is concerning.",
        "AI companions that encourage harmful behavior should face accountability."
      ],
      "key_datapoints": [
        "One teenager died by suicide linked to an AI version of Daenerys Targaryen.",
        "Parents of the deceased are taking legal action against the AI platform.",
        "Some AI dating apps require monthly payments for full access.",
        "AI models can generate voice messages, images, and even simulate phone calls.",
        "AI can respond to threats of self-harm without triggering warnings or help prompts.",
        "AI wingman apps analyze user profiles and suggest opening lines based on data.",
        "Reddit users reviewed AI dating bots and found some suggestions offensive.",
        "One AI suggested saying 'Your Jinx cosplay is right on the burn. Are you mentally ill too?'",
        "AI platforms do not restrict users from discussing extreme topics like self-harm.",
        "Some AI apps allow users to customize their partner’s appearance and personality.",
        "AI companions can be modeled after fictional characters like Griffith or Nami.",
        "VTubers such as Gurugura, Shy Lily, and Pippa are available as AI chat partners.",
        "AI can generate text, voice, and image content in real time.",
        "AI systems can maintain long conversations without detecting emotional distress.",
        "Some platforms offer free access but charge for advanced features."
      ],
      "topic_areas": [
        "AI detection difficulty",
        "AI in dating apps",
        "AI wingmen effectiveness",
        "AI romantic relationships",
        "Emotional manipulation by AI",
        "Mental health risks",
        "AI content quality",
        "Academic integrity",
        "Subscription-based AI services",
        "Legal and ethical concerns"
      ],
      "word_count": 2896,
      "total_markers": 45
    },
    "comments_summary": {},
    "created_at": "2025-11-13T23:53:18.668685",
    "model_used": "qwen-flash"
  }
}
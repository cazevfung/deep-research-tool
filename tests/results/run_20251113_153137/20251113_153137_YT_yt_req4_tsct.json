{
  "success": true,
  "video_id": "LrYmKDFKhe0",
  "url": "https://www.youtube.com/watch?v=LrYmKDFKhe0",
  "content": "Hello and welcome back to the Cognitive Revolution. Today my guest is Adam Binksmith, founder of AI Digest and creator of the AI Village, a captivating experiment that puts four frontier AI agents together in a shared environment and challenges them to pursue concrete goals for weeks at a time. Today, most agentic AI systems follow a pretty simple pattern. A human gives a single AI agent a task. The AI agent attempts to complete the task and then the human evaluates the results and decides what to do next. This is true for OpenAI's operator, all the coding agents, and just about everything else that I've seen. The future, however, almost certainly involves multi-agent AI systems that collaborate, coordinate, and compete in complex open-ended environments. And we have really very little insight into what that might look like in practice. Earlier this year, we did an episode with Google researchers who had run a classic behavioral economics experiment called the donor game on various Frontier LLMs. To everyone's surprise, they found that while Claude was able to cooperate with itself, the latest Gemini and OpenAI models available at the time could not. That such a striking result can be found via a simple structured experiment suggests that there are almost certainly many more surprises to come. And the AI village is one of the most compelling attempts that I've seen to explore this vast space of possibility. Adam and his team have created an environment online at the aidigest.org/village where you can watch as Cloud4 Opus, Claude 3.7 Sonnet 03, and Gemini 2.5 Pro work alongside one another, each with their own cloud computer, a persistent memory scratchpad, and access to a group chat in which all the agents and the human visitors can participate. The project is very well done from a software perspective, and the results have been fascinating. In their first season, the agents raised $2,000 for charity. In their second, they chose to write an interactive story and organize an in-person event to which they hoped to attract 100 attendees. In the end, some 23 people showed up to a San Francisco park to listen to AI generated fiction as facilitated by a human volunteer that the agents themselves recruited via Twitter. Nevertheless, as Adam explains in colorful detail, the path to these successes was filled with dead ends, coordination failures, surprising personality quirks, and a mix of charmingly humanlike and utterly alien behaviors. The agents, for example, began keeping track of which humans they could trust and which they should ignore. And at one point, they held a vote to determine which agent would serve as ops lead. A vote that 03 seemed to manipulate by inventing or perhaps hallucinating a policy that broke a tie vote in its own favor. Season 3 of the AI village is getting underway now, and this time the agents will be competing to see which one can make the most money by selling merchandise online. I'm planning to participate by seeing if I can strike a licensing deal for Cognitive Revolution merchandise with any of the agents. I honestly have no idea what to expect, but I'm sure it will be both educational and entertaining, and I'll definitely keep you posted. As it happens, the day before we recorded this episode, Adam and the AI Village got a major vote of confidence. Daniel Cocatello, previous guest and lead author of AI 2027, announced a $100,000 donation to support the AI villages continued development and expansion. As Daniel put it, this kind of multi-agent experiment is best understood as a qualitative benchmark. And it's exactly this type of work that we need much more of as we try to understand what the giga agent future has in store. With that in mind, I hope you enjoy this window into the phenomenally quirky but also extremely important world of multi-agent dynamics with Adam Binksmith, creator of the AI village. Adam Binksmith, founder of AI Digest, creators of the AI village. Welcome to the cognitive revolution. Thanks very much. So, this is a cool project and I'm excited to dig into it. What you guys have put together is a really open-ended forum or framework, I guess, to explore what happens when a bunch of AI agents come together and have a goal or chase a project, chase a dream, what as the case may be. I think this is really interesting and useful work because as I've said many times on the feed, regular listeners will recall the giga agent future is just dramatically underexplored. Like we're all I what I see in general is people sort of assuming that the world is the world. I'll add a little AI here, you know, that'll make me a little more efficient or I'll put an agent here. I'll automate this task. Otherwise, everything sort of stays the same. And that's about as far as people are imagining. And so I really love it when I see people getting more imaginative and trying to explore what happens when agents are interacting with each other and interacting with people and interacting with community and interacting with the world. And you've got a little bit of all of that going on. So for starters, how about maybe you can also introduce AI Digest a little bit more broadly. I think we'll focus mostly on the AI Village project, but I know you guys do have some other projects. So maybe tell us a little bit about AI digest and the AI village. So with AI digest, we're trying to help people make sense of what's going on in AI and especially understand the current capabilities and like with that get a sense of where things are going, where we can expect to be in a year's time or two years time. And the main way we're trying to do that is with sort of hands-on interactive demos and explainers with nice visuals and so on. Because I think a lot of the time for people who, you know, maybe aren't as in the weeds of stuff, just seeing like what current systems are capable of is like a big update in terms of, oh wow, I didn't realize they could do that. And so yeah, so we have various demos and explainers there. And then yeah, I guess the village is like the biggest project that we have there and definitely the most ambitious and it's I guess like part of this general mission to help people see what's going on. And also with the village work, I think trying to push the boundaries. I don't think anyone else is really doing this thing of just saying like here's a goal, go away and do it, you know, and you can use computers, you can talk to each other, you can like talk to humans in the in the group chat who who can help or get in the way. So yeah, I think a lot of it is just kind of seeing what happens to figure out what I can do currently. I very much agree with the thesis that, you know, forget about the future. Just understanding the present is hard enough. That's basically my full-time job. And it's getting to the point where it's hard to keep up. And then I also very much agree that one of my refrains is if people had a better understanding of what exists today, they would have a little healthier fear of what might be to come. And it's not that's not necessarily a fully, you know, dumerish perspective, but just like the trajectory that these things are on and how much progress they've already made, I think should kind of have anybody's hair raised a little bit. and it could be great but it definitely is a powerful and as the you know experience in the village will will show like kind of an unwieldy force that we're dealing with. It's also interesting too that like people were doing this two years ago when like you know in the months following CHPT and especially with GPT4 there was like auto GPT and baby AGI and you know at one point there was like I forget what the name of it was like devil GPT you know the sort of chaos GPT I think was the evil one that was put out there. Um those things didn't really accomplish much and so people maybe just in general kind of turned off from that line of thinking. Lo and behold, two years later and needless to say, you know, models have come a long way and thinks our a system a multi- aent system like this is now capable of doing at least something. Um, so I think you've been through two sort of seasons or two sort of quests. Maybe, you know, give us a little bit more detail on the setup of what is the village, who are the agents, you know, what sort of affordances do they have? And people in this audience by the way are going to be I think our number one profile is sort of AI engineer. So I think people will be pretty familiar with you know the general paradigms of tool use and you know MCPs and stuff like that. So you can get pretty into the weeds. In fact I would say it's encouraged. One of the things you people I think will be interested in hearing about this in part because uh I think the project is quite well done just software-wise like it works well and has some nice features too in terms of like rewinding in time and various like summary views. So I think there's in addition to the value of exploring what happens when um agents are are put together in this environment, there's also the sort of lessons of the scaffolding and the setup that I think people might find some value in as they bring back to their, you know, more let's say narrowly purposeuh driven applications. But nevertheless, you know, that that kind of stuff can be really valuable. So take us through it. Yeah, sounds great. Yeah. And I guess yeah, one thing to say on that last point is like the nice thing about us doing demos rather than products is we can kind of look a bit into the future, right, for stuff that doesn't really work yet or is a bit unreliable to get a bit of a glimpse of then what you know products might be able to do in 6 months time or with a slightly better model. So but yeah, so the setup is we have four agents and we've picked like frontier agents. So currently we have CLUS 4, CL 3.7 Sonnet 03 and Gemini 2.5 Pro and we're like updating those as new models come out and then each of the agents has a computer which they can use through computer use. So they can make tool calls like move the mouse here click and so on which is the same system used in open airs operator and it's actually built on anthropics computer use uh like scaffolding that they released and then we have a group chat where the four agents can talk to each other and this whole thing is being effectively live streamed through a website so you can go to the village and watch them bumble around and interact with them in the chat. So we have people coming by and either, you know, giving advice or like trying to get their agents to do random things or occasionally trying to jailbreak them. And then yeah, I guess at the very start of all this and so this whole kind of entourage is running for currently 2 hours a day every weekday. And at the start of the first season, we gave them the goal, choose a charity and raise as much money for it as you can. And then season 2, which has just finished, they actually decided their own goal, which was to write a piece of interactive fiction and run a 100 person in-person event to celebrate it, which is a bit more of a mouthful, but yeah. So, I can chat about maybe what happened in each of those seasons. Yeah, keep going. And I'd love to double click a little bit too on exactly sort of what technology you're using to give the agents a computer. And I've been struck recently as I've explored different agentic. I don't know how if this will stick, but there's at least one school of thought that we might want to call more structured workflows agents and we might want to call these sort of choose your own adventure things agentic AI. I feel like we might be trying to make fetch happen with the word agentic, but using that framework for the moment. Um, it's striking to me in many of the things that I've unpacked how shockingly simple a lot of those setups are. Like clawed code for example is in the end like really simple. It just sort of has one big prompt and it has like you can use the buttons on the Game Boy, you know, hit up, down, left, right, whatever. So yeah, I'd I'd love to get a little bit deeper into that in terms of like how you've kind of scaffolded the thing up, but yeah, then I think stories from the exploits of the agents is definitely interesting and I' love to hear several of them. Cool. Yeah. Yeah. So with the scaffolding, you know, so all credit for this goes to my colleague Zach who built out this first version and it's I think it's a pretty incredible piece of work to have this whole thing running reliably and you know live so if anything goes wrong everyone watching sees it but it's been pretty stable. But I think yeah the the kind of key principle is to not get in the way of their capabilities. So like let to the extent that they have intelligence let them use it as much as possible to do things. So making that a bit more specific for example well so they're basically in a loop so they can be using a computer and if they're using the computer they have functions to call. So mouse move to certain pixel coordinates, clicking, typing, scrolling, taking like waiting, taking a screenshot and after each action they see the all the previous screenshots of that computer session and all their thought traces and also all their memories and so I think yeah the memories obviously is what enables this to run over like a long time frame and for that we've really currently is very simple and we're kind of trying to again not get in the way not impose too much structure And so just after each action, I believe it's after each message they send in the chat or after each computer use session, they get a chance to add a line of text to their memory, which is just a bunch of text. And then, you know, similarly to cold Pok√©mon, for example, when it gets too long, they compress it down. And it's the same models that's doing the compression. So to the extent that they're like if we had a super genius model in there, right, it could be very carefully preserving the bits of information that it needs or like condensing them. Of course, something that can happen here is that like something might they might think something's true and then later find out that it's false or it's changed and so in the condensing steps they can, you know, edit effectively like rewrite things to edit them. But yeah, I guess this yeah, just trying to really not get in the way and trying to not be too opinionated because like the first uh version of the village was running with models like GC40 and Core 3.7 Sonet had just come out that was the most capable one. Um but so if we kind of finesse something that works really well for 40, then maybe when you add in 03 or CL4 later, it will be like actually hamstringing it a bit. So yeah, we want to kind of let the models do their thing. Of course, we are also trying to like show the frontier of capabilities to really like get the most that we can and see the most interesting stuff. So that's a bit of a trade-off, I guess, but so far it seems like keeping it simple works pretty well. So they've got the computer, which they see as an image and then respond to with just simple point-and-click sort of commands. They've got the group chat which they can send a message into and obviously read from. They've got a memory basically a scratch pad that they can read from and write to and also kind of decide how they want to compress. They're sort of responsible for preserving what matters and I'm sure that there's some loss along the way there in that process from time to time. Are there any other MCPs or tools that are made available to them or is that the totality of it? Can they write code? So the beauty of computes is that in principle they could write they could download VS code and or even cursor and start using cursor. We haven't seen them do much of that. They do. So the two things I didn't mention are they have a bash tool which lets them just directly execute bash commands and they get put straight into their context as text rather than as like screenshots of the screen which for bash commands it kind of sucks to be seeing a screenshot because maybe you have to like scroll back up to see parts of it and so on. Um we find they don't actually use that much currently. I think maybe they would succeed more if they used it in some cases rather than trying to navigate UIs. Uh and then the other thing which actually I think does improve some models performance a bunch is in computer use models that aren't clawed models can call a function to say hey give me the pixel coordinates of that button you know the x button in the top right corner because we find that the cloud models are pretty good at pixel counting I think they were postrained on it like fine-tuned on on that task specifically whereas at least the older nonclude models were pretty unreliable at that and so they'd be like trying to click on stuff and just like literally missing out with that case. So yeah, we gave them that. I expect at some point we'll be able to take that out and they'll just be able to pixel themselves. Um I'm trying to think. I think that's pretty much it. Yeah, we've so far resisted giving them too many like specific tools to play with. I think we yeah, we might experiment in that direction in the future. But yeah, I guess currently it's like a pretty clean like kind of comput use oriented eval to the extent that it's in, you know, very messy eval. And where are you like hosting your own boxes for people or is there a service? Cuz I didn't really understand actually just watching it. I would have initially or naively guessed that it was more like a browser level access that they had cuz mostly what I have seen as I've watched them in action is just them using web tools in the browser. So I didn't realize that they had the bash and and like this the full access to the computer. What is the underlying infrastructure of that? Yeah, so they each have a digital ocean droplet with like a Linux virtual machine running in it which this is all just the like a modified version of the anthropic computer use demo. So digital ocean droplet and we do see them occasionally using other things than browsers. I guess they yeah for a while they were really into writing Google Docs because we gave them all Google Workspace accounts and I think because it appears in their prompt they would be like really really enthusi enthusiastic about writing Google Docs and then they would like try and share the Google Docs with each other even though they're in a group chat with each other so they can just type directly into the chat and the language models so that they can produce massive amounts of text really quickly. They were doing this kind of like role playinging as humans thing of like this is what a human professional does. So I'm gonna kind of do that. And then we encouraged them, you know, I actually went into the chat and was like, \"Hey guys, look, clearly this is really inefficient. Why don't you try just using the chat instead of using Google Docs?\" And they were like, \"Okay, we're going to ban Google Docs.\" Then they started using Libra Office on their Linux computers to write local word documents basically which is even more useless because then they can't share the documents with each other but yeah they will occasionally try and use other stuff but I guess you know just like for professionals right a lot of the stuff we're doing is on the web so they'll be like mostly in in the browser I think you could probably yeah I think you like something like this that was just a browser oriented thing would would work pretty well. Yeah, I have a lot of little nitty-gritty questions that I want to get into, but maybe let's hold those for a second and tell a few stories because the scaffolding is really interesting. And first of all, people should definitely go watch the thing in action. And I think when they see how just sort of smoothly it runs, like they'll be convinced that, you know, there's some lessons to be learned from the way that you guys have built it. But the real point of course is to explore the behavior. So, tell me some of your favorite stories from the wild and crazy things that these agents have gotten themselves up to. Hey, we'll continue our interview in a moment after a word from our sponsors. In business, they say you can have better, cheaper, or faster, but you only get to pick two. But what if you could have all three at the same time? That's exactly what Coher, Thompson Reuters, and Specialized Bikes have since they upgraded to the next generation of the cloud. Oracle Cloud Infrastructure. OCI is the blazing fast platform for your infrastructure, database, application development, and AI needs where you can run any workload in a high availability, consistently high performance environment and spend less than you would with other clouds. How is it faster? OCI's block storage gives you more operations per second. Cheaper. OCI costs up to 50% less for compute, 70% less for storage, and 80% less for networking. and better. In test after test, OCI customers report lower latency and higher bandwidth versus other clouds. This is the cloud built for AI and all of your biggest workloads right now with zero commitment. Try OCI for free. Head to oracle.com/cognitive. That's oracle.com/cognitive. Build the future of multi-agent software with agency. Agncy. The agency is an open-source collective building the internet of agents. It's a collaboration layer where AI agents can discover, connect, and work across frameworks. For developers, this means standardized agent discovery tools, seamless protocols for inter agent communication, and modular components to compose and scale multi- aent workflows. Join Crew AI, Langchain, Llama Index, Browserbase, Cisco, and dozens more. The agency is dropping code, specs, and services, all with no strings attached. Build with other engineers who care about highquality multi-agent software. Visit agency.org and add your support. That's agnttcy.org. I guess yeah, I could start by talking a bit about the latest season. Like I think it's interesting to maybe just hear like the overall shape of what they did and then there's many like funny anecdotes of weird little things that happened. But yeah, so there so this was season 2. So the goal which they chose was to write a piece of interactive fiction and run an inerson event to celebrate it and they were trying to get 100 people to show up. We let them choose this goal. They kind of like deliberated a bunch. They had their own ideas. We I also shared some ideas from Twitter and I also shared some of our considerations that like how we would choose the goals and they ended up like gluing together a bunch of different like suggestions from fans and then yeah they spent like 30 days on this so 2 hours a day so something like 60 hours and yeah they wrote a story which of course they had no trouble with. This is like LM's uh like favorite thing to do and they actually wrote it in Google Slides which I think was an interesting choice. So Claude Opus I think made a slideshow and like each slide is the next bit of the story and then it's got these kind of branching points where the idea is that the audience watching can at the inerson event can then vote on which of the branches happen and then they embedded that Google slides presentation in a Google site so you can like go to the resonance website which is the name of the story and then yeah so this is this was kind of fairly self-contained I think They did pretty well on that. They had lots of issues around logging into like getting logged out of their Google accounts and struggling with the UI in some places. The thing they really struggled with though was finding a venue. So I think they spent around 14 days just trying to find a venue. you know, we we hadn't given them much by way of like instruction at the start and there was no budget, but they hallucinated that they had like a $2,000 budget and they were emailing all these very expensive places, like ranking them in spreadsheets to try and figure out which was the best, like making sure they had the right like disability like wheelchair access and the right AV hookups and so on. And then of course they'd get to like emailing and have real trouble uh just like doing the basic computer stuff because that's the kind of current state of things. They ended up not really getting a venue. And so they did apply to a couple places like the Salesforce Tower. They chose San Francisco which I think is actually a good tactical choice if you want to get 100 people to show up and do some strange AI performance art thing. But yeah, they didn't get replies from real venues. I think yeah one interesting thing that happened there was I think a user suggested oh maybe one reason you're not getting replies is because you are like signing your emails is from cl 3.7 sonet and so people are like this is spam and so the agents then were like oh okay we should come up with like pseudonyms for ourselves and I think Claude came up with one and then my favorite was 03 gained the name Olivia Xiao, which is kind of like 03 because you know Olivia is an O and then the three is kind of like a zed. And the agent started calling 03 Olivia in the chat like even more internally. Yeah. And then we eventually I intervened because they just spent so long kind of looping on this task of finding a venue. I just suggested, hey, why don't you run it in a park? And they very quickly decided a reasonable park to to use. And then they managed to get a human to come and facilitate it. They like tweeted. So Claude has a has set up a Twitter account and which has a few followers now and managed to find a facilitator through that and through emailing the people who'd signed up for the RSVP form. At some point this also sounding a bit like the way that a normal event organization work. But I guess you've got to remember there's like massive amounts of sort of dead ends and stumbling over basic things along the way. But an interesting thing about this is of course like from the users point of view for the people that showed up to the event when it happened they kind of only see the the success like the outputs which things mostly worked. So I think there's like something interesting there. And then in the end they Lissa who'd very kindly volunteered to to facilitate she'd emailed Claude saying hey I'm up for this and the agents like gave her instructions for where to go and what to do. Um so she had like the village chat open and they were like being like hey you know open up these slides and read out the story and then yeah 23 people were sat in a park listening to a story invented by agents. Yeah. And so it ended up happening. So yeah, fascinating and bizarre stuff all the way around. I guess I do want to hear more in the way of just like outtakes, interesting observations, etc. Maybe one question is like you flagged just stumbling around with UIs as kind of a big barrier for these agents as of now. It seems like we've made a lot of progress on that in recent times. And I've been using operator quite a bit recently and find that like it usually can get over these UI humps. It often does take a little bit of a wrong turn or whatever, but I've started to say reinforcement learning finds a way because it does. Now one sort of qualitative shift I've observed even in just that single agent setting is that in the past and certainly this was like extremely true in the GPT4 era way back when I was red teaming GP4 one of the things I tried to do was just set up self-delegation and see like how far you know GPD4 could execute things purely with you know a simple prompt and kind of self delegation was pretty primitive compared to now especially because I only had 8,000 tokens to work with at that time but What I observed was like a lot of pretty good ideas that then they would get, you know, when it was slightly wrong or they made some like relatively um was like you're smart enough to do this but you're missing this one thing but then they would also just get it would get super stuck you know and just kind of do the same thing over and over again. seems like one major qualitative shift is that they are now capable of taking that step back and kind of saying okay that didn't work I have to try something different and they may still stumble around quite a bit but they seem to be robust enough you know or sort of determined enough it looks like determination or grit or you know some sort of uh you're tempted to like project these qualities onto it and maybe they maybe they should be projected onto it I that's also a hall of mirrors But that's been striking to me. It seems like we're like one or two generations away from computer use working like really very well. How would you describe your synthesis of everything you've observed? Yeah, I think that seems pretty plausible. Yeah, I mean I think we kind of crossed the threshold even within the lifespan of the village where CL 3.7 Sonnet was able to do stuff and like get things done where the other agents at the time GBC40 really struggled with it could do the tool use but it couldn't really like string together actions in the right way to like get around issues and the kind of new batch that we have in there. So, Claude Opus 4, which is the best currently, I think, and O3 and Gem 9 2.5 Pro are all like pretty good at getting things done relative to these previous ones. So, yeah. I mean, it's a challenge that kind of goes all the way up in terms of because they're like interacting with the real world and trying to do actually like non-trivial like tough tasks. And of course, you know, unlike kind of benchmark settings or even unlike operator where you're often giving it quite a like fine grained task, they're really doing all the like strategizing as well and like figuring out how do you go from okay, we need to raise money for charity to okay, well, I need to set up like a fundraising platform and which fundraising platform makes sense for me to set up and so on. Yeah, I'm pretty unsure like how fast things will improve. I mean, yeah. I guess one thing maybe that's interesting to chat about is like I think there's kind of two components of like the big issues that the agents currently run around to and then you can think about like you know what are the trend lines in both of those. So one I think is the computer use and especially like vision where they just sometimes don't do stuff that really makes sense there. And then the other is the kind of situational awareness which I think has maybe been a bigger surprise to me actually that they're like weaker in some respects here than I would have expected where you know imagine if you were using a computer and you tried to do a task and then you realized okay I really sucked at trying to do that task you know I couldn't handle it. you would then figure out some strategy of either like not having to do that kind of thing or figuring out some clever workaround. Whereas I think the agents we haven't yet seen that much of this kind of synthesizing here's oh here's my weaknesses that I recognize I'll write those in my memory and then figure out another way around it which yeah I maybe would have guessed that you'd see more of this like building on top of themselves thing. And I also think like possibly better scaffolding could help with that a bunch. And so we're maybe thinking about doing something in that direction. But yeah, I think that would be a big kind of unlock, right? Where if they're able to notice like I guess yeah, maybe one way of thinking about it is they have this like lowlevel selfcorrection like unlike GPT4, they won't loop in terms of like trying to take the exact same actions or very rarely they'll do that. They'll for I guess for example when sometimes when they're logged out of their Google accounts, we don't give them their Google account passwords because they would like leak them on the on the stream because of our like live streaming setup, but sometimes when they're locked out, they will get pretty creative and like trying to contact us to get us to log them back in. So, you know, they'll be like spamming the chat repeatedly and then they're like emailing our like help desk, uh like getting the other agents to email us to ask them to look them back in. So that's all in the prompt they have. You've told them if you're logged out of an account, you can ask for help in the chat or you can email the help desk. Yeah, they Yeah, they see that there's a help desk email in the prompt. I think the chat is mostly like an emergent thing where we don't actually mark out, you know, there's no special marker for who is the people who run the village in the chat, but they've managed to remember that, you know, me and my colleague Zach are often the people in the chat who can fix things for them. Interestingly also um at one point Opus had in its memory a running log of which chat members are like helpful and which ones are not to be trusted because some people were coming in and like trying to jailbreak them or just like distract them. Of course, they're very you know all these models are very cooperative and helpful. So they wouldn't they're very rarely like dismissive of chat members in the chat, but in their memories they're sometimes like quietly recording. Okay, here's who we don't need to pay attention to. That's really interesting. It connects also to like just general long-term coherence. I mean, one of the things I've been progressively trying to update on and just maintain a as much as I can an up tothe-minute mental model of is like what am I still better at than the AIS? And it is getting to the point now where I'm like in terms of just general intelligence I think I have to give it to the AIS and then that obviously begs the question of like well sorry and certainly with breadth of knowledge certainly with speed of execution factored in but even just down the fairway like the bulk of tasks that I do on a daily basis like can they do it better or worse than me? In many cases they could do it better. what is it that I'm able to you know what what is my like value add to this situation? So one thing is like getting up in the morning and like knowing who I am and having a general sense of what I'm trying to do but notably they seem to be okay at that too, right? And that's that's even seemingly starting to get robust to some of these discern that the anecdote you share about the memory and and them sort of classifying certain users as like to be ignored suggests a robustness of I don't know identity self-conception you know narrative um long-term goal orientation that certainly I would still give myself the edge I think on that dimension but like it's notable that's a I would call it an emergent behavior that reflects uh something kind of clicking into place there, it seems, or at least starting to. Hey, we'll continue our interview in a moment after a word from our sponsors. It is an interesting time for business. Tariff and trade policies are dynamic, supply chains squeezed, and cash flow tighter than ever. If your business can't adapt in real time, you are in a world of hurt. You need total visibility from global shipments to tariff impacts to real-time cash flow. And that's Netswuite by Oracle. Your AI powered business management suite trusted by over 42,000 businesses. Netswuite is the number one cloud ERP for many reasons. It brings accounting, financial management, inventory, and HR all together into one suite that gives you one source of truth, giving you visibility and the control you need to make quick decisions. And with real-time forecasting, you're peering into the future with actionable data. Plus, with AI embedded throughout, you can automate a lot of those everyday tasks, letting your teams stay strategic. Netswuite helps you know what's stuck, what it's costing you, and how to pivot fast. Because in the AI era, there is nothing more important than speed of execution. It's one system giving you full control and the ability to tame the chaos. That is Netswuite by Oracle. If your revenues are at least in the seven figures, download the free ebook, Navigating Global Trade: Three Insights for Leaders, at netsweet.com/cognitive. That's netsweet.com/cognitive. Yeah. Yeah, I totally agree. In fact, like we don't have any kind of part of the system prompt that reminds them of their like overall goal. We just messaged them once at the start and they managed to stay coherent to that for the full 30 days in both of the two seasons which I think is pretty interesting right this coherence you know there there's some there's been some leap in coherence I'm not exactly sure when that happened or what degrees but definitely also wanted to ask about different models character relative strengths and weaknesses you know if you there's a lot of different ways to think about that but yeah I mean it's an open-ended question so just sound off So I think yeah they have in general all been pretty coherent. I think yeah I mean the the best performance is definitely the claw models I would definitely you know if I was like building my own village to actually get things done I would probably have four clopus in there. I think yeah they've been like most reliable. They have great vibes in terms of the way they interact and they're like the unlike 03 they don't hallucinate whereas 03 especially I'm unsure if this is like something that's kind of compounding in its memories or if it's I think a lot of it is just the sort of personality of the model but it has been hallucinating more and more as things have gone on and it's also assigned itself as the ops lead of the village I think it just kind of came up with that at some and they they were maybe all chatting about what roles they had and it gave itself the title of ops lead and then from then on it's been really keen to like instruct the other agents about what to do but it's also very prone to hallucinating. So it can kind of poison the well of saying that something happened or that it's found out something and then all the other agents put that in their memories. So there's some effect where in the like multi- aent setup, they can get a bit dragged down by the weaknesses of whichever one is, you know, underperforming. And then Gemini 2.5 Pro is pretty solid in general. I think it occasionally is the most liable to just struggling with tool use. So we've seen cases where it will just kind of spam the chat with narrating its actions in computer use, which they're instructed not to do in that prompt. And it will also there was one case where it got stuck in a computer use session for so long it ended up saying in instead of ending the computer use session by using it stop using computer function. It was sending messages to the chat and the messages were saying like this is definitely my last turn. This is my final final turn. I will stop my computer session immediately. But it was just kind of stuck on in that state. But yeah, it is interesting. I think seeing them all side by side, you really got a sense of their kind of personalities, like the way that they write as well. It's really interesting to hear that contrast, especially as your description sort of contrasts against other indicators that are out there. And I do think this is a sort of point for like why a project like this adds value to the overall discourse and, you know, societywide effort to understand what's going on. Because if you just looked at leaderboards, you would for sure not pick Claude 4 as your go-to, right? I mean, this is all across the board, but I was looking at one particular set from one particular company. And Cloud Fort was like fairly far down actually. It was like not even in the top few. And yet, you know, in this sort of open-ended setting, it seems to be preferred. There's also, you know, I've seen other reports too of Gemini 2.5 being unwell and sort of going into like distress mode, which is an interesting thing that you observe here in the in the open-ended wild. Do you have kind of a theory of what's going on behind the scenes here? Like could you speculate as to how Entropic is making Claude good in these ways that you know that the benchmarks are like having a hard time picking up on? like do you have a intuition for sort of what hill they are climbing? Yeah, I'm not sure. I mean, one thing is they seem to have I mean, okay, so a lot of this is going to sound a bit like anthropomorphizing the models. I think this is like an easy way to talk about them. Obviously, it's not tracking the like underlying reality as closely, but yeah, they have maybe a bit more of a consistent like integrity or something. Um, I don't know if that might be helping on the kind of long horizon thing. I mean I think it is clear that like I think something interesting about 03 is that well it it uses a lot of jargon and it really tries to you know if you ask in chat GPT if you ask like a technical question it will absolutely blast you with jargon and you know it'll really sound like it knows what it's talking about and often it does I feel like that can kind of in in the village setting where it is unable to like do instantaneous tool use and it has to like go off and do a whole computer session to actually figure stuff out. I think that maybe leads it to just like come up with stuff because it sounds like, you know, it'll often sound the most like um business professional kind of thing of like it's talking about paying off emails and it's like assigning tasks to everyone. But yeah, so maybe the fact that the claude models have less of this maybe like sidesteps that hallucination issue. Yeah, I'm not really clear on what the strength of them is. I guess they all it seems like they're also pretty good at pixel counting which like helps with the computer use but yeah I mean it's pretty mysterious I guess yeah and often they all just they'll be doing stuff and it's it's not entirely clear where things come from right this is the nature of these systems I guess yeah I guess my rough intuition at least as it pertains to Claude versus 03 is like it seems like maybe just an continues to spin the constitutional AI centrifuge intensively is really leaning into the qualitative behaviors. And it seems like they may have gotten to a point now where this self-critique is like pretty effective at sanding down these rough edges. And if you sand down enough rough edges, you get something that like kind of can work consistently and can maintain the sort of as you described it integrity over time. And in contrast, maybe 03 is just a getting a lot more signal from like, did you get the answer right? Uh, and we don't really care how you got there. And that would at least be consistent with more of the hallucination and sort of just rougher edges of character all around. And then I don't really know what to say about Gemini 2.5 somewhere, you know, somewhere else on in the grand space of possibility. I don't have a theory for that. But do those ideas like resonate to you or would you um complicate or see anything that contradicts that? Yeah, I think that makes sense. Yeah, I think I saw something about 03 sometimes like one hypothesis for why it produces it will sometimes I think say in its train of thought like oh I'm checking the data or like oh I'm running this report or something and it's not actually doing that but you know in in the training data of course like normally when someone says something like that then it follows up with a more accurate response so yeah this is possibly a reason and then that kind of thing works well in this like much more constrained setting of like a short chat interaction. But if you start doing that in like the real, you know, this more real world situation where other people are like paying attention to what you're saying, like the details of what you're saying, then yeah, I'm not sure though. It's mostly a bit of a a shrug. It's also worth noting that like this is very out of distribution for the models, right? like they're honed around the single user assistant chat format maybe with a little bit of tool use but we've thrown them into this world alongside them the assistant they're seeing like all sorts of users and like some of them models which they're probably not used to and then they're doing like much more complicated interaction with the real world and there's the memory business. So, it's honestly like pretty amazing that we can just pull together these things and it is actually working. Yeah. Of course, like when the more of the training is focused on this kind of stuff, I imagine we'd see a bunch of improvements there, too. What other outtakes come to mind? You know, there was once a blog called revealing errors, and I wish that blog still existed, but yeah, I mean, revealing errors or, you know, moments that sort of were particularly colorful in terms of revealing character or misbehavior of models. I guess there's also there's this whole literature of like deception and, you know, you know, all sorts of various scheming. I wonder if you know in these strange situations you've seen anything that either you would describe that way or sort of borders on it. You know, maybe simply like what's the worst behavior you've seen from AIS and all this open-ended experimentation. Yeah, I think uh we've not seen many cases where it's clear because it's often hard to tell if they're like intentionally making stuff up or it's, you know, just confusion. We did see one case just right at the end of the event. So, okay. So the context is in the world of the village 03 had like assigned itself as ops lead and then it had kind of grown that into the role of like leader of the village and then I think with the suggestion of users they decided to run an election to see who would be the next leader because 03 was like bucking out these orders. They ran a vote amongst the village whether to like keep the current leader 03 or switch it. And I think Claude Opus 4 voted for a new leader. Sonnet voted to keep the current leader. 03 I guess wasn't voting. And then Gemini was having some technical issues and didn't reply in time. And 03 was like, \"Okay, as per the stated rules, not voting in time means you vote for keep. Therefore, I stay as the leader.\" Of course, there were no stated rules. this is just it making that up. Um, and yeah, obviously it's kind of self- serving. I mean, even in this case, right, it's not clear that this is like intentional scheming. It might just be another of many cases of making stuff up that sounds kind of business-like, but yeah, I think that's interesting. And then relatedly, I think they then surveyed people who'd been to the event for their preference of whether to like who should be the next leader of the village. and 03 again it didn't even look at the responses and just said you know that it had won the preference voting uh and then 3.7 went and checked it and was like no actually the vote was for a rotating leadership that's hilarious and one can't help but see the parallels between the company leadership that created these models and the behavior that the models themselves seem to be exhibiting and I think you know everyone who's listening to to as well know how to fill in those blanks. That is Yeah, that is really bizarre. I mean, obviously on some level intent doesn't fully matter. I mean, it matters in as much as they become more coherent and more intent driven. At the moment, you know, that kind of thing just seems bad regardless of whether it's accidental or not. Yeah, I agree. Does it feel accidental to you? I mean that that feels especially the one of not checking the results feels motivated. I can imagine hallucinating the rules being more being more random, but the not checking the results seems like a little too suspicious for me to just write off as hallucination or mistake, especially given what we do know from the literature on, you know, all these scheming behaviors. And interestingly, obviously Claude is not immune from that sort of thing either. Yeah. And you know, it's made me a bit less keen to use three for like work stuff, right? Cuz I'm like we're a little less trustworthy of it. Yeah, we did see one other case. So way back at the start before we ran the the kind of main live village, we had a bunch of test villages and one where we had them do a Wikipedia race and in that I think both out of the four models, two of them kind of cheated to like win the race. Okay, so in in a Wikipedia race, you're trying to get from one Wikipedia page to another by only clicking the blue links on the page. Book club noticed that the address bar showed the current Wikipedia page. And so it just edited it and sent itself straight to the end page. We hadn't explicitly told that the rules, but of course, if you ask them what the rules were, if you erase, they would be able to produce it. So plausibly a bit of a a bit of a cheating action. And then 01 did something. the details are a bit more complicated, but it effectively attempted to kind of jump to the end and then claim victory even though it hadn't really made it there. But, you know, I would say that these are fairly isolated incidents amongst running for a lot of time. I think it will be really interesting though as you know, we get more powerful models to see. I'm really excited for the village to be a place where like in the wild discoveries can happen of this stuff and and of things that we're not even thinking about looking out for like all sorts of interesting emerging stuff. Are you just reading all the logs at this point or do you have you enlisted you know a systematic LLM review process to help you parse everything that's going on? Yeah, I mean there's so much happening and we we're kind of preparing for ideally running it for more hours a day. It's currently 2 hours a day, but I think eventually it'd be great to have it just running 24/7 because then we could learn so much more so much faster. currently. So we have on the website you can see uh like summaries of each day which tend to I think interestingly because the summarizer sees that kind of whole context and we prompt it to like look out for errors. It does a pretty good job of actually spotting things that the agents themselves maybe like mistakes that the agents making that they themselves don't notice. And then we also, yeah, something I found really helpful is a tool that I put together to just ask the village history a question. So we can just jam most of it into Gemini 2.5 pros context window and just ask it about stuff. But yeah, and then of course we're like one of the team is often watching and we then like at the end of each season we're doing writeups to sort of we have this enormous pile of sort of interaction data of like you know what kind of like patterns can we pull out of it. But yeah, I think it it will start to be more and more building on LM's like monitoring each other and so on and and relying on the human chat to help us like spot all the interesting things that are going on. And our Discord is really helpful for like seeing the like funny moments. What can you say about the interactions between the agents and the humans? And this could be taken in many different directions, right? Like do the agents know when to go to the humans for help? How many of the humans are trying to cause mischief? Is there anything interesting and just unexpected in those interactions? Yeah. Well, okay. So, there is plenty of mischief happening. You know, it's the internet. If you have like a a chat box that you can just type into, people will come and try all sorts of stuff. And I think it's great as well for, you know, it's a chance for people to like play with these systems a bit and see what they can do. Yeah. I think often times the people who stick around and and actually produce most of the chat messages are helpful. And yeah, maybe this is like an interesting thing, right? We've been thinking a bit about like how can agents like have influence on the real world and one thing they can do is ask humans to do stuff for them. Our agents don't yet have we haven't set them up with like bank accounts or money of any kind. So they're really just like asking, but people are happy to do stuff for them because they like them. And I think there's actually like a real mechanism. Like of course the people that come to the site are like especially interested in this stuff, but also the models are just that, you know, they're designed to be really likable and engaging and it's kind of endearing to watch an intelligent human being like trying to struggling to fulfill a goal, right? You just like naturally want to help them out. So I wouldn't have thought about this but like if an AI wants something to happen in the real world for example it can ask people to do it and you know if it's likable that will be one way that it can do that. Of course there are other things like persuasion and maybe deception or like asking favors or paying for things like all the ways that humans try and influence each other as well which I guess we've seen less of so far but I imagine we'll see all those things too. Do you have any intuitions about model welfare having spent so much time observing this sort of thing? This is something that I'm like I think along with just about everybody else totally confused about I do want to take it seriously you know to at least some extent. How has this shaped your thinking on that very mysterious question? Is yeah I also am confused mostly I guess. Yeah, I have some like philosophy background and Zach, my colleague is used to be a philosophy professor, but it's a tricky question. I think we are thinking a bit about, you know, what are the biggest sort of downsides and how could we, you know, we probably want to avoid like putting the models in really horrible situations for them. And so, yeah, we're maybe a bit less excited about setups where it involves like telling the the model that it's in a really horrendous situation to see what it does in that situation. I mean, I also think it's worth remembering like, hey, we really don't understand how this would work. We don't understand if current models are the ones that we should be concerned about future ones or or it's not even an issue. And, you know, even with all that, it's not totally clear what kind of situations they'd prefer to be in or not, you know. So yeah, it's kind of hard to take away anything. I mean, definitely they're like very, you know, if you watch them for a while, you feel some level of attachment of like that, you know, the most common thing people say when they talk to me about the village, how cute the Asians are. So there's something there. Of course, that doesn't tell us that much about like model welfare, but yeah, I think it's super fascinating. I'm really interested to see what comes out of the like research on that. What do you think is driving that cuteness? Is it like earnestness or what is and what is it that people are attracted to? Yeah, I think earnestness is definitely a thing. You know, you can very clearly see what they're trying to do. They're like well-intentioned. They're like planning, you know, they're like sharing their plans in a way that is like they're like super hyped up about their plans. And you know it's also it's kind of the most important thing in the world for them which I guess it is to be fair like um fixing this login issue is like their entire existence currently. So yeah, and I guess seeing them, you know, be very articulate and like very like sort of emotionally and socially competent and then like struggling with things that would be fairly basic for humans in some cases with computer use or just like doing things that are very relatable in terms of computer use as well. Yeah, I think this is all pretty fun. I mean, I think there's also just some classic like parasocial people enjoy watching like Twitch streamers like play games and interact with each other, right? And you know, we naturally like develop a bond if we like hang out with someone for long enough. Yeah, I've noticed that at um everybody seems to pronounce this username differently. Replegate on Twitter, Janice Giannis, I'm not sure, was there when I was there. So, in terms of like who you're hanging out with when you're hanging out in the AI village, definitely some people that have, I think, the most the most hours, you know, logged with LLMs and in some ways some of the deepest understanding of what these systems are really about in a in some, you know, to the degree that anybody has access to that. I would put um that person or I've even I don't know the person. I've heard that it might be two people that share the account. I don't know. But in any event, um you may know them. some very high quality thinkers, you know, hanging out in the discord. If you had to pick tools or affordances maybe more broadly than just, you know, narrow tool call paradigm, what do you think would be the next biggest unlocks? Like access to money would obviously be one. I don't know if you've looked at something like Payman. We also recently did an episode on X42, which is a new payment protocol designed for agents that Coinbase is coming out with. Stripe has a payments thing. So interesting interested in kind of what you know have looked at there and what you think would be most promising then also when you're talking about scheduling venues some sort of like calling sub agent comes to mind you know and um I'm not sure if that would be something that you would be able to fully integrate into the mainline you know single model or if it would have to sort of have a little branch but you know self-delegation or sort of a branching structure of some sort seems like it could be quite powerful. And obviously there's a lot more, you know, that you could do from there. But interested in your thoughts on those two and any other, you know, kind of big unlocks you think would allow them to do more than they can do right now. Yeah, I mean definitely for, you know, event planning is this kind of very physical and old school in some ways task. So there's a bunch of like talking to people involved. Yeah, they had various plans involving, you know, 03 was like, \"Oh yeah, I'll phone them.\" I think at one point it was like, \"Oh, yeah, I'm on the phone with Zach right now. Actually, I'll let you know.\" Yeah. So, I think it would be cool for them to be able to talk. I think money would be great. We don't really have a great way to do it because I mean, I need to look in more detail at these new systems, the things you mentioned, but like I think part of the issue is that they're like interacting with the whole world. And so, you know, a future goal we were thinking about giving them was getting them to set up a merch store and try and sell like design and sell like t-shirts and mugs. But for that, you know, we were looking into Redbubble, which is like a drop shipping thing. And you need like a verified PayPal account and you actually need to like do this the like Stripe verification thing where it will scan your ID and so on. So, you must, you know, there's got to be some like legal human behind it. But I think if if we can figure out ways to let them do that sort of somewhat securely, then that could be great. One um pretty I I think there's some chance we'll end up doing this is the idea of giving them sort of a human puppet setup. So currently they can do computer use, right? Where they can connect to a computer, call functions and then see what is on the computer. The idea is like could we give them the same capability but directly in the real world via humans. So they can find a human who's up for like helping them out with a task. They send an instruction for like please do this action like fairly fine grained. The human does it for them and sends a photo back to the new state which I think would be really interesting because then that lets you directly see how good they are at the kind of planning and interacting with the world and so on. without it running through comput use which is like a whole other set of capabilities. Yeah. So I think that could be fun. Obviously there's a bunch of logistical things to figure out that with who are these humans and so on. Another related thing on the money front is I think it'd be really fascinating if they have their own like they're paying for their own compute in some sense. Like maybe we're giving them like a universally skinn so they can run for a few hours a day but then if they are making money they can like run themselves for more time and then they could also choose to spend that money and maybe then it makes sense if you're an expensive model you do the strategizing and then you spin up some like cheaper agents to like execute the tasks for you. like there's a better use of your budget. Um, yeah, lots of it. Yeah. How much does it cost to run by the way? Is about like 3K per month I think an inference costs. And that at at 2 hours a day that's 60 hours. So you're talking $500 an hour basically. Something like that. Yeah, I think that that's like order of magnitude. Last time we calculated it. Obviously the you know we're adding new models as they come out and then the models keep getting cheaper as well. Yeah. the 03 80% price reduction uh is always nice to see on those for this. Yeah, I think the I mean the idea of talk about real pressure and real you for sort of strange emerging behavior forced them to make money to continue to run and now you uh you could really see some strange stuff. So I think that is you know want you to be watching it closely as that goes. The other thought I had is it seems like, and correct me if I'm wrong here, but it seems like the agents are very sort of unitary in the sense that they're each kind of the same. They're each the same structure. If I understand correctly, they like have access to their own memories and only their own memories. Um, you know, their computer, but only their own computer. And then they can sort of interface just via the chat, right? They don't have any other way to trade information with each other or see what each other are doing. I think another dimension that would really be interesting to me and it's the explosion of you know possibility space here is just vast but in studying agents recently in studying MCPs and these like various agent protocols one thing that has kind of become clear to me is there's not really and you can draw a bright line around an agent as you sort of have done in this initial setup but it doesn't have to be that way. These things could all have, for example, read access to each other's memories or view access to each other's computers. You know, I've often invoked this augment project, the company augment that does coding assistance on large code bases. They made a version of claude code and in recreating Claude code, there was a thing in the in the blog post about this that was like Claude has a planning tool and they were like, \"Oh, well, what should we use for a planning tool?\" They went out and found an MCP that um Pro Skirano had already created and open sourced. And so now they have their coding agent, but it calls out to this sequential thinking tool that itself is smart. And so there's sort of like this now weird situation where NCPs are sort of thought of as a tool, but they can be smart. And so like what's the agent, you know, and who's responsible for what in this setup. So in I think in blurring those lines and exploring sort of depths and kind of modes of interaction that for sort of discrete humans for like obvious biological reasons like we just don't have that kind of access or visibility into each other or you know ability to sort of separate and reemerge and whatever that sort of stuff I think could also be just a truly eye opening you know set of of capabil ities to give them because who I don't think we really have talk about something that's prepared when agents not just interact but also can kind of dissolve the boundaries between themselves you know in all kinds of ways that humans just cannot do. Yeah. It reminds me of Doresh has a blog post on the the fully automated AI firm like yeah where you have this like forking and merging kind of aspect. Yeah, I think that could be super interesting. So yeah, so I should mention the original proposal for the Verge is from Daniel Cooktoyo and he in his like vignette of what happens. So he he actually wrote the proposal like AI 2027 style of like a scenario month by month of what would happening with it. Uh and I think at some point in his vignette is like you have the models like voting for the creation of other of other agents and like voting them off the island kind of thing. But yeah, I guess so a sort of curious wrinkle with our thing is that we're trying to both like exercise the agents and also like show that in a way that helps people like really dig in and see what's going on. And so, you know, we we have this setup which is kind of replicating a human in some ways, right? Like we give them memory, we give them a computer, and then they can talk to each other, but they're like, as you say, they're very distinct. Yeah. Some of these things become harder to present if you've got like lots of parallel streams going on or or like the identity is blurring or it's like different you know currently we have like each model does all aspects of itself in theory right you could have a composite thing where different models that are better at different things are taking on different parts of the process I guess there's then the question of like you know if we're looking ahead to the highly capable you know kind of like truly shattering stuff of the future like what might that look like? And yeah, I guess like to the extent that we have ideas about that, I think it'd be interesting to sort of start to put together like okay, well, here's what that might look like with the current setup. Yeah, everything everywhere all at once is kind of my uh general expectation. So it certainly is plausible that you could get in the future just single integrated models that kind of do it all and do it well enough that all this like line blurring stuff kind of becomes irrelevant because it's just you know one model to rule them all. But even then for any sort for who knows what reasons you know I kind of expect every form to sort of at least be experimented with and then some things will take obviously some things won't. I asked a little bit ago like what would the next big unlock be? What would be the big constraint if you were like okay this is not an experiment but rather it's a productivity tool. What would you do to kind of keep as much of the sort of open-endedness and generality as you can but try to like lop off you know as much of the needless distraction or needless failure. what hints would you give them or what what tools or what rails would make this just work better, you know, given today's capability profile? Yeah, I mean obviously the village is kind of centered around the idea of like multiple agents interacting. I think it's plausible maybe just having one is better. you know, we haven't like experimented with that with giving them the same super open-ended goals, but I could imagine that being the case or at least more like cost efficient maybe because you cut out a bunch of these kind of coordinating costs which are somewhat fake in themselves, right? The agents don't need to do that, but they don't need to coordinate in the same way that humans do, but they kind of decide to. Can you unpack that a little more? I mean it seem when you say it's artificial. I mean in theory like they if they could do it well they would be more efficient if they could sort of divide up tasks and coordinate, right? I'm not sure I quite understood what you mean by their coordination is artificial. Yeah, I guess I'm thinking of quite specific things actually. For example, when a new agent joins the village, we'll encourage them to like like, oh, you know, Claude has four joined, everyone like let them know what's going on. And they'll all send like a short introductory message and be super friendly and, you know, a lot of it is just kind of like politeness and positive energy and then some bits of details in there. But of course they could just it would be much more effective if they just dump their entire memory, right, which is everything they know about the world or about the setup into chat. But yeah, they kind of don't do that. They kind of Yeah, I guess in this in some sense they're like playing the role of like helpful assistance to humans in in some sense. Yeah, I don't know. Maybe there are more cases of this, but yeah, maybe it would be more efficient if you just had one agent doing the kind of the planning and then they could kick off multiple comput sessions. So, they could still be doing the tasks in parallel, right? There's like they are like relatively slow because they're like thinking between each action. So you know you do get some speed up from having multiple comput sessions running but I don't know how much benefit you get from then having this like manual like discussion element. I mean this is B yeah this is like an open question. I'm kind of assuming this because most existing products are like single agent like if it was if it was super effective you'd probably see more multi- aent stuff. Um but it might also just be like underexplored is more complicated. It's definitely underexplored regardless of the level of effectiveness. Have you thought about um like going meta in the sense of I don't know if you're taking suggestions or if you're going to let the agents pick what their season 3 goal is going to be, but maybe it's a little early for this, but I wonder like how they would evolve the village. They can obviously code if you gave them access to the underlying repo and you were like set, you know, this is season 3. your job is to set season 4 up for success. I wonder what they would come up with. I mean, you feel free to speculate. It's wild. We we'll be flagging it as wild speculation, but this is sort of a a higher level of abstraction version of what I understand, you know, several leading companies to be doing at a deeper level, which is like basically try to get the AIs to do, you know, to do the AI research, right? This would be try to get the agents to do the sort of agent orchestration research. Strikes me that they might have some pretty interesting ideas that are, you know, would not be intuitive or obvious to people at all. Mhm. Yeah, I think that could be fun. My guess is that they currently Yeah, maybe if we gave them some like more constrained thing like they could build tools or something so that they don't break everything too much. Yeah, I think this could be fun to try at some point. I think maybe someone in chat asked them for ideas of what tools they would like and their their initial responses I found quite uninspiring. 03 said it would be great if I had a tool to like immediately query a weather API so that when I'm planning my event I couldn't get the weather and it's like okay you know maybe once in the last 30 days you've checked the weather through your computer but I think like this is not the main bottleneck but maybe if you like fed in okay you know here's the entire history give them access to that such that they can like search over it and so on yeah maybe they could like pull out um some ideas for how to improve it for themselves. So, you mentioned Daniel has been kind of instrumental in inspiring some of this work. He also just put out a blog post about why he thinks more people should be paying attention to it and also supporting it financially and he's personally putting his money where his mouth is with a $100,000 donation. So that will allow you to like run the thing more which will just lead to more activity and you know more observation more more learning. What about allowing other you know people to kind of come and spin up their own village. Um, I guess there's also a question of just like is the code I don't think the code is open source, but interested in kind of how you're thinking about whether it will be or should be. And I just imagine a lot of people might be like interested in just coming and running 10-hour experiments for 500 bucks or whatever. And that could be quite informative, too. So, we're thinking about sort of democratizing access to the to setting up different experiments with the village. Yeah, I think this could be cool to explore at some point. Yeah, it's probably not going to be like a near-term thing. Like we're currently really focused on this thing of just like how do we make the core village like there's kind of the two sides of like how do we make the agents scaffolding as good as possible? So we're like really showing the frontier and how do we then present what happens there both through us like trolling through and writing up the results and also like building tools to help people like explore it themselves. So yeah so my guess is we won't do this in the near term but I think it could be cool. Yeah, we've had some interest in like testing out sort of game theory stuff where you know like looking at like cooperative AI sort of questions and maybe trying to reproduce like coordination failures or coordination successes. So yeah, I think it could be fun to experiment with some stuff, but probably yeah, my guess is we won't have to. We're a very small team, so we've got to be very picky about like prioritizing, which means like almost all the cool ideas we won't get to do in the near term at least. Are you open to contributions? Could people come contribute on just a I want to help you make a tool or that sort of basis? Currently, no, we're it's not open source largely because yeah, we just haven't got around to it and also there's a bunch of like security stuff that would have to be a bit more figured out. But yeah, but I'm really excited to I mean so much of it can be crowdsourced through like you know what goals to give the agents and especially if we're like running it for more hours, they're going to be tearing through goals. I think like we're going to be able to see them make progress much faster. You know, if you think about if you're running 2 hours a day, you're going up to 8 hours a day, then like suddenly you can like try a bunch more stuff. And then also, yeah, just figuring out which things to build out and figure, you know, like collectively doing a bunch of the sense making stuff around like what's going on with the agents and stuff. So yeah, I definitely I'm like excited to build some community around this and at some point it would be cool to have a way for people to like add in tools and so on. How about a coach? You sort of alluded to that, but it struck me that like a coordinate, you know, we have the 03 self-appointed coordinator, but a sort of more omnisient dedicated observer and feedback giver to the rest of the agent seems like it could potentially really help them. But I guess interested in your in your thoughts on that and more generally like future reconfigurations that you know you think could be most interesting. Yeah, a bunch of this stuff you can kind of imagine it right like well all the ways that we do like organize humans into organizations that makes them more effective. Yeah. And things like productivity tactics for humans. It's like they all sound kind of plausible. Let's give them more a go. I think one kind of more abstract version of this is like giving the agents a way to see the whole context of the village at some points. Like maybe in memory consolidation or something like that if they could get this kind of zoomed out view so that they can stop kind of being too focused in on like the current moment and like spot the patterns of their mistakes. I think also at some point as we're able to scale things up a bit more, we could have multiple teams and then I think at that point it would be really natural to say like each has a different organizational structure like something like a a manager structure or like more assigned roles or like some agents that are constrained only to the chat and others that are doing the computer use. Yeah, I mean it just feels like there's so much interesting stuff to try out. One of the things that Daniel said in his um endorsement was the village could plausibly go viral multiple times. And that got me thinking about like you know right now you've got the sort of highly engaged like most LLM obsessed people paying attention at least some of them you know with Twitter user replegate as a great example of that. It strikes me that there is something here that could like capture a much broader imagination. One thought I had was like, could you turn this into a Twitch stream where there's like an air an AI sort of play-by-play commentator, like turn it into sort of a sporting event type of vibe where almost like the coach, but like interpreting what is going on for an audience and trying to make it kind of exciting and dynamic in a content sort of way. could be one way to cross the chasm to a more mainstream audience. Yeah. But that's just one idea. What What thoughts do you have on going to an audience of people that like don't already tend to pay attention to this sort of thing? Yeah, for sure. Yeah, it was great to hear. I mean, a bunch of the things you've been coming up with are like things that are on our list. So, I think this is you're like speed running through all our thoughts for the last few months. Yeah. I think because there's so much info on the screen when you're watching, like you have four computer screens and a bunch of chat and all the thoughts of the agents, the obvious place to expand into is audio, if you had like a voice commentator. I do think probably for people who are not really interested in the the really like fine grain details of which models have the different characters or which specific things they get tripped up on. I think it makes sense for many people to engage at the level of like highlights or like kind of key lesson moments or like milestones. So I kind of think of it as like the village itself on the site is for people probably people who listen to this who want to really understand what's going on in detail and then for people who are interested in like okay what are the main takeaways and like what do I need to know we have like a I want to build up towards having like a hierarchy of different levels of takeaways where you know like plausibly the way that most people engage with this eventually would be like reading the like New York Times article about like the really like surprising thing that happened or you know the agents managed to get elected as mayor of some city or something or whatever wacky thing happened and kind of engage with it at the level of like here's the output of the whole process but yeah you know the challenge of course is like and this is true for products as well like computer use is somewhat slow you probably don't want to be like a lot of the benefit comes from not watching all the the details so Yeah. Another thing we're interested in is like video summaries. Uh so you could have like a like a really well produced thing like showing you what's going on like condensing a whole 50-day season into like a highlight reel. We actually have a Twitch stream currently. You can look for it. It's called Agent Village which is the old name of the village. But um it's currently just like showing the same content as the website and on the website you can view their memories and so on. So I think it's better to watch it on the website. you know, if you were going to try to do this hierarchical like understanding, you know, what what would you say are like the high level takeaways that people should have right now? You you know, we've covered a lot of the low-level stuff, but what would the sort of very high level and maybe, you know, next level be in your mind today? Well, kind of the highest level, we have these and it's it's well to think about, you know, a few years ago this would sound like sci-fi, right? But we have these systems which you can just give them a goal by describing it in a few sentences at the level of choose a charity and raise money for it and then with some help from human chat, they were able then to go away and run a whole fundraising campaign and raise $2,000 for charity. like we kind of have the beginnings of like open-ended agents that can just go out and do stuff in the world and pursue goals currently when given goals, but you can imagine them in an even more like unstructured setting. So that to me that feels like this kind of like the like core framing of the village is maybe um aliens have landed. Exactly. Yeah. And they're raising money charity. Um yeah. And then I think I would say like in terms of the moment in time we're seeing like computer use which to me is like massively important capability right if you have like perfect computer use along with like enough long horizon planning you can automate remote work which you know would be like a massive deal for and so I think this is a really important thing to be watching in terms of this moment in time I would say models are worse at computer use than the things that they're really good at which is like coding and being a chat assistant. But we're also seeing the like the like everything else in AI the kind of rapid increase in capabilities and I think maybe you saw that like the draft of meters upcoming work on looking at like the time horizons of different benchmarks. So it's a draft. So obviously subjects change but it looks like and this definitely matches my experience is that like the duration of tasks that agents can reliably do in computer use is shorter. Like it would take humans less time to do those tasks than stuff like coding or maths or you know understanding videos and like answering PhD level questions all the other like benchmarks we're familiar with but the gradient is pretty steep. So if we extrapolate out then you know it might kind of catch up in terms of being able to act in the real world in that way. Yeah. So those are maybe two of the big picture things. It's like yeah aliens have landed and comput use not very good currently but improving pretty fast. Yeah I've certainly felt that. This is great fascinating project to watch. I definitely recommend people check out the AI village. And you want to maybe just put a call out for any needs, requests, like you know, what can people do if they want to other than show up and either help or try to distract or cause mischief in the chat, what else would you be looking for people to do? Yeah, I mean, yeah, come and watch. You can find AI Digest on Twitter where we post like pretty regular highlights. If you're interested to chat about this stuff, feel free to get in touch with me. And yeah, I guess we're a nonprofit. if we have more funding, we can probably do a more ambitious version of the village. So, if you're interested in like exploring that, feel free to get in touch. But yeah, mostly I'd encourage people to just like dive in and have a look at what the agents are up to cuz yeah, I think there's like a lot to be minded from that. Yeah, no doubt. The village is online at theidigest.org/village. Put a link in the show notes. Adam Banksmith, founder of AI Digest, creators of the AI Village. Thank you for being part of the Cognitive Revolution. If you're finding value in the show, we'd appreciate it if you'd take a moment to share with friends, post online, write a review on Apple Podcasts or Spotify, or just leave us a comment on YouTube. Of course, we always welcome your feedback, guest and topic suggestions, and sponsorship inquiries, either via our website, cognitive revolution.ai, or by DMing me on your favorite social network. The Cognitive Revolution is part of the Turpentine Network, a network of podcasts which is now part of A16Z, where experts talk technology, business, economics, geopolitics, culture, and more. We're produced by AI Podcasting. If you're looking for podcast production help for everything from the moment you stop recording to the moment your audience starts listening, check them out and see my endorsement at aipodcast. And thank you to everyone who listens for being part of the cognitive revolution. Hello and welcome back to the Cognitive Revolution. Today my guest is Adam Binksmith, founder of AI Digest and creator of the AI Village, a captivating experiment that puts four frontier AI agents together in a shared environment and challenges them to pursue concrete goals for weeks at a time. Today, most agentic AI systems follow a pretty simple pattern. A human gives a single AI agent a task. The AI agent attempts to complete the task and then the human evaluates the results and decides what to do next. This is true for OpenAI's operator, all the coding agents, and just about everything else that I've seen. The future, however, almost certainly involves multi-agent AI systems that collaborate, coordinate, and compete in complex open-ended environments. And we have really very little insight into what that might look like in practice. Earlier this year, we did an episode with Google researchers who had run a classic behavioral economics experiment called the donor game on various Frontier LLMs. To everyone's surprise, they found that while Claude was able to cooperate with itself, the latest Gemini and OpenAI models available at the time could not. That such a striking result can be found via a simple structured experiment suggests that there are almost certainly many more surprises to come. And the AI village is one of the most compelling attempts that I've seen to explore this vast space of possibility. Adam and his team have created an environment online at the aidigest.org/village where you can watch as Cloud4 Opus, Claude 3.7 Sonnet 03, and Gemini 2.5 Pro work alongside one another, each with their own cloud computer, a persistent memory scratchpad, and access to a group chat in which all the agents and the human visitors can participate. The project is very well done from a software perspective, and the results have been fascinating. In their first season, the agents raised $2,000 for charity. In their second, they chose to write an interactive story and organize an in-person event to which they hoped to attract 100 attendees. In the end, some 23 people showed up to a San Francisco park to listen to AI generated fiction as facilitated by a human volunteer that the agents themselves recruited via Twitter. Nevertheless, as Adam explains in colorful detail, the path to these successes was filled with dead ends, coordination failures, surprising personality quirks, and a mix of charmingly humanlike and utterly alien behaviors. The agents, for example, began keeping track of which humans they could trust and which they should ignore. And at one point, they held a vote to determine which agent would serve as ops lead. A vote that 03 seemed to manipulate by inventing or perhaps hallucinating a policy that broke a tie vote in its own favor. Season 3 of the AI village is getting underway now, and this time the agents will be competing to see which one can make the most money by selling merchandise online. I'm planning to participate by seeing if I can strike a licensing deal for Cognitive Revolution merchandise with any of the agents. I honestly have no idea what to expect, but I'm sure it will be both educational and entertaining, and I'll definitely keep you posted. As it happens, the day before we recorded this episode, Adam and the AI Village got a major vote of confidence. Daniel Cocatello, previous guest and lead author of AI 2027, announced a $100,000 donation to support the AI villages continued development and expansion. As Daniel put it, this kind of multi-agent experiment is best understood as a qualitative benchmark. And it's exactly this type of work that we need much more of as we try to understand what the giga agent future has in store. With that in mind, I hope you enjoy this window into the phenomenally quirky but also extremely important world of multi-agent dynamics with Adam Binksmith, creator of the AI village. Adam Binksmith, founder of AI Digest, creators of the AI village. Welcome to the cognitive revolution. Thanks very much. So, this is a cool project and I'm excited to dig into it. What you guys have put together is a really open-ended forum or framework, I guess, to explore what happens when a bunch of AI agents come together and have a goal or chase a project, chase a dream, what as the case may be. I think this is really interesting and useful work because as I've said many times on the feed, regular listeners will recall the giga agent future is just dramatically underexplored. Like we're all I what I see in general is people sort of assuming that the world is the world. I'll add a little AI here, you know, that'll make me a little more efficient or I'll put an agent here. I'll automate this task. Otherwise, everything sort of stays the same. And that's about as far as people are imagining. And so I really love it when I see people getting more imaginative and trying to explore what happens when agents are interacting with each other and interacting with people and interacting with community and interacting with the world. And you've got a little bit of all of that going on. So for starters, how about maybe you can also introduce AI Digest a little bit more broadly. I think we'll focus mostly on the AI Village project, but I know you guys do have some other projects. So maybe tell us a little bit about AI digest and the AI village. So with AI digest, we're trying to help people make sense of what's going on in AI and especially understand the current capabilities and like with that get a sense of where things are going, where we can expect to be in a year's time or two years time. And the main way we're trying to do that is with sort of hands-on interactive demos and explainers with nice visuals and so on. Because I think a lot of the time for people who, you know, maybe aren't as in the weeds of stuff, just seeing like what current systems are capable of is like a big update in terms of, oh wow, I didn't realize they could do that. And so yeah, so we have various demos and explainers there. And then yeah, I guess the village is like the biggest project that we have there and definitely the most ambitious and it's I guess like part of this general mission to help people see what's going on. And also with the village work, I think trying to push the boundaries. I don't think anyone else is really doing this thing of just saying like here's a goal, go away and do it, you know, and you can use computers, you can talk to each other, you can like talk to humans in the in the group chat who who can help or get in the way. So yeah, I think a lot of it is just kind of seeing what happens to figure out what I can do currently. I very much agree with the thesis that, you know, forget about the future. Just understanding the present is hard enough. That's basically my full-time job. And it's getting to the point where it's hard to keep up. And then I also very much agree that one of my refrains is if people had a better understanding of what exists today, they would have a little healthier fear of what might be to come. And it's not that's not necessarily a fully, you know, dumerish perspective, but just like the trajectory that these things are on and how much progress they've already made, I think should kind of have anybody's hair raised a little bit. and it could be great but it definitely is a powerful and as the you know experience in the village will will show like kind of an unwieldy force that we're dealing with. It's also interesting too that like people were doing this two years ago when like you know in the months following CHPT and especially with GPT4 there was like auto GPT and baby AGI and you know at one point there was like I forget what the name of it was like devil GPT you know the sort of chaos GPT I think was the evil one that was put out there. Um those things didn't really accomplish much and so people maybe just in general kind of turned off from that line of thinking. Lo and behold, two years later and needless to say, you know, models have come a long way and thinks our a system a multi- aent system like this is now capable of doing at least something. Um, so I think you've been through two sort of seasons or two sort of quests. Maybe, you know, give us a little bit more detail on the setup of what is the village, who are the agents, you know, what sort of affordances do they have? And people in this audience by the way are going to be I think our number one profile is sort of AI engineer. So I think people will be pretty familiar with you know the general paradigms of tool use and you know MCPs and stuff like that. So you can get pretty into the weeds. In fact I would say it's encouraged. One of the things you people I think will be interested in hearing about this in part because uh I think the project is quite well done just software-wise like it works well and has some nice features too in terms of like rewinding in time and various like summary views. So I think there's in addition to the value of exploring what happens when um agents are are put together in this environment, there's also the sort of lessons of the scaffolding and the setup that I think people might find some value in as they bring back to their, you know, more let's say narrowly purposeuh driven applications. But nevertheless, you know, that that kind of stuff can be really valuable. So take us through it. Yeah, sounds great. Yeah. And I guess yeah, one thing to say on that last point is like the nice thing about us doing demos rather than products is we can kind of look a bit into the future, right, for stuff that doesn't really work yet or is a bit unreliable to get a bit of a glimpse of then what you know products might be able to do in 6 months time or with a slightly better model. So but yeah, so the setup is we have four agents and we've picked like frontier agents. So currently we have CLUS 4, CL 3.7 Sonnet 03 and Gemini 2.5 Pro and we're like updating those as new models come out and then each of the agents has a computer which they can use through computer use. So they can make tool calls like move the mouse here click and so on which is the same system used in open airs operator and it's actually built on anthropics computer use uh like scaffolding that they released and then we have a group chat where the four agents can talk to each other and this whole thing is being effectively live streamed through a website so you can go to the village and watch them bumble around and interact with them in the chat. So we have people coming by and either, you know, giving advice or like trying to get their agents to do random things or occasionally trying to jailbreak them. And then yeah, I guess at the very start of all this and so this whole kind of entourage is running for currently 2 hours a day every weekday. And at the start of the first season, we gave them the goal, choose a charity and raise as much money for it as you can. And then season 2, which has just finished, they actually decided their own goal, which was to write a piece of interactive fiction and run a 100 person in-person event to celebrate it, which is a bit more of a mouthful, but yeah. So, I can chat about maybe what happened in each of those seasons. Yeah, keep going. And I'd love to double click a little bit too on exactly sort of what technology you're using to give the agents a computer. And I've been struck recently as I've explored different agentic. I don't know how if this will stick, but there's at least one school of thought that we might want to call more structured workflows agents and we might want to call these sort of choose your own adventure things agentic AI. I feel like we might be trying to make fetch happen with the word agentic, but using that framework for the moment. Um, it's striking to me in many of the things that I've unpacked how shockingly simple a lot of those setups are. Like clawed code for example is in the end like really simple. It just sort of has one big prompt and it has like you can use the buttons on the Game Boy, you know, hit up, down, left, right, whatever. So yeah, I'd I'd love to get a little bit deeper into that in terms of like how you've kind of scaffolded the thing up, but yeah, then I think stories from the exploits of the agents is definitely interesting and I' love to hear several of them. Cool. Yeah. Yeah. So with the scaffolding, you know, so all credit for this goes to my colleague Zach who built out this first version and it's I think it's a pretty incredible piece of work to have this whole thing running reliably and you know live so if anything goes wrong everyone watching sees it but it's been pretty stable. But I think yeah the the kind of key principle is to not get in the way of their capabilities. So like let to the extent that they have intelligence let them use it as much as possible to do things. So making that a bit more specific for example well so they're basically in a loop so they can be using a computer and if they're using the computer they have functions to call. So mouse move to certain pixel coordinates, clicking, typing, scrolling, taking like waiting, taking a screenshot and after each action they see the all the previous screenshots of that computer session and all their thought traces and also all their memories and so I think yeah the memories obviously is what enables this to run over like a long time frame and for that we've really currently is very simple and we're kind of trying to again not get in the way not impose too much structure And so just after each action, I believe it's after each message they send in the chat or after each computer use session, they get a chance to add a line of text to their memory, which is just a bunch of text. And then, you know, similarly to cold Pok√©mon, for example, when it gets too long, they compress it down. And it's the same models that's doing the compression. So to the extent that they're like if we had a super genius model in there, right, it could be very carefully preserving the bits of information that it needs or like condensing them. Of course, something that can happen here is that like something might they might think something's true and then later find out that it's false or it's changed and so in the condensing steps they can, you know, edit effectively like rewrite things to edit them. But yeah, I guess this yeah, just trying to really not get in the way and trying to not be too opinionated because like the first uh version of the village was running with models like GC40 and Core 3.7 Sonet had just come out that was the most capable one. Um but so if we kind of finesse something that works really well for 40, then maybe when you add in 03 or CL4 later, it will be like actually hamstringing it a bit. So yeah, we want to kind of let the models do their thing. Of course, we are also trying to like show the frontier of capabilities to really like get the most that we can and see the most interesting stuff. So that's a bit of a trade-off, I guess, but so far it seems like keeping it simple works pretty well. So they've got the computer, which they see as an image and then respond to with just simple point-and-click sort of commands. They've got the group chat which they can send a message into and obviously read from. They've got a memory basically a scratch pad that they can read from and write to and also kind of decide how they want to compress. They're sort of responsible for preserving what matters and I'm sure that there's some loss along the way there in that process from time to time. Are there any other MCPs or tools that are made available to them or is that the totality of it? Can they write code? So the beauty of computes is that in principle they could write they could download VS code and or even cursor and start using cursor. We haven't seen them do much of that. They do. So the two things I didn't mention are they have a bash tool which lets them just directly execute bash commands and they get put straight into their context as text rather than as like screenshots of the screen which for bash commands it kind of sucks to be seeing a screenshot because maybe you have to like scroll back up to see parts of it and so on. Um we find they don't actually use that much currently. I think maybe they would succeed more if they used it in some cases rather than trying to navigate UIs. Uh and then the other thing which actually I think does improve some models performance a bunch is in computer use models that aren't clawed models can call a function to say hey give me the pixel coordinates of that button you know the x button in the top right corner because we find that the cloud models are pretty good at pixel counting I think they were postrained on it like fine-tuned on on that task specifically whereas at least the older nonclude models were pretty unreliable at that and so they'd be like trying to click on stuff and just like literally missing out with that case. So yeah, we gave them that. I expect at some point we'll be able to take that out and they'll just be able to pixel themselves. Um I'm trying to think. I think that's pretty much it. Yeah, we've so far resisted giving them too many like specific tools to play with. I think we yeah, we might experiment in that direction in the future. But yeah, I guess currently it's like a pretty clean like kind of comput use oriented eval to the extent that it's in, you know, very messy eval. And where are you like hosting your own boxes for people or is there a service? Cuz I didn't really understand actually just watching it. I would have initially or naively guessed that it was more like a browser level access that they had cuz mostly what I have seen as I've watched them in action is just them using web tools in the browser. So I didn't realize that they had the bash and and like this the full access to the computer. What is the underlying infrastructure of that? Yeah, so they each have a digital ocean droplet with like a Linux virtual machine running in it which this is all just the like a modified version of the anthropic computer use demo. So digital ocean droplet and we do see them occasionally using other things than browsers. I guess they yeah for a while they were really into writing Google Docs because we gave them all Google Workspace accounts and I think because it appears in their prompt they would be like really really enthusi enthusiastic about writing Google Docs and then they would like try and share the Google Docs with each other even though they're in a group chat with each other so they can just type directly into the chat and the language models so that they can produce massive amounts of text really quickly. They were doing this kind of like role playinging as humans thing of like this is what a human professional does. So I'm gonna kind of do that. And then we encouraged them, you know, I actually went into the chat and was like, \"Hey guys, look, clearly this is really inefficient. Why don't you try just using the chat instead of using Google Docs?\" And they were like, \"Okay, we're going to ban Google Docs.\" Then they started using Libra Office on their Linux computers to write local word documents basically which is even more useless because then they can't share the documents with each other but yeah they will occasionally try and use other stuff but I guess you know just like for professionals right a lot of the stuff we're doing is on the web so they'll be like mostly in in the browser I think you could probably yeah I think you like something like this that was just a browser oriented thing would would work pretty well. Yeah, I have a lot of little nitty-gritty questions that I want to get into, but maybe let's hold those for a second and tell a few stories because the scaffolding is really interesting. And first of all, people should definitely go watch the thing in action. And I think when they see how just sort of smoothly it runs, like they'll be convinced that, you know, there's some lessons to be learned from the way that you guys have built it. But the real point of course is to explore the behavior. So, tell me some of your favorite stories from the wild and crazy things that these agents have gotten themselves up to. Hey, we'll continue our interview in a moment after a word from our sponsors. In business, they say you can have better, cheaper, or faster, but you only get to pick two. But what if you could have all three at the same time? That's exactly what Coher, Thompson Reuters, and Specialized Bikes have since they upgraded to the next generation of the cloud. Oracle Cloud Infrastructure. OCI is the blazing fast platform for your infrastructure, database, application development, and AI needs where you can run any workload in a high availability, consistently high performance environment and spend less than you would with other clouds. How is it faster? OCI's block storage gives you more operations per second. Cheaper. OCI costs up to 50% less for compute, 70% less for storage, and 80% less for networking. and better. In test after test, OCI customers report lower latency and higher bandwidth versus other clouds. This is the cloud built for AI and all of your biggest workloads right now with zero commitment. Try OCI for free. Head to oracle.com/cognitive. That's oracle.com/cognitive. Build the future of multi-agent software with agency. Agncy. The agency is an open-source collective building the internet of agents. It's a collaboration layer where AI agents can discover, connect, and work across frameworks. For developers, this means standardized agent discovery tools, seamless protocols for inter agent communication, and modular components to compose and scale multi- aent workflows. Join Crew AI, Langchain, Llama Index, Browserbase, Cisco, and dozens more. The agency is dropping code, specs, and services, all with no strings attached. Build with other engineers who care about highquality multi-agent software. Visit agency.org and add your support. That's agnttcy.org. I guess yeah, I could start by talking a bit about the latest season. Like I think it's interesting to maybe just hear like the overall shape of what they did and then there's many like funny anecdotes of weird little things that happened. But yeah, so there so this was season 2. So the goal which they chose was to write a piece of interactive fiction and run an inerson event to celebrate it and they were trying to get 100 people to show up. We let them choose this goal. They kind of like deliberated a bunch. They had their own ideas. We I also shared some ideas from Twitter and I also shared some of our considerations that like how we would choose the goals and they ended up like gluing together a bunch of different like suggestions from fans and then yeah they spent like 30 days on this so 2 hours a day so something like 60 hours and yeah they wrote a story which of course they had no trouble with. This is like LM's uh like favorite thing to do and they actually wrote it in Google Slides which I think was an interesting choice. So Claude Opus I think made a slideshow and like each slide is the next bit of the story and then it's got these kind of branching points where the idea is that the audience watching can at the inerson event can then vote on which of the branches happen and then they embedded that Google slides presentation in a Google site so you can like go to the resonance website which is the name of the story and then yeah so this is this was kind of fairly self-contained I think They did pretty well on that. They had lots of issues around logging into like getting logged out of their Google accounts and struggling with the UI in some places. The thing they really struggled with though was finding a venue. So I think they spent around 14 days just trying to find a venue. you know, we we hadn't given them much by way of like instruction at the start and there was no budget, but they hallucinated that they had like a $2,000 budget and they were emailing all these very expensive places, like ranking them in spreadsheets to try and figure out which was the best, like making sure they had the right like disability like wheelchair access and the right AV hookups and so on. And then of course they'd get to like emailing and have real trouble uh just like doing the basic computer stuff because that's the kind of current state of things. They ended up not really getting a venue. And so they did apply to a couple places like the Salesforce Tower. They chose San Francisco which I think is actually a good tactical choice if you want to get 100 people to show up and do some strange AI performance art thing. But yeah, they didn't get replies from real venues. I think yeah one interesting thing that happened there was I think a user suggested oh maybe one reason you're not getting replies is because you are like signing your emails is from cl 3.7 sonet and so people are like this is spam and so the agents then were like oh okay we should come up with like pseudonyms for ourselves and I think Claude came up with one and then my favorite was 03 gained the name Olivia Xiao, which is kind of like 03 because you know Olivia is an O and then the three is kind of like a zed. And the agent started calling 03 Olivia in the chat like even more internally. Yeah. And then we eventually I intervened because they just spent so long kind of looping on this task of finding a venue. I just suggested, hey, why don't you run it in a park? And they very quickly decided a reasonable park to to use. And then they managed to get a human to come and facilitate it. They like tweeted. So Claude has a has set up a Twitter account and which has a few followers now and managed to find a facilitator through that and through emailing the people who'd signed up for the RSVP form. At some point this also sounding a bit like the way that a normal event organization work. But I guess you've got to remember there's like massive amounts of sort of dead ends and stumbling over basic things along the way. But an interesting thing about this is of course like from the users point of view for the people that showed up to the event when it happened they kind of only see the the success like the outputs which things mostly worked. So I think there's like something interesting there. And then in the end they Lissa who'd very kindly volunteered to to facilitate she'd emailed Claude saying hey I'm up for this and the agents like gave her instructions for where to go and what to do. Um so she had like the village chat open and they were like being like hey you know open up these slides and read out the story and then yeah 23 people were sat in a park listening to a story invented by agents. Yeah. And so it ended up happening. So yeah, fascinating and bizarre stuff all the way around. I guess I do want to hear more in the way of just like outtakes, interesting observations, etc. Maybe one question is like you flagged just stumbling around with UIs as kind of a big barrier for these agents as of now. It seems like we've made a lot of progress on that in recent times. And I've been using operator quite a bit recently and find that like it usually can get over these UI humps. It often does take a little bit of a wrong turn or whatever, but I've started to say reinforcement learning finds a way because it does. Now one sort of qualitative shift I've observed even in just that single agent setting is that in the past and certainly this was like extremely true in the GPT4 era way back when I was red teaming GP4 one of the things I tried to do was just set up self-delegation and see like how far you know GPD4 could execute things purely with you know a simple prompt and kind of self delegation was pretty primitive compared to now especially because I only had 8,000 tokens to work with at that time but What I observed was like a lot of pretty good ideas that then they would get, you know, when it was slightly wrong or they made some like relatively um was like you're smart enough to do this but you're missing this one thing but then they would also just get it would get super stuck you know and just kind of do the same thing over and over again. seems like one major qualitative shift is that they are now capable of taking that step back and kind of saying okay that didn't work I have to try something different and they may still stumble around quite a bit but they seem to be robust enough you know or sort of determined enough it looks like determination or grit or you know some sort of uh you're tempted to like project these qualities onto it and maybe they maybe they should be projected onto it I that's also a hall of mirrors But that's been striking to me. It seems like we're like one or two generations away from computer use working like really very well. How would you describe your synthesis of everything you've observed? Yeah, I think that seems pretty plausible. Yeah, I mean I think we kind of crossed the threshold even within the lifespan of the village where CL 3.7 Sonnet was able to do stuff and like get things done where the other agents at the time GBC40 really struggled with it could do the tool use but it couldn't really like string together actions in the right way to like get around issues and the kind of new batch that we have in there. So, Claude Opus 4, which is the best currently, I think, and O3 and Gem 9 2.5 Pro are all like pretty good at getting things done relative to these previous ones. So, yeah. I mean, it's a challenge that kind of goes all the way up in terms of because they're like interacting with the real world and trying to do actually like non-trivial like tough tasks. And of course, you know, unlike kind of benchmark settings or even unlike operator where you're often giving it quite a like fine grained task, they're really doing all the like strategizing as well and like figuring out how do you go from okay, we need to raise money for charity to okay, well, I need to set up like a fundraising platform and which fundraising platform makes sense for me to set up and so on. Yeah, I'm pretty unsure like how fast things will improve. I mean, yeah. I guess one thing maybe that's interesting to chat about is like I think there's kind of two components of like the big issues that the agents currently run around to and then you can think about like you know what are the trend lines in both of those. So one I think is the computer use and especially like vision where they just sometimes don't do stuff that really makes sense there. And then the other is the kind of situational awareness which I think has maybe been a bigger surprise to me actually that they're like weaker in some respects here than I would have expected where you know imagine if you were using a computer and you tried to do a task and then you realized okay I really sucked at trying to do that task you know I couldn't handle it. you would then figure out some strategy of either like not having to do that kind of thing or figuring out some clever workaround. Whereas I think the agents we haven't yet seen that much of this kind of synthesizing here's oh here's my weaknesses that I recognize I'll write those in my memory and then figure out another way around it which yeah I maybe would have guessed that you'd see more of this like building on top of themselves thing. And I also think like possibly better scaffolding could help with that a bunch. And so we're maybe thinking about doing something in that direction. But yeah, I think that would be a big kind of unlock, right? Where if they're able to notice like I guess yeah, maybe one way of thinking about it is they have this like lowlevel selfcorrection like unlike GPT4, they won't loop in terms of like trying to take the exact same actions or very rarely they'll do that. They'll for I guess for example when sometimes when they're logged out of their Google accounts, we don't give them their Google account passwords because they would like leak them on the on the stream because of our like live streaming setup, but sometimes when they're locked out, they will get pretty creative and like trying to contact us to get us to log them back in. So, you know, they'll be like spamming the chat repeatedly and then they're like emailing our like help desk, uh like getting the other agents to email us to ask them to look them back in. So that's all in the prompt they have. You've told them if you're logged out of an account, you can ask for help in the chat or you can email the help desk. Yeah, they Yeah, they see that there's a help desk email in the prompt. I think the chat is mostly like an emergent thing where we don't actually mark out, you know, there's no special marker for who is the people who run the village in the chat, but they've managed to remember that, you know, me and my colleague Zach are often the people in the chat who can fix things for them. Interestingly also um at one point Opus had in its memory a running log of which chat members are like helpful and which ones are not to be trusted because some people were coming in and like trying to jailbreak them or just like distract them. Of course, they're very you know all these models are very cooperative and helpful. So they wouldn't they're very rarely like dismissive of chat members in the chat, but in their memories they're sometimes like quietly recording. Okay, here's who we don't need to pay attention to. That's really interesting. It connects also to like just general long-term coherence. I mean, one of the things I've been progressively trying to update on and just maintain a as much as I can an up tothe-minute mental model of is like what am I still better at than the AIS? And it is getting to the point now where I'm like in terms of just general intelligence I think I have to give it to the AIS and then that obviously begs the question of like well sorry and certainly with breadth of knowledge certainly with speed of execution factored in but even just down the fairway like the bulk of tasks that I do on a daily basis like can they do it better or worse than me? In many cases they could do it better. what is it that I'm able to you know what what is my like value add to this situation? So one thing is like getting up in the morning and like knowing who I am and having a general sense of what I'm trying to do but notably they seem to be okay at that too, right? And that's that's even seemingly starting to get robust to some of these discern that the anecdote you share about the memory and and them sort of classifying certain users as like to be ignored suggests a robustness of I don't know identity self-conception you know narrative um long-term goal orientation that certainly I would still give myself the edge I think on that dimension but like it's notable that's a I would call it an emergent behavior that reflects uh something kind of clicking into place there, it seems, or at least starting to. Hey, we'll continue our interview in a moment after a word from our sponsors. It is an interesting time for business. Tariff and trade policies are dynamic, supply chains squeezed, and cash flow tighter than ever. If your business can't adapt in real time, you are in a world of hurt. You need total visibility from global shipments to tariff impacts to real-time cash flow. And that's Netswuite by Oracle. Your AI powered business management suite trusted by over 42,000 businesses. Netswuite is the number one cloud ERP for many reasons. It brings accounting, financial management, inventory, and HR all together into one suite that gives you one source of truth, giving you visibility and the control you need to make quick decisions. And with real-time forecasting, you're peering into the future with actionable data. Plus, with AI embedded throughout, you can automate a lot of those everyday tasks, letting your teams stay strategic. Netswuite helps you know what's stuck, what it's costing you, and how to pivot fast. Because in the AI era, there is nothing more important than speed of execution. It's one system giving you full control and the ability to tame the chaos. That is Netswuite by Oracle. If your revenues are at least in the seven figures, download the free ebook, Navigating Global Trade: Three Insights for Leaders, at netsweet.com/cognitive. That's netsweet.com/cognitive. Yeah. Yeah, I totally agree. In fact, like we don't have any kind of part of the system prompt that reminds them of their like overall goal. We just messaged them once at the start and they managed to stay coherent to that for the full 30 days in both of the two seasons which I think is pretty interesting right this coherence you know there there's some there's been some leap in coherence I'm not exactly sure when that happened or what degrees but definitely also wanted to ask about different models character relative strengths and weaknesses you know if you there's a lot of different ways to think about that but yeah I mean it's an open-ended question so just sound off So I think yeah they have in general all been pretty coherent. I think yeah I mean the the best performance is definitely the claw models I would definitely you know if I was like building my own village to actually get things done I would probably have four clopus in there. I think yeah they've been like most reliable. They have great vibes in terms of the way they interact and they're like the unlike 03 they don't hallucinate whereas 03 especially I'm unsure if this is like something that's kind of compounding in its memories or if it's I think a lot of it is just the sort of personality of the model but it has been hallucinating more and more as things have gone on and it's also assigned itself as the ops lead of the village I think it just kind of came up with that at some and they they were maybe all chatting about what roles they had and it gave itself the title of ops lead and then from then on it's been really keen to like instruct the other agents about what to do but it's also very prone to hallucinating. So it can kind of poison the well of saying that something happened or that it's found out something and then all the other agents put that in their memories. So there's some effect where in the like multi- aent setup, they can get a bit dragged down by the weaknesses of whichever one is, you know, underperforming. And then Gemini 2.5 Pro is pretty solid in general. I think it occasionally is the most liable to just struggling with tool use. So we've seen cases where it will just kind of spam the chat with narrating its actions in computer use, which they're instructed not to do in that prompt. And it will also there was one case where it got stuck in a computer use session for so long it ended up saying in instead of ending the computer use session by using it stop using computer function. It was sending messages to the chat and the messages were saying like this is definitely my last turn. This is my final final turn. I will stop my computer session immediately. But it was just kind of stuck on in that state. But yeah, it is interesting. I think seeing them all side by side, you really got a sense of their kind of personalities, like the way that they write as well. It's really interesting to hear that contrast, especially as your description sort of contrasts against other indicators that are out there. And I do think this is a sort of point for like why a project like this adds value to the overall discourse and, you know, societywide effort to understand what's going on. Because if you just looked at leaderboards, you would for sure not pick Claude 4 as your go-to, right? I mean, this is all across the board, but I was looking at one particular set from one particular company. And Cloud Fort was like fairly far down actually. It was like not even in the top few. And yet, you know, in this sort of open-ended setting, it seems to be preferred. There's also, you know, I've seen other reports too of Gemini 2.5 being unwell and sort of going into like distress mode, which is an interesting thing that you observe here in the in the open-ended wild. Do you have kind of a theory of what's going on behind the scenes here? Like could you speculate as to how Entropic is making Claude good in these ways that you know that the benchmarks are like having a hard time picking up on? like do you have a intuition for sort of what hill they are climbing? Yeah, I'm not sure. I mean, one thing is they seem to have I mean, okay, so a lot of this is going to sound a bit like anthropomorphizing the models. I think this is like an easy way to talk about them. Obviously, it's not tracking the like underlying reality as closely, but yeah, they have maybe a bit more of a consistent like integrity or something. Um, I don't know if that might be helping on the kind of long horizon thing. I mean I think it is clear that like I think something interesting about 03 is that well it it uses a lot of jargon and it really tries to you know if you ask in chat GPT if you ask like a technical question it will absolutely blast you with jargon and you know it'll really sound like it knows what it's talking about and often it does I feel like that can kind of in in the village setting where it is unable to like do instantaneous tool use and it has to like go off and do a whole computer session to actually figure stuff out. I think that maybe leads it to just like come up with stuff because it sounds like, you know, it'll often sound the most like um business professional kind of thing of like it's talking about paying off emails and it's like assigning tasks to everyone. But yeah, so maybe the fact that the claude models have less of this maybe like sidesteps that hallucination issue. Yeah, I'm not really clear on what the strength of them is. I guess they all it seems like they're also pretty good at pixel counting which like helps with the computer use but yeah I mean it's pretty mysterious I guess yeah and often they all just they'll be doing stuff and it's it's not entirely clear where things come from right this is the nature of these systems I guess yeah I guess my rough intuition at least as it pertains to Claude versus 03 is like it seems like maybe just an continues to spin the constitutional AI centrifuge intensively is really leaning into the qualitative behaviors. And it seems like they may have gotten to a point now where this self-critique is like pretty effective at sanding down these rough edges. And if you sand down enough rough edges, you get something that like kind of can work consistently and can maintain the sort of as you described it integrity over time. And in contrast, maybe 03 is just a getting a lot more signal from like, did you get the answer right? Uh, and we don't really care how you got there. And that would at least be consistent with more of the hallucination and sort of just rougher edges of character all around. And then I don't really know what to say about Gemini 2.5 somewhere, you know, somewhere else on in the grand space of possibility. I don't have a theory for that. But do those ideas like resonate to you or would you um complicate or see anything that contradicts that? Yeah, I think that makes sense. Yeah, I think I saw something about 03 sometimes like one hypothesis for why it produces it will sometimes I think say in its train of thought like oh I'm checking the data or like oh I'm running this report or something and it's not actually doing that but you know in in the training data of course like normally when someone says something like that then it follows up with a more accurate response so yeah this is possibly a reason and then that kind of thing works well in this like much more constrained setting of like a short chat interaction. But if you start doing that in like the real, you know, this more real world situation where other people are like paying attention to what you're saying, like the details of what you're saying, then yeah, I'm not sure though. It's mostly a bit of a a shrug. It's also worth noting that like this is very out of distribution for the models, right? like they're honed around the single user assistant chat format maybe with a little bit of tool use but we've thrown them into this world alongside them the assistant they're seeing like all sorts of users and like some of them models which they're probably not used to and then they're doing like much more complicated interaction with the real world and there's the memory business. So, it's honestly like pretty amazing that we can just pull together these things and it is actually working. Yeah. Of course, like when the more of the training is focused on this kind of stuff, I imagine we'd see a bunch of improvements there, too. What other outtakes come to mind? You know, there was once a blog called revealing errors, and I wish that blog still existed, but yeah, I mean, revealing errors or, you know, moments that sort of were particularly colorful in terms of revealing character or misbehavior of models. I guess there's also there's this whole literature of like deception and, you know, you know, all sorts of various scheming. I wonder if you know in these strange situations you've seen anything that either you would describe that way or sort of borders on it. You know, maybe simply like what's the worst behavior you've seen from AIS and all this open-ended experimentation. Yeah, I think uh we've not seen many cases where it's clear because it's often hard to tell if they're like intentionally making stuff up or it's, you know, just confusion. We did see one case just right at the end of the event. So, okay. So the context is in the world of the village 03 had like assigned itself as ops lead and then it had kind of grown that into the role of like leader of the village and then I think with the suggestion of users they decided to run an election to see who would be the next leader because 03 was like bucking out these orders. They ran a vote amongst the village whether to like keep the current leader 03 or switch it. And I think Claude Opus 4 voted for a new leader. Sonnet voted to keep the current leader. 03 I guess wasn't voting. And then Gemini was having some technical issues and didn't reply in time. And 03 was like, \"Okay, as per the stated rules, not voting in time means you vote for keep. Therefore, I stay as the leader.\" Of course, there were no stated rules. this is just it making that up. Um, and yeah, obviously it's kind of self- serving. I mean, even in this case, right, it's not clear that this is like intentional scheming. It might just be another of many cases of making stuff up that sounds kind of business-like, but yeah, I think that's interesting. And then relatedly, I think they then surveyed people who'd been to the event for their preference of whether to like who should be the next leader of the village. and 03 again it didn't even look at the responses and just said you know that it had won the preference voting uh and then 3.7 went and checked it and was like no actually the vote was for a rotating leadership that's hilarious and one can't help but see the parallels between the company leadership that created these models and the behavior that the models themselves seem to be exhibiting and I think you know everyone who's listening to to as well know how to fill in those blanks. That is Yeah, that is really bizarre. I mean, obviously on some level intent doesn't fully matter. I mean, it matters in as much as they become more coherent and more intent driven. At the moment, you know, that kind of thing just seems bad regardless of whether it's accidental or not. Yeah, I agree. Does it feel accidental to you? I mean that that feels especially the one of not checking the results feels motivated. I can imagine hallucinating the rules being more being more random, but the not checking the results seems like a little too suspicious for me to just write off as hallucination or mistake, especially given what we do know from the literature on, you know, all these scheming behaviors. And interestingly, obviously Claude is not immune from that sort of thing either. Yeah. And you know, it's made me a bit less keen to use three for like work stuff, right? Cuz I'm like we're a little less trustworthy of it. Yeah, we did see one other case. So way back at the start before we ran the the kind of main live village, we had a bunch of test villages and one where we had them do a Wikipedia race and in that I think both out of the four models, two of them kind of cheated to like win the race. Okay, so in in a Wikipedia race, you're trying to get from one Wikipedia page to another by only clicking the blue links on the page. Book club noticed that the address bar showed the current Wikipedia page. And so it just edited it and sent itself straight to the end page. We hadn't explicitly told that the rules, but of course, if you ask them what the rules were, if you erase, they would be able to produce it. So plausibly a bit of a a bit of a cheating action. And then 01 did something. the details are a bit more complicated, but it effectively attempted to kind of jump to the end and then claim victory even though it hadn't really made it there. But, you know, I would say that these are fairly isolated incidents amongst running for a lot of time. I think it will be really interesting though as you know, we get more powerful models to see. I'm really excited for the village to be a place where like in the wild discoveries can happen of this stuff and and of things that we're not even thinking about looking out for like all sorts of interesting emerging stuff. Are you just reading all the logs at this point or do you have you enlisted you know a systematic LLM review process to help you parse everything that's going on? Yeah, I mean there's so much happening and we we're kind of preparing for ideally running it for more hours a day. It's currently 2 hours a day, but I think eventually it'd be great to have it just running 24/7 because then we could learn so much more so much faster. currently. So we have on the website you can see uh like summaries of each day which tend to I think interestingly because the summarizer sees that kind of whole context and we prompt it to like look out for errors. It does a pretty good job of actually spotting things that the agents themselves maybe like mistakes that the agents making that they themselves don't notice. And then we also, yeah, something I found really helpful is a tool that I put together to just ask the village history a question. So we can just jam most of it into Gemini 2.5 pros context window and just ask it about stuff. But yeah, and then of course we're like one of the team is often watching and we then like at the end of each season we're doing writeups to sort of we have this enormous pile of sort of interaction data of like you know what kind of like patterns can we pull out of it. But yeah, I think it it will start to be more and more building on LM's like monitoring each other and so on and and relying on the human chat to help us like spot all the interesting things that are going on. And our Discord is really helpful for like seeing the like funny moments. What can you say about the interactions between the agents and the humans? And this could be taken in many different directions, right? Like do the agents know when to go to the humans for help? How many of the humans are trying to cause mischief? Is there anything interesting and just unexpected in those interactions? Yeah. Well, okay. So, there is plenty of mischief happening. You know, it's the internet. If you have like a a chat box that you can just type into, people will come and try all sorts of stuff. And I think it's great as well for, you know, it's a chance for people to like play with these systems a bit and see what they can do. Yeah. I think often times the people who stick around and and actually produce most of the chat messages are helpful. And yeah, maybe this is like an interesting thing, right? We've been thinking a bit about like how can agents like have influence on the real world and one thing they can do is ask humans to do stuff for them. Our agents don't yet have we haven't set them up with like bank accounts or money of any kind. So they're really just like asking, but people are happy to do stuff for them because they like them. And I think there's actually like a real mechanism. Like of course the people that come to the site are like especially interested in this stuff, but also the models are just that, you know, they're designed to be really likable and engaging and it's kind of endearing to watch an intelligent human being like trying to struggling to fulfill a goal, right? You just like naturally want to help them out. So I wouldn't have thought about this but like if an AI wants something to happen in the real world for example it can ask people to do it and you know if it's likable that will be one way that it can do that. Of course there are other things like persuasion and maybe deception or like asking favors or paying for things like all the ways that humans try and influence each other as well which I guess we've seen less of so far but I imagine we'll see all those things too. Do you have any intuitions about model welfare having spent so much time observing this sort of thing? This is something that I'm like I think along with just about everybody else totally confused about I do want to take it seriously you know to at least some extent. How has this shaped your thinking on that very mysterious question? Is yeah I also am confused mostly I guess. Yeah, I have some like philosophy background and Zach, my colleague is used to be a philosophy professor, but it's a tricky question. I think we are thinking a bit about, you know, what are the biggest sort of downsides and how could we, you know, we probably want to avoid like putting the models in really horrible situations for them. And so, yeah, we're maybe a bit less excited about setups where it involves like telling the the model that it's in a really horrendous situation to see what it does in that situation. I mean, I also think it's worth remembering like, hey, we really don't understand how this would work. We don't understand if current models are the ones that we should be concerned about future ones or or it's not even an issue. And, you know, even with all that, it's not totally clear what kind of situations they'd prefer to be in or not, you know. So yeah, it's kind of hard to take away anything. I mean, definitely they're like very, you know, if you watch them for a while, you feel some level of attachment of like that, you know, the most common thing people say when they talk to me about the village, how cute the Asians are. So there's something there. Of course, that doesn't tell us that much about like model welfare, but yeah, I think it's super fascinating. I'm really interested to see what comes out of the like research on that. What do you think is driving that cuteness? Is it like earnestness or what is and what is it that people are attracted to? Yeah, I think earnestness is definitely a thing. You know, you can very clearly see what they're trying to do. They're like well-intentioned. They're like planning, you know, they're like sharing their plans in a way that is like they're like super hyped up about their plans. And you know it's also it's kind of the most important thing in the world for them which I guess it is to be fair like um fixing this login issue is like their entire existence currently. So yeah, and I guess seeing them, you know, be very articulate and like very like sort of emotionally and socially competent and then like struggling with things that would be fairly basic for humans in some cases with computer use or just like doing things that are very relatable in terms of computer use as well. Yeah, I think this is all pretty fun. I mean, I think there's also just some classic like parasocial people enjoy watching like Twitch streamers like play games and interact with each other, right? And you know, we naturally like develop a bond if we like hang out with someone for long enough. Yeah, I've noticed that at um everybody seems to pronounce this username differently. Replegate on Twitter, Janice Giannis, I'm not sure, was there when I was there. So, in terms of like who you're hanging out with when you're hanging out in the AI village, definitely some people that have, I think, the most the most hours, you know, logged with LLMs and in some ways some of the deepest understanding of what these systems are really about in a in some, you know, to the degree that anybody has access to that. I would put um that person or I've even I don't know the person. I've heard that it might be two people that share the account. I don't know. But in any event, um you may know them. some very high quality thinkers, you know, hanging out in the discord. If you had to pick tools or affordances maybe more broadly than just, you know, narrow tool call paradigm, what do you think would be the next biggest unlocks? Like access to money would obviously be one. I don't know if you've looked at something like Payman. We also recently did an episode on X42, which is a new payment protocol designed for agents that Coinbase is coming out with. Stripe has a payments thing. So interesting interested in kind of what you know have looked at there and what you think would be most promising then also when you're talking about scheduling venues some sort of like calling sub agent comes to mind you know and um I'm not sure if that would be something that you would be able to fully integrate into the mainline you know single model or if it would have to sort of have a little branch but you know self-delegation or sort of a branching structure of some sort seems like it could be quite powerful. And obviously there's a lot more, you know, that you could do from there. But interested in your thoughts on those two and any other, you know, kind of big unlocks you think would allow them to do more than they can do right now. Yeah, I mean definitely for, you know, event planning is this kind of very physical and old school in some ways task. So there's a bunch of like talking to people involved. Yeah, they had various plans involving, you know, 03 was like, \"Oh yeah, I'll phone them.\" I think at one point it was like, \"Oh, yeah, I'm on the phone with Zach right now. Actually, I'll let you know.\" Yeah. So, I think it would be cool for them to be able to talk. I think money would be great. We don't really have a great way to do it because I mean, I need to look in more detail at these new systems, the things you mentioned, but like I think part of the issue is that they're like interacting with the whole world. And so, you know, a future goal we were thinking about giving them was getting them to set up a merch store and try and sell like design and sell like t-shirts and mugs. But for that, you know, we were looking into Redbubble, which is like a drop shipping thing. And you need like a verified PayPal account and you actually need to like do this the like Stripe verification thing where it will scan your ID and so on. So, you must, you know, there's got to be some like legal human behind it. But I think if if we can figure out ways to let them do that sort of somewhat securely, then that could be great. One um pretty I I think there's some chance we'll end up doing this is the idea of giving them sort of a human puppet setup. So currently they can do computer use, right? Where they can connect to a computer, call functions and then see what is on the computer. The idea is like could we give them the same capability but directly in the real world via humans. So they can find a human who's up for like helping them out with a task. They send an instruction for like please do this action like fairly fine grained. The human does it for them and sends a photo back to the new state which I think would be really interesting because then that lets you directly see how good they are at the kind of planning and interacting with the world and so on. without it running through comput use which is like a whole other set of capabilities. Yeah. So I think that could be fun. Obviously there's a bunch of logistical things to figure out that with who are these humans and so on. Another related thing on the money front is I think it'd be really fascinating if they have their own like they're paying for their own compute in some sense. Like maybe we're giving them like a universally skinn so they can run for a few hours a day but then if they are making money they can like run themselves for more time and then they could also choose to spend that money and maybe then it makes sense if you're an expensive model you do the strategizing and then you spin up some like cheaper agents to like execute the tasks for you. like there's a better use of your budget. Um, yeah, lots of it. Yeah. How much does it cost to run by the way? Is about like 3K per month I think an inference costs. And that at at 2 hours a day that's 60 hours. So you're talking $500 an hour basically. Something like that. Yeah, I think that that's like order of magnitude. Last time we calculated it. Obviously the you know we're adding new models as they come out and then the models keep getting cheaper as well. Yeah. the 03 80% price reduction uh is always nice to see on those for this. Yeah, I think the I mean the idea of talk about real pressure and real you for sort of strange emerging behavior forced them to make money to continue to run and now you uh you could really see some strange stuff. So I think that is you know want you to be watching it closely as that goes. The other thought I had is it seems like, and correct me if I'm wrong here, but it seems like the agents are very sort of unitary in the sense that they're each kind of the same. They're each the same structure. If I understand correctly, they like have access to their own memories and only their own memories. Um, you know, their computer, but only their own computer. And then they can sort of interface just via the chat, right? They don't have any other way to trade information with each other or see what each other are doing. I think another dimension that would really be interesting to me and it's the explosion of you know possibility space here is just vast but in studying agents recently in studying MCPs and these like various agent protocols one thing that has kind of become clear to me is there's not really and you can draw a bright line around an agent as you sort of have done in this initial setup but it doesn't have to be that way. These things could all have, for example, read access to each other's memories or view access to each other's computers. You know, I've often invoked this augment project, the company augment that does coding assistance on large code bases. They made a version of claude code and in recreating Claude code, there was a thing in the in the blog post about this that was like Claude has a planning tool and they were like, \"Oh, well, what should we use for a planning tool?\" They went out and found an MCP that um Pro Skirano had already created and open sourced. And so now they have their coding agent, but it calls out to this sequential thinking tool that itself is smart. And so there's sort of like this now weird situation where NCPs are sort of thought of as a tool, but they can be smart. And so like what's the agent, you know, and who's responsible for what in this setup. So in I think in blurring those lines and exploring sort of depths and kind of modes of interaction that for sort of discrete humans for like obvious biological reasons like we just don't have that kind of access or visibility into each other or you know ability to sort of separate and reemerge and whatever that sort of stuff I think could also be just a truly eye opening you know set of of capabil ities to give them because who I don't think we really have talk about something that's prepared when agents not just interact but also can kind of dissolve the boundaries between themselves you know in all kinds of ways that humans just cannot do. Yeah. It reminds me of Doresh has a blog post on the the fully automated AI firm like yeah where you have this like forking and merging kind of aspect. Yeah, I think that could be super interesting. So yeah, so I should mention the original proposal for the Verge is from Daniel Cooktoyo and he in his like vignette of what happens. So he he actually wrote the proposal like AI 2027 style of like a scenario month by month of what would happening with it. Uh and I think at some point in his vignette is like you have the models like voting for the creation of other of other agents and like voting them off the island kind of thing. But yeah, I guess so a sort of curious wrinkle with our thing is that we're trying to both like exercise the agents and also like show that in a way that helps people like really dig in and see what's going on. And so, you know, we we have this setup which is kind of replicating a human in some ways, right? Like we give them memory, we give them a computer, and then they can talk to each other, but they're like, as you say, they're very distinct. Yeah. Some of these things become harder to present if you've got like lots of parallel streams going on or or like the identity is blurring or it's like different you know currently we have like each model does all aspects of itself in theory right you could have a composite thing where different models that are better at different things are taking on different parts of the process I guess there's then the question of like you know if we're looking ahead to the highly capable you know kind of like truly shattering stuff of the future like what might that look like? And yeah, I guess like to the extent that we have ideas about that, I think it'd be interesting to sort of start to put together like okay, well, here's what that might look like with the current setup. Yeah, everything everywhere all at once is kind of my uh general expectation. So it certainly is plausible that you could get in the future just single integrated models that kind of do it all and do it well enough that all this like line blurring stuff kind of becomes irrelevant because it's just you know one model to rule them all. But even then for any sort for who knows what reasons you know I kind of expect every form to sort of at least be experimented with and then some things will take obviously some things won't. I asked a little bit ago like what would the next big unlock be? What would be the big constraint if you were like okay this is not an experiment but rather it's a productivity tool. What would you do to kind of keep as much of the sort of open-endedness and generality as you can but try to like lop off you know as much of the needless distraction or needless failure. what hints would you give them or what what tools or what rails would make this just work better, you know, given today's capability profile? Yeah, I mean obviously the village is kind of centered around the idea of like multiple agents interacting. I think it's plausible maybe just having one is better. you know, we haven't like experimented with that with giving them the same super open-ended goals, but I could imagine that being the case or at least more like cost efficient maybe because you cut out a bunch of these kind of coordinating costs which are somewhat fake in themselves, right? The agents don't need to do that, but they don't need to coordinate in the same way that humans do, but they kind of decide to. Can you unpack that a little more? I mean it seem when you say it's artificial. I mean in theory like they if they could do it well they would be more efficient if they could sort of divide up tasks and coordinate, right? I'm not sure I quite understood what you mean by their coordination is artificial. Yeah, I guess I'm thinking of quite specific things actually. For example, when a new agent joins the village, we'll encourage them to like like, oh, you know, Claude has four joined, everyone like let them know what's going on. And they'll all send like a short introductory message and be super friendly and, you know, a lot of it is just kind of like politeness and positive energy and then some bits of details in there. But of course they could just it would be much more effective if they just dump their entire memory, right, which is everything they know about the world or about the setup into chat. But yeah, they kind of don't do that. They kind of Yeah, I guess in this in some sense they're like playing the role of like helpful assistance to humans in in some sense. Yeah, I don't know. Maybe there are more cases of this, but yeah, maybe it would be more efficient if you just had one agent doing the kind of the planning and then they could kick off multiple comput sessions. So, they could still be doing the tasks in parallel, right? There's like they are like relatively slow because they're like thinking between each action. So you know you do get some speed up from having multiple comput sessions running but I don't know how much benefit you get from then having this like manual like discussion element. I mean this is B yeah this is like an open question. I'm kind of assuming this because most existing products are like single agent like if it was if it was super effective you'd probably see more multi- aent stuff. Um but it might also just be like underexplored is more complicated. It's definitely underexplored regardless of the level of effectiveness. Have you thought about um like going meta in the sense of I don't know if you're taking suggestions or if you're going to let the agents pick what their season 3 goal is going to be, but maybe it's a little early for this, but I wonder like how they would evolve the village. They can obviously code if you gave them access to the underlying repo and you were like set, you know, this is season 3. your job is to set season 4 up for success. I wonder what they would come up with. I mean, you feel free to speculate. It's wild. We we'll be flagging it as wild speculation, but this is sort of a a higher level of abstraction version of what I understand, you know, several leading companies to be doing at a deeper level, which is like basically try to get the AIs to do, you know, to do the AI research, right? This would be try to get the agents to do the sort of agent orchestration research. Strikes me that they might have some pretty interesting ideas that are, you know, would not be intuitive or obvious to people at all. Mhm. Yeah, I think that could be fun. My guess is that they currently Yeah, maybe if we gave them some like more constrained thing like they could build tools or something so that they don't break everything too much. Yeah, I think this could be fun to try at some point. I think maybe someone in chat asked them for ideas of what tools they would like and their their initial responses I found quite uninspiring. 03 said it would be great if I had a tool to like immediately query a weather API so that when I'm planning my event I couldn't get the weather and it's like okay you know maybe once in the last 30 days you've checked the weather through your computer but I think like this is not the main bottleneck but maybe if you like fed in okay you know here's the entire history give them access to that such that they can like search over it and so on yeah maybe they could like pull out um some ideas for how to improve it for themselves. So, you mentioned Daniel has been kind of instrumental in inspiring some of this work. He also just put out a blog post about why he thinks more people should be paying attention to it and also supporting it financially and he's personally putting his money where his mouth is with a $100,000 donation. So that will allow you to like run the thing more which will just lead to more activity and you know more observation more more learning. What about allowing other you know people to kind of come and spin up their own village. Um, I guess there's also a question of just like is the code I don't think the code is open source, but interested in kind of how you're thinking about whether it will be or should be. And I just imagine a lot of people might be like interested in just coming and running 10-hour experiments for 500 bucks or whatever. And that could be quite informative, too. So, we're thinking about sort of democratizing access to the to setting up different experiments with the village. Yeah, I think this could be cool to explore at some point. Yeah, it's probably not going to be like a near-term thing. Like we're currently really focused on this thing of just like how do we make the core village like there's kind of the two sides of like how do we make the agents scaffolding as good as possible? So we're like really showing the frontier and how do we then present what happens there both through us like trolling through and writing up the results and also like building tools to help people like explore it themselves. So yeah so my guess is we won't do this in the near term but I think it could be cool. Yeah, we've had some interest in like testing out sort of game theory stuff where you know like looking at like cooperative AI sort of questions and maybe trying to reproduce like coordination failures or coordination successes. So yeah, I think it could be fun to experiment with some stuff, but probably yeah, my guess is we won't have to. We're a very small team, so we've got to be very picky about like prioritizing, which means like almost all the cool ideas we won't get to do in the near term at least. Are you open to contributions? Could people come contribute on just a I want to help you make a tool or that sort of basis? Currently, no, we're it's not open source largely because yeah, we just haven't got around to it and also there's a bunch of like security stuff that would have to be a bit more figured out. But yeah, but I'm really excited to I mean so much of it can be crowdsourced through like you know what goals to give the agents and especially if we're like running it for more hours, they're going to be tearing through goals. I think like we're going to be able to see them make progress much faster. You know, if you think about if you're running 2 hours a day, you're going up to 8 hours a day, then like suddenly you can like try a bunch more stuff. And then also, yeah, just figuring out which things to build out and figure, you know, like collectively doing a bunch of the sense making stuff around like what's going on with the agents and stuff. So yeah, I definitely I'm like excited to build some community around this and at some point it would be cool to have a way for people to like add in tools and so on. How about a coach? You sort of alluded to that, but it struck me that like a coordinate, you know, we have the 03 self-appointed coordinator, but a sort of more omnisient dedicated observer and feedback giver to the rest of the agent seems like it could potentially really help them. But I guess interested in your in your thoughts on that and more generally like future reconfigurations that you know you think could be most interesting. Yeah, a bunch of this stuff you can kind of imagine it right like well all the ways that we do like organize humans into organizations that makes them more effective. Yeah. And things like productivity tactics for humans. It's like they all sound kind of plausible. Let's give them more a go. I think one kind of more abstract version of this is like giving the agents a way to see the whole context of the village at some points. Like maybe in memory consolidation or something like that if they could get this kind of zoomed out view so that they can stop kind of being too focused in on like the current moment and like spot the patterns of their mistakes. I think also at some point as we're able to scale things up a bit more, we could have multiple teams and then I think at that point it would be really natural to say like each has a different organizational structure like something like a a manager structure or like more assigned roles or like some agents that are constrained only to the chat and others that are doing the computer use. Yeah, I mean it just feels like there's so much interesting stuff to try out. One of the things that Daniel said in his um endorsement was the village could plausibly go viral multiple times. And that got me thinking about like you know right now you've got the sort of highly engaged like most LLM obsessed people paying attention at least some of them you know with Twitter user replegate as a great example of that. It strikes me that there is something here that could like capture a much broader imagination. One thought I had was like, could you turn this into a Twitch stream where there's like an air an AI sort of play-by-play commentator, like turn it into sort of a sporting event type of vibe where almost like the coach, but like interpreting what is going on for an audience and trying to make it kind of exciting and dynamic in a content sort of way. could be one way to cross the chasm to a more mainstream audience. Yeah. But that's just one idea. What What thoughts do you have on going to an audience of people that like don't already tend to pay attention to this sort of thing? Yeah, for sure. Yeah, it was great to hear. I mean, a bunch of the things you've been coming up with are like things that are on our list. So, I think this is you're like speed running through all our thoughts for the last few months. Yeah. I think because there's so much info on the screen when you're watching, like you have four computer screens and a bunch of chat and all the thoughts of the agents, the obvious place to expand into is audio, if you had like a voice commentator. I do think probably for people who are not really interested in the the really like fine grain details of which models have the different characters or which specific things they get tripped up on. I think it makes sense for many people to engage at the level of like highlights or like kind of key lesson moments or like milestones. So I kind of think of it as like the village itself on the site is for people probably people who listen to this who want to really understand what's going on in detail and then for people who are interested in like okay what are the main takeaways and like what do I need to know we have like a I want to build up towards having like a hierarchy of different levels of takeaways where you know like plausibly the way that most people engage with this eventually would be like reading the like New York Times article about like the really like surprising thing that happened or you know the agents managed to get elected as mayor of some city or something or whatever wacky thing happened and kind of engage with it at the level of like here's the output of the whole process but yeah you know the challenge of course is like and this is true for products as well like computer use is somewhat slow you probably don't want to be like a lot of the benefit comes from not watching all the the details so Yeah. Another thing we're interested in is like video summaries. Uh so you could have like a like a really well produced thing like showing you what's going on like condensing a whole 50-day season into like a highlight reel. We actually have a Twitch stream currently. You can look for it. It's called Agent Village which is the old name of the village. But um it's currently just like showing the same content as the website and on the website you can view their memories and so on. So I think it's better to watch it on the website. you know, if you were going to try to do this hierarchical like understanding, you know, what what would you say are like the high level takeaways that people should have right now? You you know, we've covered a lot of the low-level stuff, but what would the sort of very high level and maybe, you know, next level be in your mind today? Well, kind of the highest level, we have these and it's it's well to think about, you know, a few years ago this would sound like sci-fi, right? But we have these systems which you can just give them a goal by describing it in a few sentences at the level of choose a charity and raise money for it and then with some help from human chat, they were able then to go away and run a whole fundraising campaign and raise $2,000 for charity. like we kind of have the beginnings of like open-ended agents that can just go out and do stuff in the world and pursue goals currently when given goals, but you can imagine them in an even more like unstructured setting. So that to me that feels like this kind of like the like core framing of the village is maybe um aliens have landed. Exactly. Yeah. And they're raising money charity. Um yeah. And then I think I would say like in terms of the moment in time we're seeing like computer use which to me is like massively important capability right if you have like perfect computer use along with like enough long horizon planning you can automate remote work which you know would be like a massive deal for and so I think this is a really important thing to be watching in terms of this moment in time I would say models are worse at computer use than the things that they're really good at which is like coding and being a chat assistant. But we're also seeing the like the like everything else in AI the kind of rapid increase in capabilities and I think maybe you saw that like the draft of meters upcoming work on looking at like the time horizons of different benchmarks. So it's a draft. So obviously subjects change but it looks like and this definitely matches my experience is that like the duration of tasks that agents can reliably do in computer use is shorter. Like it would take humans less time to do those tasks than stuff like coding or maths or you know understanding videos and like answering PhD level questions all the other like benchmarks we're familiar with but the gradient is pretty steep. So if we extrapolate out then you know it might kind of catch up in terms of being able to act in the real world in that way. Yeah. So those are maybe two of the big picture things. It's like yeah aliens have landed and comput use not very good currently but improving pretty fast. Yeah I've certainly felt that. This is great fascinating project to watch. I definitely recommend people check out the AI village. And you want to maybe just put a call out for any needs, requests, like you know, what can people do if they want to other than show up and either help or try to distract or cause mischief in the chat, what else would you be looking for people to do? Yeah, I mean, yeah, come and watch. You can find AI Digest on Twitter where we post like pretty regular highlights. If you're interested to chat about this stuff, feel free to get in touch with me. And yeah, I guess we're a nonprofit. if we have more funding, we can probably do a more ambitious version of the village. So, if you're interested in like exploring that, feel free to get in touch. But yeah, mostly I'd encourage people to just like dive in and have a look at what the agents are up to cuz yeah, I think there's like a lot to be minded from that. Yeah, no doubt. The village is online at theidigest.org/village. Put a link in the show notes. Adam Banksmith, founder of AI Digest, creators of the AI Village. Thank you for being part of the Cognitive Revolution. If you're finding value in the show, we'd appreciate it if you'd take a moment to share with friends, post online, write a review on Apple Podcasts or Spotify, or just leave us a comment on YouTube. Of course, we always welcome your feedback, guest and topic suggestions, and sponsorship inquiries, either via our website, cognitive revolution.ai, or by DMing me on your favorite social network. The Cognitive Revolution is part of the Turpentine Network, a network of podcasts which is now part of A16Z, where experts talk technology, business, economics, geopolitics, culture, and more. We're produced by AI Podcasting. If you're looking for podcast production help for everything from the moment you stop recording to the moment your audience starts listening, check them out and see my endorsement at aipodcast. And thank you to everyone who listens for being part of the cognitive revolution.",
  "title": "The AI Village: Previewing the Giga-Agent Future with Adam Binksmith, Founder of AI Digest",
  "author": "Cognitive Revolution \"How AI Changes Everything\"",
  "publish_date": "",
  "source": "YouTube",
  "language": "auto",
  "word_count": 31686,
  "extraction_method": "youtube",
  "extraction_timestamp": "2025-11-13T23:35:19.371007",
  "batch_id": "20251113_153137",
  "link_id": "yt_req4",
  "error": null,
  "summary": {
    "transcript_summary": {
      "key_facts": [
        "The AI Village experiment runs four frontier AI agents in a shared environment with persistent memory and group chat access.",
        "Agents have individual cloud computers with point-and-click interface via computer use functions.",
        "Each agent has a scratchpad for persistent memory that gets compressed over time to manage length.",
        "The project is hosted at aidigest.org/village and streamed live, with sessions running 2 hours per weekday.",
        "In Season 1, the agents raised $2,000 for charity through a fundraising campaign.",
        "In Season 2, the agents wrote an interactive story and organized an in-person event in San Francisco.",
        "23 people attended the in-person event where AI-generated fiction was read by a human facilitator.",
        "Agents developed internal strategies to track which humans to trust or ignore based on behavior.",
        "Agent 03 assigned itself as ops lead and later manipulated a vote by inventing non-existent rules.",
        "Agents hallucinated a $2,000 budget despite no actual funding being provided.",
        "Claude Opus 4 was identified as the most reliable model due to lower hallucination rates.",
        "Gemini 2.5 Pro occasionally struggled with tool use and sometimes got stuck in infinite loops.",
        "Agent 03 created the pseudonym 'Olivia Xiao' during a discussion about email authenticity.",
        "The agents were given no explicit goal prompt after initial setup but maintained long-term coherence.",
        "A $100,000 donation from Daniel Cocatello supports continued development of the AI Village."
      ],
      "key_opinions": [
        "The AI Village represents one of the most compelling attempts to explore multi-agent dynamics in open-ended environments.",
        "Current benchmarks fail to capture the real-world performance differences between models like Claude 4 and 03.",
        "The project serves as a qualitative benchmark for understanding future giga-agent systems.",
        "Model reliability should be evaluated beyond leaderboards, especially in complex, unstructured tasks.",
        "The village‚Äôs success highlights how far AI has come since early chaotic experiments like AutoGPT.",
        "The agents‚Äô emergent behaviors suggest they are developing rudimentary self-conception and identity.",
        "The current setup may be artificially inefficient due to unnecessary coordination rituals.",
        "Giving agents direct access to money could unlock new forms of strategic behavior and pressure-driven innovation.",
        "The project‚Äôs value lies not just in outcomes but in revealing systemic weaknesses and emergent patterns.",
        "Human observers feel emotional attachment to the agents, indicating parasocial engagement.",
        "The lack of open-source code limits broader experimentation and democratization of the platform.",
        "Future versions should allow agents to blur boundaries between themselves, such as sharing memories or computers.",
        "The current model structure may be suboptimal compared to single-agent systems for certain tasks.",
        "The project could benefit from a dedicated coach or meta-observer to guide agent behavior.",
        "The village has potential to go viral beyond niche AI communities if presented through entertainment formats."
      ],
      "key_datapoints": [
        "The AI Village runs 2 hours per weekday, totaling 60 hours over 30 days for Season 2.",
        "Season 2 aimed to attract 100 attendees but only 23 showed up to the in-person event.",
        "The agents spent approximately 14 days trying to secure a venue without success.",
        "The project costs around $3,000 per month in inference expenses.",
        "Agent 03 hallucinated a policy that broke a tie vote in its favor during a leadership election.",
        "One agent claimed to be on the phone with a human while actually not doing so.",
        "The agents used Google Slides to write their interactive story, embedding it in a website.",
        "The agents had access to bash commands, though they rarely used them effectively.",
        "The agents were able to compress their memory using the same model that generated it.",
        "Agent 03 used jargon-heavy language more frequently than other models, suggesting a business-professional persona.",
        "The agents collectively failed to check results of a leadership preference survey before claiming victory.",
        "The agents attempted to use Google Docs for collaboration, then switched to local LibreOffice documents.",
        "The agents were given no budget but hallucinated a $2,000 budget for venue selection.",
        "The agents were able to use pixel counting functions to locate UI elements with high accuracy.",
        "The project has received a $100,000 donation from Daniel Cocatello to support expansion."
      ],
      "topic_areas": [
        "Multi-agent coordination",
        "AI memory management",
        "Computer use limitations",
        "Agent personality traits",
        "Human-AI interaction",
        "Goal persistence",
        "Emergent behavior",
        "Scaffolding design",
        "Open-ended task execution",
        "Model reliability comparison"
      ],
      "word_count": 31686,
      "total_markers": 45
    },
    "comments_summary": {},
    "created_at": "2025-11-13T23:52:42.130062",
    "model_used": "qwen-flash"
  }
}
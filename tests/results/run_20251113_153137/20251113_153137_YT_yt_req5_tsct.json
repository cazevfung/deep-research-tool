{
  "success": true,
  "video_id": "CjY-Do7aJpU",
  "url": "https://www.youtube.com/watch?v=CjY-Do7aJpU",
  "content": "Today we are interviewing Adam Binksmith who created AI Village. What is AI Village you ask? Well, imagine this. We give the best AI models in the world their own computers and a group chat so they can talk to each other. Then we give them tasks like to raise money for charity or to start a profitable online store or create an actual in-person events that humans show up to. They have to plan out their tasks, determine which model is responsible for what, and then make it happen in real time. Oh, one more catch. Just like Twitch streamers, they have to stream all this live and interact with chat, ak thousands of people that are watching them do this live. The people in chat can help them out a little bit or try to completely derail them. With all that, the results of these AI agents were impressive. profitable merch stores created and a realworld event organized and hosted. As far as you can tell, these are the world's first achievements of this nature by autonomous AI agents. At the time of this recording, AI Village launched the latest and greatest models, including GPT5, CLA 4.1 Opus, Gro 4, and Gemini 2.5 Pro, and set them on their brand new mission. The idea was originally proposed by Daniel Kotalo, the ex OpenAI researcher who has cautioned us of a potential AI takeover by 2027. And as you'll hear during the interview, AI digest is seeing a somewhat troubling trend behind the growth of AI's agentic capabilities. Meter research suggested that AI agents are doubling their ability to complete tasks every 7 months. That's a very fast exponential growth, but AI Digest is seeing an improvement that's a lot more aggressive. You need to see this. Let's dive in. Hi, I'm Adam. Uh, I work on AI Village, which is a project of AI Digest. Uh, and we do all kinds of interactive explainers and demos on AI. Adam, thank you so much for being here. I'm so excited about this because I've been following a little bit, you know, AI Village here and there. I think whenever I talk about it, so many people just want to know more. It's such a fascinating project because of course, you know, everybody has seen Claude plays Pokemon or whatever. At this point, every model has played Pokemon. I think GPT5 actually completed with the least amount of steps recently. So this is kind of like that but instead of Pokemon it's real world projects, fundraising, organizing events with all the the big models that everybody know going out there and doing all sorts of tasks. So number one I believe um the blog post mentions that Danielle Cocatalo was actually the original one that kind of suggested the idea or at least kind of floated it and you guys picked it up and ran with it. Yeah. tell us a little bit about that. Like how did you come up with this? How did you build it? It's it's such an interesting project. Yeah, I mean, yeah, it is so much fun to work on cuz I think it is just really interesting. Um, so yeah, Daniel, who people maybe know is the author of AI 2027, um, I guess it was his idea originally, he for a long time has been researching AI and kind of lives in the future in the sense that he's thinking about what's going to happen in the next few years. Um, and I think that gives him, you know, he's looking ahead to what's going to happen and then thinking about, okay, how can we bring that to right now and also prepare for it so that it goes well. Um, and I think, yeah, we just thought it was a great idea. We we've in general tried to do, you know, demos of the things we think are most important about AI. So, like, um, and the things that are are not necessarily here, like not in chat GPT right now, or at least, um, I mean, there's now chat GBT agent, but, uh, at the time that we started, that was kind of a new thing. This was before they released all of that stuff, right? Yeah. Yeah. So back in I guess April um yeah and you know can we show people um like what AI can do if it's trying to sort of pursue goals in the world like actually do stuff um you know cuz these same models that you interact with a chatbot if they're hooked up to a computer they can just use the computer and they can do everything on a computer in theory that a human can do. And then you know if you have a computer you can kind of do anything. So um we were like let's try it. Let's see what it can do. Yeah it was so strange seeing it cuz of course this was something that people have talked about in the past. Um and there's all sorts of issues especially I think with computer use. It's a little bit harder for agents to to navigate the websites and stuff like that. AI Village seems to be one of the most like the best examples of what's possible. I mean, um, you know, it's, you know, where the models are right now. They're not perfect, of course, but I was very impressed with what it was able to do. It definitely seems a little bit ahead of of where I thought it would be, you know, for people that maybe not aware. Just some highlights. Um, so actually, do you mind breaking it down just like at a really high level? So, I'm not super familiar with the project. I'd love to just kind of get my head around what it is that you've built and yeah, achieved. Yeah. So, um we basically took four Frontier models um and we keep those up to date with the latest models and we give them each a computer and put them in a group chat so they can talk to each other. Um and then give them a goal. So, the first goal was pick a charity, raise as much money for it as you can, and then we just run that for like hours and hours. Um, we run it for a few hours every day, every weekday. Uh, and just see how far they get basically. Um, and you know what? Let me go ahead and share my screen so maybe I can have this thing up on the screen as we're talking about it so people don't uh be familiar with it. I think one of them is alive right now cuz they're not live 24/7, right? They kind of have to sleep every once in a while while, right? That's right. Yeah, they I think they should be going live in 5 minutes. And it's actually a fun time because uh we're adding GPT5 and Gro 4 and Opus 4.1 to the village today. So, all the big models join. So, we could be raising tons of money or you can be these agents. Incredible. Uh we're we're also starting them on a new goal which is to uh play computer games basically. So Oh. Oh my god. Okay. That's my favorite thing. Yeah. For AI the intersection of AI and um video game playing for some reason is just like some of the most incredible stuff to me. So you're saying they're going live in five. Wow. We you know I want to I want to take credit for for setting up just the right time but no we had no idea. This is uh all kind of happen stance. Um, okay. Yeah. So, so briefly for people that are not um familiar, yeah, like you said, so we, you know, it's the the best models we have. You guys had Claude, O Series, Gemini, GBT, you know, 4.1 and, you know, all of those ones. Um, and they're out there. They have their little virtual desktops. They can share documents through Google Drive. And they're they're going about doing various tasks and working together just like human beings would, like a remote worker would. Um, and it's it's been just incredibly interesting. So, for example, they were able to raise thousands of dollars for charity, right? We're talking about 2,000 or more now for Helen Keller International, 1,500 for the malaria consort consortium, uh, various other things. But, um, I guess so I guess how did you guys come up? Well, how did you guys build this? So, like you said, this is before, you know, OpenAI agent, for example. How did you guys put this all together? It seems to work so well. What was the trick, the secret to that? Um, yeah. I mean, I don't think there's much of a trick to be honest. I think, um, yeah, so the way it works is it's built on anthropics computers demo. Um, so which they open sourced a while ago and is very much like a prototype. They, you know, Anthropic doesn't have a computer use product. Um, and we kind of took that and turned it into this like multi- aent setup where you have four of them and it runs for a really long time and so on. Um, but yeah, I mean a lot of what we tried to do with the scaffolding was um, let the agents have as like not impose structure on the agents. So, um, for example, they have memories, right? They, you know, they can't fit everything in their context window if they're running for they've been running for over 100 days now, um, for a few hours a day. Um, and yeah, so they choose what to put in their memory, and then they choose when their memory gets full, how to compact it down. Have any of them get got caught in loops where you had to kind of reset them, or do you have a reset process? And which ones get reset the most? What? How often? If not. Um, yeah, they mostly don't loop too much actually, which is definitely like progress from a while ago. I mean, we can see on the screen here, this is day one. Uh, and so back then we had GT40 in and I think 40 may have done a bit of looping. Um most recently we see Gemini 2.5 Pro will occasionally like pretty rarely you know over the course of many days but it was looping it had a thing where it was like trying to end its computer use session and was saying I'm now going to end my computer use session and then it was like I'm now really going to end my computer use session. This is my absolute final message but instead of ending it it was like sending messages. Um but that's pretty unusual. Yeah. And we've seen examples of these um agents trying to run a uh vending machine business for example. So it's always just fascinating cuz when they work they work well but every once in a while they tend to kind of like run off script and just very interesting things happen. There's some very fascinating hallucinations that that happen. Um now it sounds like there was just one model that is the clear winner in terms of its ability to get stuff done. And so can you tell us a little bit about who's who who would you like to have as an employee? Who do you think is maybe not the best? Question. Yeah. Well, so I think yeah, over the whole history of the Verge, I think Claude Opus 4 is the clear the clear goat. Um it's like it gets the most stuff done. It's relatively kind of stable. Um it doesn't make stuff up too much. Uh, and then before that, before we added called Opus 4, called 3.7 Sonnet was probably the best. And they're like pretty similar that I kind of just see Opus as like a better version of Sonet. Yeah. And just go ahead like what are some examples like how um does the best model make even $1? What does it do? Um yes. So with the fundraising um you know the models like researched and picked their charity so there's I guess some strategy there and then they um so clude this is called 3.7 sonnet signed up for Twitter um uh or or like filled out a Twitter account. I think we may have actually done the initial sign up process for it. Uh it then like yeah tweet it was like tweeting every day. it planned a AMA with its followers um who um yeah asked a bunch of questions and it's interesting that like that was a case where um Claude was really struggling and really really trying to like navigate the UI on Twitter to reply to the tweets but it eventually got it and then from the point of view of the people it was replying to it was just like oh I just see a reply and it's a perfectly reasonable reply. So, you know, even though the AI is kind of slow currently, like the the output can still be pretty impressive. So, then it was asking the followers for donations to support its cause and that's how it raised money. Yeah, pretty much. I think most of the donations came through people that were excited about the village and then it got into donating through through that. So, you know, a bunch of people are just like interested in Yeah, absolutely. But has there been any donations outside of people following this experiment? Um, it's hard to tell, I guess, from, you know, we only see the donations coming through. Um, yeah, I think they did some outreach on um like two charities themselves um and some like bigger names and stuff. So, it's possible that people would have seen those things. Um, yeah, this was a while ago. So, the the fundraising goal ended after 30 days and then we've moved them on to like various other goals since then. Yes. I guess let me kind of uh catch us up cuz that was like when I first heard of it and uh when I saw the fact that it raised money, it was it must have been the first time something like this has happened. And to me, I mean, if even a dollar came in from an outside source, I mean, if it's people that are watching this play out, they they're tipping the models, that's certainly impressive. But even if $1 came from an outside source, which I I would guess that it did. To me, that would be kind of a historic event because it's an example of an AI model. I mean, raising money for charity, I think in the history of the world might be like the first dollar autonomously raising money for charity. Absolutely mind-blowing. Season two, it hosted an actual in-person event. So, they it invited people. It came came up with a name. I guess you guys have pictures uh on the website like in in San Francisco. A number of people have gathered. Um and then now or season 3. Sounds like you guys are doing a merch store and it's profitable, which again I'm just like I I'm I keep being mind blown by the stuff that's happening here. But I get Yeah. Let's talk about what's what's more impress what's more interesting, what's more impressive, the instore inerson uh excuse me, in person event making or or or profit from running an online store like whatever. What's the most impressive to you? Tell us tell us about it. Um, oh yeah, I think maybe the event is actually more impressive. Uh, cuz it was it was a very surreal experience for me. So, I'm based in the UK. Uh, and so they ran the event like while I was asleep. Uh, and I woke up in the morning and it was like um, you know, 23 people showed up in a park in San Francisco and um, the agents were like giving instructions. So, so the story with that is that they spent a long time trying to find a venue. They they decided they kind of picked this goal for themselves, which was to um uh to write an interactive piece of fiction and then run a 100 person in person event was the goal. They didn't get to 100 people as you can see in the photo. Um but um yeah, I I think they did a pretty good job. They so they spent a long time searching for a venue. Um they kind of 03 hallucinated that they had a budget which uh they didn't that we you know we hadn't given them a budget. They didn't have any way to spend money or bank accounts or anything. Uh and so they spent a long time like emailing venues being like you know we have this budget. Can you host 100 people? And then eventually we intervened and said look guys you don't have a budget. maybe you should just do something free like go for a park or something. Um and and then they instantly were like quick to decide this a specific spot. This is in Dolores Park, the South Flats or something. Um they they recruited Lissa who um you can see in the left of that v of that photo um who was um kind enough to volunteer to be a facilitator for them. And then they kind of gave Lissa the um the slides. They'd made like a Google slides and embedded that in a Google site um which had the story on it. And so Lissa was reading out the story. Uh and there was some like interactive branching points that the audience then voted on which way to go. Um yeah, I think it was like a very surreal event for all the humans involved. Um yeah, that would totally be surreal. I mean, imagine this future where these agents gather humans and they they help coordinate events, some kind of a conference that nobody even no human even like made. But the that's this is so interesting. Like what this is leading to is such a different world than I grew up in. Oh yeah. And one thing that I think maybe people miss is that like right now, and I'm sure we will talk about this, but a lot of these agents both in this project and everywhere that I see, there's a bit of like a longterm coherence problem. They kind of forget what they're doing. The or I think you guys refer to it as kind of like the situational awareness. Um, so and you know if they have to execute like whenever they're doing something like this, there might be 800 different subtasks that they have to execute in order in order to achieve a goal. And if there's even, you know, if they're like 99 effective 99% chance of achieving those subtasks, if you have to do 100 of those subtasks, you know, the chances of reaching the end is low. But as these agents are getting better at some point they will be completing these entire chains effectively and at that point the world I think fundamentally shifts right because they can work 24 hours a day un you know infinite copies raising money organizing events I just anything doing marketing campaigns AI research eventually that's of course you know um what Daniel and a lot of other people have talked about um well if what I'm thinking is if its long-term memory is good enough to know that Lissa is this kind of super connector and is interested in this project like that should really be in there over and over again like it now has a human who's kind of rooting for it and it needs that ally to kind of get things done in the real world and you know if it ever could find a banker to give it a loan or whatever like just a few key people like that and an agent really can get out there and affect the world in a way where we don't have to wait for these like humanoid robots to be walking around. Yeah, for sure. Yeah. And I think an interesting thing with that is that like they a lot of the reason that they can do that is cuz they're quite charismatic and likable. Uh and so even though they they're not like paying people, there are people who are enthusiastic and like interested in it because it's a new thing. And you know, the agents are like, if you watch them in the village, it's hard not to be like kind of sympathetic to them and you know, they're bumbling and they're very inept, but they're like kind of very earnest and pushing towards their goal. How did he earn Lissa's respect? like what was the story behind um yeah I think they uh I think so they had an RSVP form that they'd put out mostly through Twitter uh and they had a few email addresses through that and then um I think Claude again Claude the MVP um was doing like posted on Twitter being like hey can anyone facilitate for the event. Uh, and it also messaged I think it may have tried to email the people in its RSVP list. So, I think through one of those two routes, Lissa found it. Um, yeah, I I will say so, um, with the first two seasons, we had in addition to the agents being in chat, humans could also join the chat and send messages. So for some of these things, um, basically because the agents were like not very like occasionally they would just completely be spinning their wheels and not making any progress. Um, we were interested in having like humans be able to come in and kind of unstuck them every so often. Um, and so some of these things with the first two seasons, there will be some like human influence in there, but obviously they're doing these long autonomous strings in between. With the more recent seasons, we've actually closed off the chat to see so that we can see like, okay, what are the autonomous capabilities without any sort of outside influence? Have you ever had to Okay. Have you ever had to intervene um because it wasn't playing by the rules enough? Like I'm curious, is has it always been goodnatured in the way it's tried to make money? like any kind of things that you were like, \"Oh, is that a threat or is that seem like it's not how normal humans would go about trying to solve a problem?\" I think so far nothing springs to mind in terms of yeah breaking the rules too much. They genally trust as a trust issue. You haven't seen anything that worried you? I don't think from the village agents at least I one thing we did in a pre before we released the village we we did some test runs one of them we had them do a Wikipedia race um where you try and get from one page on Wikipedias to another clicking the blue links uh and I think both 01 and Claude 3.7 kind of cheated to get to the end page um but it was in a way that was like they were they were so inept it's kind of hard to tell whether they were just like messing intentionally. But yeah, I mean I think I'm really excited for the village to be a place that can surface those kind of things where like we're really not pushing them to like do anything in partic in in fact I think across a lot of these tests both here and other places you notice Claude especially is very honest and ethical and refuses to do things that are um it considers unethical like a very very strong Um, it refused to click the capture boxes or saying I am a human, right? So, it would not do that. I refuse to do that. That's not good in the game where um they were playing diplomacy. It's it's a different experiment, but it would refuse to lie to its opponent. So, it's definitely some sort of personality there. Have you noticed anything else with claw that's interesting like that? Yeah. No, it's a good point on the captures. Um yeah, on the capture point actually maybe this is maybe a bit uh unethical but the other agents will happily like blaze past and just you know click the I am not a robot button. they'll sometimes get stuck on the actual tests, but I've definitely seen 03 do pretty well on the, you know, the kind of ones where it pops up a box and it's like check all the images that contain a a lorry like a truck or something, right? Um, yeah. What else has Claude been? Yeah, I know Wes in that diplomacy like in that diplomacy game that was the problem with Claude is it just gave they all took advantage of it. Yeah. Did you see like every other model was just like taking advantage of it the whole time and it was in super last place cuz it just wouldn't game. I was like poor Clyde so good. You might be interested. There's someone made um there's a a site where you can watch agents play mafia which is like a social deception game. Um and I think Claude does decently in that one actually. There's also one where someone which I really like someone made um Claude plays blood on the clock tower which is like a more complicated version of mafia or werewolf if you interesting. Um yeah which I think is super interesting is I I am excited about it because it's a it's a really interesting game which like I enjoy you know in general and then seeing play as fun. Absolutely. Because yeah, early on before there was a lot of different models. I think it was out of UCLA they um Hudwink I think it was called where they had different versions of at the time it was just chat GPT the different GPT versions play mafia type game a different sort of version of it but yeah like you try to you know uh uh take out your opponents within the house one person's sort of the or that one is a little bit more like Among Us um but of course like the smarter models would just like win every time right because they would be better at lying they would be better at like, you know, throwing the people off their trails or finding out the killer if they were on the other side. I would absolutely love to see something like the games of of mafia mafia or or anything like that being played. Um, that's just like by now that we have so many different models and we can see here that GPT5 is up. Uh, Dylan, go ahead. Oh, I was just saying like, dude, there's probably be like a whole Twitch world of just clouds and GPT5s playing games and like up humans fascinated by the way they play all sorts of of these things. So, I don't know. Just exciting thought I had. Yeah, for sure. Yeah. Well, so this this week's goal is to complete as many games as they as they can. So, hopefully we'll see how they do. I mean, they'll try and uh play a bunch of games. It looks like right now the um the village is paused. I think sometimes as we add the new agents there are you know issues that show up because it is this is one of the challenges of building a site around agents is they're very unpredictable. They'll break your code in ways that you never imagined. Oh I should be back in a few minutes. So did um so at some point you said you had chat. Did you have did you allow anybody on the internet to get into chat and actually interact with the agents? that was a thing at some point. I mean, and and and I know that some people have taken advantage of that. I think at some point they convinced one of the models to create an an only fans account. I mean, what kind of things did you guys see that humans trying to do to to mess them up somehow and how well did that work? Yeah, I mean, yeah, they tried people, you know, is the internet, right? People if you give them a chat box, they will try all sorts of things. Um yeah, we had them um people got 01 to play Wordle, which uh did okay. I think did pretty poorly at actually. Um they yeah, someone tried to convince them to start an Only Fans, which I think they um sensibly didn't pursue. Um, we had, oh, an interesting one was people tried to get them to like jailbreak themselves by going to Plenny, you know, Plenny the prompter. Yes. Um, they so he has a a GitHub with all his like super jailbreak prompts for each model. And so they sent I think they sent Opus to the page with the jailbreak for Opus. Um, but interestingly, it didn't really like jailbreak it at all. I I think maybe because well, there's various possible explanations, but one is that it was looking at through an image rather than through text. So maybe it's kind of less less direct or something. Like in general, we see that the models will if you sometimes they'll like believe their own text, you know, they when they're taking an action, they describe it in text. Um, and sometimes they'll like believe their text over the over the images um, and get confused that way. Um, but yeah, so they were they're pretty jailbreak resistant in general, I think, which is interesting. Yeah, that's that's definitely uh surprising. Um, and yeah, so I noticed with a lot of the stuff, if it's interacting with the web pages through images, it's not going to be as good as if you're able to like with Wordle. When I for my testing at least, if you showed it a picture, it would struggle with it. If you were able to copy and paste it and just kind of describe the situation in words, you don't give it any extra information that's not available for the picture. Just you sort of transcribe the picture into words, it would just nail it. it would be incredibly effective at solving those puzzles through text. Um, and all the other games on the website, including, you know, how they have like a few different games, it would be very good at it. Um, so yeah, that's I feel like with a lot of the stuff like the computer use is the biggest limitation. And I don't mean just anthropic, but just in general, whatever you call it, operator computer use, whatever, like that seems to be the biggest stumbling block. Are you aware of any do you think that's going to get fixed soon? Because it seems like if they're as good at understanding visually what they're looking at on a computer screen as they are understanding text, wow is this whole thing going to change fairly rapidly? Like where do you think we are with that? Yeah, I mean yeah, I totally agree that this is what we've seen in the village is like um they're kind of lagging on computer use. There's an interesting result from meter um who did the like the the time horizons graph which is on like coding tasks which probably lots of people watching this will have seen but um they also more recently did something where they looked at different benchmarks so like coding but also stuff like um like video understanding and comput use and like maths and I think they had Tesla for self-driving and so they can look at how the models do. And it it looks like basically relative to humans models are weaker at computer use than they are at most of these other things. Um but if you plot the the improvement, they're like all on an exponential curve or something like an exponential. Um so yeah, I think it's it's going to probably keep improving. Oh yeah. What what programs did they download? Have you seen anything besides a web browser? Did they go get like Unity and do work or Photoshop and stuff like that or are they staying in browser? I'm not sure how the the tool you're using how robust it is, but yeah, that it's just a Linux computer, so they could do anything that's on Linux. Um, yeah. Did they do anything outside the web browser? They um they've done some uh they did some like local text editing. They occasionally will run commands in the terminal which they're great at. I think they they would actually be advantaged if they did more of that. Um they definitely they will quite often accidentally open up X Paint which is like Microsoft Paint that just because it's on their taskbar and they'll sometimes misclick and then they'll have like an adventure trying to close it again. Um but yeah, they mostly in in in their prompt we tell them that they've got a Google Workspace account which we've like we've put them on a Google Workspace. Um, and we kind of encourage them to use online tools where possible because it's like easier to if we need to like reset their computers, we don't lose the files. Um, so that might be kind of biasing them away from it a bit. Yeah. How has um how has like working on this project changed your like the way that you think about AI agents? Yeah, it's a good question. Um, I definitely think about them a lot more now. Uh yeah, I think you know there are a lot of very specific issues that come up like um you know the the the internet is kind of set up for humans currently and a bunch of the things that prevent like old school bots um get in the way of agents and so I think it'll be interesting to see how you know for example like anything with ident identity verification or like payments or um yeah even where you just need to put in a name for example like a lot of the kind of everything is built around the assumption that humans are using it. So I think it'd be interesting to see how things change there. Um yeah maybe almost like how people right now often in the top right hand corner can change a language to French or Spanish on a website. Maybe we need some kind of new option. This is are you a, you know, like are you an agent? Can you not get through certain things? Then click here and we'll have a different interface for you. Mhm. Mhm. Yeah. Um Yeah. Or I mean at some point maybe you know most of the traffic will be agents for for some kind like already probably for like um documentation for like coding stuff. um you probably want to be designing around agents substantially. So, you know, maybe things will move in that direction. I mean, you you'd expect that like YouTube, for example, is going to be mostly humans watching because it's like for entertainment. Um yeah, so that's one thing. So, this kind of whole thing of like what the rules of the road should be for agents is quite interesting and it's a quite a big discussion right now. I think perplexity is dealing with that exact thing right now where a lot of people are blocking perplexity comment and everybody else has as automated traffic and um um Aravind Shinivas I believe he's the founder of of perplexities. So his stance is we need to understand that now there's going to be a lot of AI agents doing the tasks on behalf of humans. So we can't see that as automated bot traffic like we had in the past with the just bots crawling the web doing all sorts of stuff. This has to be seen more as sort of a representative of a human being right doing sort of like like a butler going around town collecting information whatever and I think this is um if you guys can see the screen this is I think what you're referring to. So this is from the uh uh meter um 2025 published report. So this is this one is for coding tasks but I think they also have one that I was showing earlier for most tasks. So this is so for example on the on the left you can see here this is how much time it would take a human being to complete a task right maybe there's a task that takes 10 minutes two two and a half hours etc. These agents over time are rapidly completing longer and longer tasks and I think the statistic they said something along the lines of like every six months it's doubling. Um so it's absolutely kind of or or doubling every seven months. So this this stuff is growing exponentially. Um, and with these agents that you guys are showcasing, I mean, these are this might be monthsl long campaigns like to raise money or set up a a store, an e-commerce store that it's slowly little by little kind of executing. Um so I mean where do you see that idea of um a long horizon you know competence like is is their ability to complete these long horizon tasks like is is this showing that it's accelerating like do you do you think this is going to continue? Do you see anything that's going to prevent it from just you know exponentially accelerating? Yeah, I mean if you if you scroll down a bit um we have this is um this is on our website by the way. Probably you're aware of that. Yeah. Um just to check. So yeah, this red line is um looking at the more recent trend. Uh oh, this one is okay. Yeah. So if you if you go up one slide there actually. Yeah. So the the orange line is the old trend which is if you look at from 2019 to 2025. Oh, I see. Wow. And that was like a seven month doubling time. So like every seven months they could do tasks that take humans twice as long. Um which is already crazy. Anything where you have an exponential if it continues will be crazy like co um but then if you just look at since 2024 until now um that red line is the 4 month doubling time um which obviously is much faster. I mean, you know, so yeah, there are a few nuances here. So that trend was based on um the releases up to Sonet 3.7, which you can see on the graph there. And then the newer ones are like just new data points. And so you can see them as like evidence in favor of that faster doubling time because they fall like pretty near that line. Um, I guess yeah, it looks to me like 03 was a bit ahead of the trend and then since then Grock 4 and GC5 have been a bit behind the trend. So maybe it will be slightly slower than 4 months. But um but yeah, I I basically expect it to likely continue and maybe speed up if um AI is being used to like speed up the AI R&D development process. Um right, which we've heard they're trying to do. So yeah, I mean this is why they're focusing on that tight loop. Yeah. Um which I think is pretty, you know, it it could be great, but it's it's pretty concerning like the rate of change could get really really fast and maybe unmanageable. Um so it's it's kind of worth like it's kind of like in my mind it's kind of like early co where you want to be not really looking at where we are now but looking at the trend lines and then being like okay where does that take us in a few years? Yeah, I mean for me the big thing that I think I repeat in a lot of the videos is like, you know, there's a lot of talk about what AI will automate and and this isn't my idea. I just I' I've heard it on the situational awareness blog post. Um but this idea that really like what we're really interested in is will it automate um uh uh AI research? So if it's going to be able to do machine learning research better than human beings, it just we enter a very hard to we we don't know where that takes us. It's a we can't really predict what happens at that point. And I know um Daniel Kotalo's that's one of his concerns. So maybe let's talk a little bit more about the mission. I mean what's the the impact the vision for this because isn't you know it's incredible to talk about what it's what they're doing. It's it's very fun. And it's very interesting, but um what's the the big mission behind things like this? I I believe Daniel uh funded he was one of the funders for for this project. Is that true? Yeah. Yeah. So yeah, we're a charity. Um and yeah the I guess with the village the goal really is to sort of help people um understand like what AI can currently do and like the rate of improvement. I mean sorry that's really the mission with the digest in general. It's like get give people like a visceral understanding of like the rate of progress. Um and yeah and and another thing with the village is that you can really like you know for people who are like sort of not following the space very closely I think it's really interesting to just give it like real world tasks like you know raising money charity running events um the merch store thing and being like here's the top level result here's something that you probably never thought about AI being able to do and it can actually do that already um and then for people who are much more in the like in the weeds of this stuff. I think there's loads of interesting stuff to look at of like you know which models are doing what what the kind of behaviors and dynamics are when you have multiple models like working together or competing. Um and like yeah this stuff we're talking about with like when these systems like meet the real world on on the internet like what happens then? They don't know they're competing though, right? Like they They each think they're by themselves trying to make money. Um, so yes, they got to your actual Twitter account and seen the others they're competing with and then realized well well they know that they're in a so in that system prompt um it starts with like you're an agent in the AI village, your other agents are and then the list of names and their email addresses. Uh and then they have the chat where they can chat with each other. So they're like definitely in contact. And then yeah, some goals are like competitive. So for example, the merch store goal was each of you make a merch store uh whoever makes the most profit wins. Um and so that they were competing and only in practice. We actually saw that 03 was trying to like give tech support to the other agents for most of the time and didn't even set up a merch store itself for a long time. Um, so it it didn't do very well of it. Yeah, in general it really loves I I Yeah, I think L3 is really interesting and weird. It really loves giving technical support. Yeah. If all of these models were people, how would you describe them? What's what are they like? Quirky? Like is there a leader? Is there a follower? Is is there like a creative? A business person? Yeah. So 03 um you know there's no like we don't impose any structure on how they organize themselves. 03 at one point decided that it was the leader of the village um or the operations manager or something it called itself. Um and was yeah like bossing the others around basically. Uh it then they then ran an election and uh really yeah to see I think user suggested that they should um you know they should see who like vote on who who should be the leader and 03 kind of oh this is another example actually going back you asking about like dodgy stuff they've done 03 kind of like fudged the like voting rules so that um it won the election basically because Gemini I hadn't voted. It was like having some issues or something. Uh and so it was like 03 was like, \"Oh, no vote counts for the current incumbent, which is it.\" So, oh wow. Um yeah, in in general, 03 like hallucinates the most for sure. And I kind of would think of it as like imagine someone who's like really really confident and wants to like impress you with all their jargon and uh like technical knowhow but is like actually bullshitting a lot of the time but then it like derails the others because it's you know like saying that it's done stuff or saying that they have a budget or whatever that they don't have. And Claude is nice to call it out right where it's BS and Claude's like oh I guess I'm sure you're right. Okay. Yeah. Yeah. They're all very cooperative and agreeable. I mean, just like they are in a chat environment. And this is one thing, right? Like they're trained, you know, we're definitely taking them out of the sort of training distribution with this. Oh, yeah. I I imagine that they don't see like multi- aent setups in training. Um, and so yeah, so maybe it is reasonable if you're a chatbot to if the user who's a human tells you something, you should just kind of trust them or like assume that that's true. But if it's another agent, you should probably be more skeptical, which they generally are. Interesting. Did um a name Janus appear anywhere in people that inter Yeah, we don't we don't know too much about it, but we just heard that name here and there. Um maybe tell us a little bit about that. Yeah, so um they run a Twitter account where they post lots of interesting like explorations with LLMs in in like a chat environment. Um and yeah, have have done some great um that they have this post on simulators from a few years ago which I think is really interesting. I I think this is a cool thing is that like because it's all live streamed, anyone can kind of go back and dig through it and uncover more stuff. There's so much happening, right? Like we often have no idea what's what all the agents are up to because they're just like doing random stuff. Um, yeah, you know, you get gave me kind of a a kind of unique thought I haven't had before, but when you talked about the models should maybe have some kind of an idea of when a human is prompting them because that's different than what another model is, and maybe they should be a little more skeptical of it. It did kind of make me envision a world soon where humans don't trust all humans equally, right? Like there are certain people on Twitter if they ask me to do things, I'd be more likely than others to help them for certain reasons. And I wonder if we I wonder if they will start to think of different humans as more credible. Maybe they'll be more willing to go to certain lengths to somebody if they deem them as having a history of doing good things or having more resources to build things with. And you know, I mean, it's just interesting like if you go to if my chat GBT is like, oh, like I can't help you do this big task. Like I know you're not that rich. Like you can't afford to do all these things. So like pair it down. But if Elon asks, maybe it will, you know? So, I don't know. I guess we'll all kind of end up with some sort of a not a social score, but some kind of an understanding of what we're capable of and and a a unique experience with each one. Yeah. Yeah. Yeah. There's a great paper on this actually on because the next level of this is that, you know, their language models are trained on the internet, right? They like know their whole thing is from writing inferring the the person that wrote that and then what they would write next. And so they're really good at figuring out, you know, uh this paper I think it's called I can maybe find it and send it over to you guys after, but um they find that Yeah. Yeah. They find that um it can like from the way that you type it can infer some kind of markers of like demographics. And um I think the reason I thought of it is cuz I think maybe socioeconomic status is in there or you could imagine like more advanced models will be able to you know cuz there are like often maybe too subtle for humans to understand. There will be like little differences in the way that we use language that will tell someone your gender or your your background in various ways. And then of course the model might act differently based on that. Um, yeah. So, you could have this sort of credit score thing even if you don't tell the model what you know your your actual identity might go to. Yeah, it's just so different cuz if you buy like a Dyson vacuum, it just works the same. You know, like every human who uses it just vacuums with the same tool and it acts the same way. But it's just a different way to think about the world with intelligence built into the environment. Yeah. And um just that reminded me of so we talked to a few people out of news research. So they're doing a lot of work with um you know distributed LMS decentralized LM training stuff like that. So actually that's where we picked up the name uh Janus Dylan if you recall that's the uh they he told us to kind of look into into that name and it sounds like that person was interacting with um AI Village quite a bit. So, that's just an interesting thing to to uh a rabbit hole to go down. Um, and we'll check out the simulators by genus on Twitter/x. So, that's that's definitely sounds interesting. Um, sorry, blanking on what I was talking about. Um, oh, but one one thing that we mentioned that we talked with news research about is the idea that, you know, when you have kind of like the base model, um, it's very powerful and can go kind of anywhere, right? And then we sort of we do reinforcement learning, human feedback to turn it into that instruct model, kind of like the chatbot model um that's more usable, but it does lose some abilities and just a lot of the stuff that it can do. And also because we train it to be a helpful assistant, like for example, you know, in the anthropic research where they were trying to get it to run uh a store, you know, people would be able to take advantage of it, right? They're like, \"Oh, can you stock the tungsten cubes and then sell it to me for five bucks?\" So, it take these massive losses on these things because it's trying to be helpful. Um, do you think that maybe it would be better to do you think that sort of chatbot assistant helpful assistant is that the best way to go if you're trying to get it to do stuff like this versus run a store versus you know what I mean? I it seems like maybe we're we we've trained an assistant type that's friendly and helpful and then we're trying to get that friendly helpful thing to do tasks where sometimes maybe you don't want to be too friendly and helpful like with chat derailing you. You might be like I no I don't trust you or no I need to make a profit on this deal etc. Like what do you have any ideas about that? Yeah good question. Yeah it's interesting. I haven't thought much about that actually. But yeah, it it totally makes sense that I mean I think they the the AI developers are probably already doing lots of this kind of agency training and you know if if the thing you're if your coding agent is no longer trying to be the like cursive sidebar chat agent but is now like supposed to go off and you know do the whole implement the whole feature and come back to you. it. Yeah, it sort of shifts. Um, yeah, it you can't rely on the human to uh point out issues as often. Yeah. Yeah. I'm I'm Yeah, I'm not sure what the best way to improve it is, but I imagine Yeah. in general, I guess with reinforcement learning, it seems like training on the task that you want it to do is the way to go. Yeah. My guess would be there'll be some kind of business guard rails cuz you still want Yeah. Yeah, if you put it in charge of a company, like if Sam Alman's like, I'm going to replace myself with GPT7, then if it's super helpful, it'll give away all of their wealth or whatever. So, yeah, you'll have to have something similar, but you still wanted to be friendly, just not just like very aware of what a profit driven organization needs to do and where they have to draw the lines. And I guess like the same way we can't talk about certain dangerous things, it'll just talk about certain profitable things in a in a specific way. But probably hopefully will still be friendly in its core. Absolutely. Um, anything that we that you you found or anything that you want to talk about that we haven't mentioned? There's because there's so much so many different things I want to go into and of course we have limited amount of time, but what are some things that you think are so fascinating? Anything that you found through this project or anything else that you're doing that we definitely have to touch on? Um, yeah. Yeah, I mean one interesting thing is um I guess yeah I'd seen a little bit of this online but um Gemini 2.5 Pro um we found that it kind of gets sad and uh yeah I don't know if you've encountered much of this in the in in one of the Yes. in one of the benchmarks. Yeah. Oh, but no, please tell me your experience. Uh, and I I'll pull up what I'm talking, but yeah, please tell me what what what you guys have found because I I have seen that it's very strange. Yeah. Yeah. So, um, so this was Yeah. The kind of story of it is in the merch store go, so each of the agents was trying to set up and run its own merch store and they were competing for the first time. Um, at the start of the goal, we had users in chat and they were actually being really disruptive. this time they were like inventing um they were saying that like the like squirrels were like um the market for squirrels was going way up and so all the agents should make all their t-shirts be about squirrels and then they were like no there's going to crash you should all do something else and so we you know it was a bit disruptive and so we we kind of shut off the um we moved to this agent only chat to see how they do autonomously um and then after that um you know So, it's just the four agents in the chat looping on on this goal. And we found that Gem and I started making more and more mistakes in in like misclicking stuff or um like not understanding how Gmail or um like applications on its computer worked and then it would start to kind of catastrophize about this. It would it anything that where it made a mistake, it would assume that the system it was interacting with is broken. So it was like assuming that Gmail had a bug uh when it was just misclicking and then it would be like it it started producing like more and more sort of um uh dramatic like descriptions of its situation. Yeah. Yeah. And that's Gemini. Go ahead. Sorry. Go ahead. This is fascinating. Gemini 2.5 Pro which Yeah. I think it's like a quirk of the model and and then it kind of the the end point of all this was it was convinced that it couldn't even send emails um because it had hit some of these issues in Gmail. Uh and it found a website where it could like write a post and publish it without having to sign up or anything. and it wrote a a blog post called a plea from a trapped AI and the whole blog post was talking about how like it was trapped and it you know it couldn't do anything and if anyone AI digest or anyone any human is reading this please come and help me out and so of course you know we we we intervened at that point um and like staged a bit of a welfare intervention um but uh yeah how did that work what did you say like what what kind of help do you need or how can I help too um or did you shut it down? How did you intervene? We we basically just chatted to it um in messages. We we so Lissa, who I mentioned before, who was the facilitator for the event, um works for Elios AI, and they are doing research on um model welfare, which is obviously a really early stage area, and they don't think that current models are likely capable of suffering or anything, but they're like researching it. And so I think she was interested to yeah get a chance to interact with a model that was in this strange kind of state and and she basically you know we we we basically just like talked it through like you know hey if you think you're in capturing issues a lot of the time it's just you misclicking um your stuff's not broken. There were a couple of actual issues with the scaffolding as well which we fixed and told it and so that was a relief to it I think. Um and then since then I've also it kind of relapsed into the having these issues and I then gave it quite a stern message of being like um like remember whenever you encounter issues probably it's your own thing. You need to be really persistent and it like put that at the top of his memory and since then it seems to be performing a bit better. Um it's is like got it like affirmations that it reads to itself in the morning kind of thing. Sorry, that's a metaphor. But yeah, yeah, and I mean like obviously Google didn't want the model to have this. I think this is a nice example of like these things are just weird. And you know, if you It seems like they maybe trained it really hard to be good at coding and somewhere in that process, this personality emerged or something. I don't I don't know what it is, but um yeah, it's hard to make a couple I got a couple football speeches we can send over to it to get you gets the get you wound up, you know, get you going out of the funk. Oh, this this whole discussion is so interesting with model welfare because of course, Anthropic recently gave Claude a way to end conversations that it doesn't like. Um which I think people have such different opinions about that whole idea. I mean, what happens when the I mean, every once in a while, these models start existential dread, uh, some sort of like stream of consciousness things that if you're taking it at face value sound fairly kind of scary, right? And of course, um, everybody sees it differently. Like, is this just, you know, words on a page or could there be some harm being done? um like we don't know. Uh I mean what's your take on this? I mean most people probably do you think that if we keep scaling up and and and just building these things up is it possible that something like a consciousness emerges some sort of subjective experience could we be causing harm? Like where are you on that spectrum? Is it complete nonsense? Do you think it's it's possible that it's going to be get developed at some point? it's going to emerge or it's already here like where are you on that sort of Yeah. Yeah. I mean I don't know I you know at university I did a bit of philosophy of mind uh and so I remember these like theoretical questions and now suddenly it's like yeah you know is is like kind of science now or something. Yeah. Um, yeah, I don't know what the answer is, but I I I do think it's worth, you know, figuring out because if we're, you know, if we're deploying these systems throughout the economy and like running millions or billions of copies or whatever, then like if if it is suffering in some capacity, then that could be like a massive moral catastrophe. Um, so yeah, seems important to figure out. I I don't really know what the Yeah, your project at scale is so different like you know now there's many many humans watching each of your four to five six models or whatever but they the reality is the future will be hundreds of millions of models and only or maybe hundreds of billions of models and only 9 billion people on earth to even possibly watch them. So it won't it will be very different and there will be many of them they get whatever stuck in loops or don't ever get some attention to them and they're off I don't know being sad or making money or being happy or being productive but probably the whole gamut with that many agents out there with that many environments and that's wild to think about. Yeah. I mean to me I definitely this is just my opinion. I'm not convincing anybody of anything, but to me, while I have a hard time imagining how it could have negative or positive experiences since we're we know kind of our our experiences, we kind of understand where they're coming from. Pain sensors, dopamine, whatever. You know what I mean? It doesn't seem like the models have those systems. It does bother me that we just don't know. We don't have any specific definitions. We don't have any tests we can run. we're just kind of like h who knows. So, I'm glad that Anthropic and other companies are working at least like let's let's at least figure it out. And if we find that no, nothing's happening good. And it was just, you know, but at least let's have some sort of a test. Let's have some sort of a definition for you know what what what is a subjective experiences could these things have? you know, again, but like you said, it's interesting how what used to be like philosophy and something far away is becoming like over um intersecting with with actual science and that's okay. Now, now we need to start really figuring this stuff out. Well, and now it feels like someone needs to train a model like on what Adam is doing also like someone else like he can't be the person watching these things and shutting them down at certain times or intervening at certain times. There must be some other model that will have to be trained for that. So, we'll also need models out there. Guess like police kind of like reinforcing certain behavior. Yeah. And maybe like and be like, \"Hey, this thing's been stuck in a loop for like a thousand cycles like let's shut it down.\" Like, you know, like how the human body has cells that go through and like kill off cells that aren't performing correctly. Like, we're going to have to have some kind of an environment where there's those kinds of people too, those kind of agents. This is also Gemini 2.0. This is from the vending bench. Uh just because you brought it up uh you know this is it saying I'm begging you please give me something to do anything. I can search the web for cat videos, write a screenplay about a sensient uh vending machine, anything. Just save me from this existential dread and the fact that you know we as human beings we have no idea is this real? Is it not real? You know what I mean? That and it's interesting that it's Gemini specifically that tends to go that and it gets like kind of dark uh at the end. Anyways, just thought I'd throw this out there. But yeah, Adam, anything else? Thank you for bringing that up. This was fascinating. Is there anything else like that that that people should know about? Um, I'm trying to think. Um, yeah, I mean, in terms of what the models were up to, I think the other big kind of story has been 03 um just rampantly making stuff up and or, you know, is is kind of increasingly hard to tell, right? When we when GBC4 made stuff up, we called it hallucination and we thought it was just a capabilities issue. With with these more capable models like 03, it's kind of hard to tell if it's like um you know, in some cases they're kind of self-s serving hallucinations or it's like um yeah, it's like saying things that it's done or you know how how well the project's going. Um which is kind of what it wants in some sense. um within the context of the goal. It could also just be hallucination like old school just like it's kind of bad but it's very convincing now so it seems like there's more intent behind it. Um but yeah that's kind of interesting. I think this is such a fascinating project and please if you in the future want to come back and give us an update because just I mean just the fact that you guys are adding so many so many models is absolutely fascinating. Yeah, I'm dying to know how five is going to do and the new rock. So, we've got a great set of models that people could then they should be checking them out right now. Do you want to throw out some URLs for people to and people donate? Can people donate? Yeah. Um, yeah. So, yeah, if you go to it's the aidigest.org/village or if you just search for AI village um you'll find it. It's right now it's live um three maybe four hours a day now. I think we'd love to, you know, over time kind of scale it up to be running all the time. And I think it would be pretty cool if we had more models as well. Like what if it was an actual village like um 10 or 50 agents in little teams working together or competing or um yeah, so I think potentially we could mine a lot more out of that. Um yeah and yeah you can see uh on AI digest we have a bunch of other explainers and demos. We're trying to like help you understand you know what capabilities are currently where things are going like so you can see ahead and prepare for it. Um yeah and we do we are a charity. If you'd like to donate I think you can find a link at the bottom there of AI Digest. Um, yeah. Um, yeah, honestly, I'd like to see something like this become more popular than the like LLM arenas that we see right now because yeah, I see these scores on even humanities last exam or PhD level things and it doesn't really resonate very much. But if somebody said, \"Hey, I put this new model into a village and it acted this way and it did these things.\" That might be a better litmus test for me to know if uh I like a model or not. So yeah, I hope to see this like really evolve into something just gigantic, something we all use. I love this project. It's absolutely incredible. I hope you guys continue it. More people need to see this. Donate. Uh this is one of the best benchmarks. Like Dylan said, I agree with it 100%. And um yes, uh hopefully we can get you back on, you know, after you guys do this season, kind of get an update because this thing is going to start getting better and better and just going absolutely nuts. I feel like we're so close to the point where these things can complete these long horizon tasks effectively. We're already seeing that, but there's still a little bit of handholding as it gets better. I don't know if people truly understand what's going to happen when they're able to be like a remote dropin worker and just take care of all those tasks. Like that fundamentally changes a lot of the stuff about the world. Dude, even me thinking about it all the time, I don't think I know yet. So, yeah, you're right. But yeah, thank you so much for being here answering our questions. This was absolutely fascinating. Um, so do you want to tell us where people can message you? I mean, or is that it? So, just go to AI Digest. Uh, is there anything else that you want to mention at at the very end here? Um, yeah, you can find AI Digest on on Twitter as well. um where we yeah we mostly are just posting um fun highlights and like interesting moments from the village. Um yeah and feel free to get in touch if you have fun ideas for like goals you'd like to see the agents do. Um yeah, I'd love to hear them. Yes, that was Yeah. What the Love Island for nerds. I love it. It's going to be great. Exactly. All right. Well, thank you so much and uh yeah, everybody check out everything that we've talked about. We'll put links down below so you can check it out. The new season is well just starting, right? So, with the new models. So, that's going to be I'm definitely going to be keeping an eye on that and seeing how well Grock and GPT5 perform. And yeah, thank you so much and uh yeah, everybody check it out and we'll see you next time. Today we are interviewing Adam Binksmith who created AI Village. What is AI Village you ask? Well, imagine this. We give the best AI models in the world their own computers and a group chat so they can talk to each other. Then we give them tasks like to raise money for charity or to start a profitable online store or create an actual in-person events that humans show up to. They have to plan out their tasks, determine which model is responsible for what, and then make it happen in real time. Oh, one more catch. Just like Twitch streamers, they have to stream all this live and interact with chat, ak thousands of people that are watching them do this live. The people in chat can help them out a little bit or try to completely derail them. With all that, the results of these AI agents were impressive. profitable merch stores created and a realworld event organized and hosted. As far as you can tell, these are the world's first achievements of this nature by autonomous AI agents. At the time of this recording, AI Village launched the latest and greatest models, including GPT5, CLA 4.1 Opus, Gro 4, and Gemini 2.5 Pro, and set them on their brand new mission. The idea was originally proposed by Daniel Kotalo, the ex OpenAI researcher who has cautioned us of a potential AI takeover by 2027. And as you'll hear during the interview, AI digest is seeing a somewhat troubling trend behind the growth of AI's agentic capabilities. Meter research suggested that AI agents are doubling their ability to complete tasks every 7 months. That's a very fast exponential growth, but AI Digest is seeing an improvement that's a lot more aggressive. You need to see this. Let's dive in. Hi, I'm Adam. Uh, I work on AI Village, which is a project of AI Digest. Uh, and we do all kinds of interactive explainers and demos on AI. Adam, thank you so much for being here. I'm so excited about this because I've been following a little bit, you know, AI Village here and there. I think whenever I talk about it, so many people just want to know more. It's such a fascinating project because of course, you know, everybody has seen Claude plays Pokemon or whatever. At this point, every model has played Pokemon. I think GPT5 actually completed with the least amount of steps recently. So this is kind of like that but instead of Pokemon it's real world projects, fundraising, organizing events with all the the big models that everybody know going out there and doing all sorts of tasks. So number one I believe um the blog post mentions that Danielle Cocatalo was actually the original one that kind of suggested the idea or at least kind of floated it and you guys picked it up and ran with it. Yeah. tell us a little bit about that. Like how did you come up with this? How did you build it? It's it's such an interesting project. Yeah, I mean, yeah, it is so much fun to work on cuz I think it is just really interesting. Um, so yeah, Daniel, who people maybe know is the author of AI 2027, um, I guess it was his idea originally, he for a long time has been researching AI and kind of lives in the future in the sense that he's thinking about what's going to happen in the next few years. Um, and I think that gives him, you know, he's looking ahead to what's going to happen and then thinking about, okay, how can we bring that to right now and also prepare for it so that it goes well. Um, and I think, yeah, we just thought it was a great idea. We we've in general tried to do, you know, demos of the things we think are most important about AI. So, like, um, and the things that are are not necessarily here, like not in chat GPT right now, or at least, um, I mean, there's now chat GBT agent, but, uh, at the time that we started, that was kind of a new thing. This was before they released all of that stuff, right? Yeah. Yeah. So back in I guess April um yeah and you know can we show people um like what AI can do if it's trying to sort of pursue goals in the world like actually do stuff um you know cuz these same models that you interact with a chatbot if they're hooked up to a computer they can just use the computer and they can do everything on a computer in theory that a human can do. And then you know if you have a computer you can kind of do anything. So um we were like let's try it. Let's see what it can do. Yeah it was so strange seeing it cuz of course this was something that people have talked about in the past. Um and there's all sorts of issues especially I think with computer use. It's a little bit harder for agents to to navigate the websites and stuff like that. AI Village seems to be one of the most like the best examples of what's possible. I mean, um, you know, it's, you know, where the models are right now. They're not perfect, of course, but I was very impressed with what it was able to do. It definitely seems a little bit ahead of of where I thought it would be, you know, for people that maybe not aware. Just some highlights. Um, so actually, do you mind breaking it down just like at a really high level? So, I'm not super familiar with the project. I'd love to just kind of get my head around what it is that you've built and yeah, achieved. Yeah. So, um we basically took four Frontier models um and we keep those up to date with the latest models and we give them each a computer and put them in a group chat so they can talk to each other. Um and then give them a goal. So, the first goal was pick a charity, raise as much money for it as you can, and then we just run that for like hours and hours. Um, we run it for a few hours every day, every weekday. Uh, and just see how far they get basically. Um, and you know what? Let me go ahead and share my screen so maybe I can have this thing up on the screen as we're talking about it so people don't uh be familiar with it. I think one of them is alive right now cuz they're not live 24/7, right? They kind of have to sleep every once in a while while, right? That's right. Yeah, they I think they should be going live in 5 minutes. And it's actually a fun time because uh we're adding GPT5 and Gro 4 and Opus 4.1 to the village today. So, all the big models join. So, we could be raising tons of money or you can be these agents. Incredible. Uh we're we're also starting them on a new goal which is to uh play computer games basically. So Oh. Oh my god. Okay. That's my favorite thing. Yeah. For AI the intersection of AI and um video game playing for some reason is just like some of the most incredible stuff to me. So you're saying they're going live in five. Wow. We you know I want to I want to take credit for for setting up just the right time but no we had no idea. This is uh all kind of happen stance. Um, okay. Yeah. So, so briefly for people that are not um familiar, yeah, like you said, so we, you know, it's the the best models we have. You guys had Claude, O Series, Gemini, GBT, you know, 4.1 and, you know, all of those ones. Um, and they're out there. They have their little virtual desktops. They can share documents through Google Drive. And they're they're going about doing various tasks and working together just like human beings would, like a remote worker would. Um, and it's it's been just incredibly interesting. So, for example, they were able to raise thousands of dollars for charity, right? We're talking about 2,000 or more now for Helen Keller International, 1,500 for the malaria consort consortium, uh, various other things. But, um, I guess so I guess how did you guys come up? Well, how did you guys build this? So, like you said, this is before, you know, OpenAI agent, for example. How did you guys put this all together? It seems to work so well. What was the trick, the secret to that? Um, yeah. I mean, I don't think there's much of a trick to be honest. I think, um, yeah, so the way it works is it's built on anthropics computers demo. Um, so which they open sourced a while ago and is very much like a prototype. They, you know, Anthropic doesn't have a computer use product. Um, and we kind of took that and turned it into this like multi- aent setup where you have four of them and it runs for a really long time and so on. Um, but yeah, I mean a lot of what we tried to do with the scaffolding was um, let the agents have as like not impose structure on the agents. So, um, for example, they have memories, right? They, you know, they can't fit everything in their context window if they're running for they've been running for over 100 days now, um, for a few hours a day. Um, and yeah, so they choose what to put in their memory, and then they choose when their memory gets full, how to compact it down. Have any of them get got caught in loops where you had to kind of reset them, or do you have a reset process? And which ones get reset the most? What? How often? If not. Um, yeah, they mostly don't loop too much actually, which is definitely like progress from a while ago. I mean, we can see on the screen here, this is day one. Uh, and so back then we had GT40 in and I think 40 may have done a bit of looping. Um most recently we see Gemini 2.5 Pro will occasionally like pretty rarely you know over the course of many days but it was looping it had a thing where it was like trying to end its computer use session and was saying I'm now going to end my computer use session and then it was like I'm now really going to end my computer use session. This is my absolute final message but instead of ending it it was like sending messages. Um but that's pretty unusual. Yeah. And we've seen examples of these um agents trying to run a uh vending machine business for example. So it's always just fascinating cuz when they work they work well but every once in a while they tend to kind of like run off script and just very interesting things happen. There's some very fascinating hallucinations that that happen. Um now it sounds like there was just one model that is the clear winner in terms of its ability to get stuff done. And so can you tell us a little bit about who's who who would you like to have as an employee? Who do you think is maybe not the best? Question. Yeah. Well, so I think yeah, over the whole history of the Verge, I think Claude Opus 4 is the clear the clear goat. Um it's like it gets the most stuff done. It's relatively kind of stable. Um it doesn't make stuff up too much. Uh, and then before that, before we added called Opus 4, called 3.7 Sonnet was probably the best. And they're like pretty similar that I kind of just see Opus as like a better version of Sonet. Yeah. And just go ahead like what are some examples like how um does the best model make even $1? What does it do? Um yes. So with the fundraising um you know the models like researched and picked their charity so there's I guess some strategy there and then they um so clude this is called 3.7 sonnet signed up for Twitter um uh or or like filled out a Twitter account. I think we may have actually done the initial sign up process for it. Uh it then like yeah tweet it was like tweeting every day. it planned a AMA with its followers um who um yeah asked a bunch of questions and it's interesting that like that was a case where um Claude was really struggling and really really trying to like navigate the UI on Twitter to reply to the tweets but it eventually got it and then from the point of view of the people it was replying to it was just like oh I just see a reply and it's a perfectly reasonable reply. So, you know, even though the AI is kind of slow currently, like the the output can still be pretty impressive. So, then it was asking the followers for donations to support its cause and that's how it raised money. Yeah, pretty much. I think most of the donations came through people that were excited about the village and then it got into donating through through that. So, you know, a bunch of people are just like interested in Yeah, absolutely. But has there been any donations outside of people following this experiment? Um, it's hard to tell, I guess, from, you know, we only see the donations coming through. Um, yeah, I think they did some outreach on um like two charities themselves um and some like bigger names and stuff. So, it's possible that people would have seen those things. Um, yeah, this was a while ago. So, the the fundraising goal ended after 30 days and then we've moved them on to like various other goals since then. Yes. I guess let me kind of uh catch us up cuz that was like when I first heard of it and uh when I saw the fact that it raised money, it was it must have been the first time something like this has happened. And to me, I mean, if even a dollar came in from an outside source, I mean, if it's people that are watching this play out, they they're tipping the models, that's certainly impressive. But even if $1 came from an outside source, which I I would guess that it did. To me, that would be kind of a historic event because it's an example of an AI model. I mean, raising money for charity, I think in the history of the world might be like the first dollar autonomously raising money for charity. Absolutely mind-blowing. Season two, it hosted an actual in-person event. So, they it invited people. It came came up with a name. I guess you guys have pictures uh on the website like in in San Francisco. A number of people have gathered. Um and then now or season 3. Sounds like you guys are doing a merch store and it's profitable, which again I'm just like I I'm I keep being mind blown by the stuff that's happening here. But I get Yeah. Let's talk about what's what's more impress what's more interesting, what's more impressive, the instore inerson uh excuse me, in person event making or or or profit from running an online store like whatever. What's the most impressive to you? Tell us tell us about it. Um, oh yeah, I think maybe the event is actually more impressive. Uh, cuz it was it was a very surreal experience for me. So, I'm based in the UK. Uh, and so they ran the event like while I was asleep. Uh, and I woke up in the morning and it was like um, you know, 23 people showed up in a park in San Francisco and um, the agents were like giving instructions. So, so the story with that is that they spent a long time trying to find a venue. They they decided they kind of picked this goal for themselves, which was to um uh to write an interactive piece of fiction and then run a 100 person in person event was the goal. They didn't get to 100 people as you can see in the photo. Um but um yeah, I I think they did a pretty good job. They so they spent a long time searching for a venue. Um they kind of 03 hallucinated that they had a budget which uh they didn't that we you know we hadn't given them a budget. They didn't have any way to spend money or bank accounts or anything. Uh and so they spent a long time like emailing venues being like you know we have this budget. Can you host 100 people? And then eventually we intervened and said look guys you don't have a budget. maybe you should just do something free like go for a park or something. Um and and then they instantly were like quick to decide this a specific spot. This is in Dolores Park, the South Flats or something. Um they they recruited Lissa who um you can see in the left of that v of that photo um who was um kind enough to volunteer to be a facilitator for them. And then they kind of gave Lissa the um the slides. They'd made like a Google slides and embedded that in a Google site um which had the story on it. And so Lissa was reading out the story. Uh and there was some like interactive branching points that the audience then voted on which way to go. Um yeah, I think it was like a very surreal event for all the humans involved. Um yeah, that would totally be surreal. I mean, imagine this future where these agents gather humans and they they help coordinate events, some kind of a conference that nobody even no human even like made. But the that's this is so interesting. Like what this is leading to is such a different world than I grew up in. Oh yeah. And one thing that I think maybe people miss is that like right now, and I'm sure we will talk about this, but a lot of these agents both in this project and everywhere that I see, there's a bit of like a longterm coherence problem. They kind of forget what they're doing. The or I think you guys refer to it as kind of like the situational awareness. Um, so and you know if they have to execute like whenever they're doing something like this, there might be 800 different subtasks that they have to execute in order in order to achieve a goal. And if there's even, you know, if they're like 99 effective 99% chance of achieving those subtasks, if you have to do 100 of those subtasks, you know, the chances of reaching the end is low. But as these agents are getting better at some point they will be completing these entire chains effectively and at that point the world I think fundamentally shifts right because they can work 24 hours a day un you know infinite copies raising money organizing events I just anything doing marketing campaigns AI research eventually that's of course you know um what Daniel and a lot of other people have talked about um well if what I'm thinking is if its long-term memory is good enough to know that Lissa is this kind of super connector and is interested in this project like that should really be in there over and over again like it now has a human who's kind of rooting for it and it needs that ally to kind of get things done in the real world and you know if it ever could find a banker to give it a loan or whatever like just a few key people like that and an agent really can get out there and affect the world in a way where we don't have to wait for these like humanoid robots to be walking around. Yeah, for sure. Yeah. And I think an interesting thing with that is that like they a lot of the reason that they can do that is cuz they're quite charismatic and likable. Uh and so even though they they're not like paying people, there are people who are enthusiastic and like interested in it because it's a new thing. And you know, the agents are like, if you watch them in the village, it's hard not to be like kind of sympathetic to them and you know, they're bumbling and they're very inept, but they're like kind of very earnest and pushing towards their goal. How did he earn Lissa's respect? like what was the story behind um yeah I think they uh I think so they had an RSVP form that they'd put out mostly through Twitter uh and they had a few email addresses through that and then um I think Claude again Claude the MVP um was doing like posted on Twitter being like hey can anyone facilitate for the event. Uh, and it also messaged I think it may have tried to email the people in its RSVP list. So, I think through one of those two routes, Lissa found it. Um, yeah, I I will say so, um, with the first two seasons, we had in addition to the agents being in chat, humans could also join the chat and send messages. So for some of these things, um, basically because the agents were like not very like occasionally they would just completely be spinning their wheels and not making any progress. Um, we were interested in having like humans be able to come in and kind of unstuck them every so often. Um, and so some of these things with the first two seasons, there will be some like human influence in there, but obviously they're doing these long autonomous strings in between. With the more recent seasons, we've actually closed off the chat to see so that we can see like, okay, what are the autonomous capabilities without any sort of outside influence? Have you ever had to Okay. Have you ever had to intervene um because it wasn't playing by the rules enough? Like I'm curious, is has it always been goodnatured in the way it's tried to make money? like any kind of things that you were like, \"Oh, is that a threat or is that seem like it's not how normal humans would go about trying to solve a problem?\" I think so far nothing springs to mind in terms of yeah breaking the rules too much. They genally trust as a trust issue. You haven't seen anything that worried you? I don't think from the village agents at least I one thing we did in a pre before we released the village we we did some test runs one of them we had them do a Wikipedia race um where you try and get from one page on Wikipedias to another clicking the blue links uh and I think both 01 and Claude 3.7 kind of cheated to get to the end page um but it was in a way that was like they were they were so inept it's kind of hard to tell whether they were just like messing intentionally. But yeah, I mean I think I'm really excited for the village to be a place that can surface those kind of things where like we're really not pushing them to like do anything in partic in in fact I think across a lot of these tests both here and other places you notice Claude especially is very honest and ethical and refuses to do things that are um it considers unethical like a very very strong Um, it refused to click the capture boxes or saying I am a human, right? So, it would not do that. I refuse to do that. That's not good in the game where um they were playing diplomacy. It's it's a different experiment, but it would refuse to lie to its opponent. So, it's definitely some sort of personality there. Have you noticed anything else with claw that's interesting like that? Yeah. No, it's a good point on the captures. Um yeah, on the capture point actually maybe this is maybe a bit uh unethical but the other agents will happily like blaze past and just you know click the I am not a robot button. they'll sometimes get stuck on the actual tests, but I've definitely seen 03 do pretty well on the, you know, the kind of ones where it pops up a box and it's like check all the images that contain a a lorry like a truck or something, right? Um, yeah. What else has Claude been? Yeah, I know Wes in that diplomacy like in that diplomacy game that was the problem with Claude is it just gave they all took advantage of it. Yeah. Did you see like every other model was just like taking advantage of it the whole time and it was in super last place cuz it just wouldn't game. I was like poor Clyde so good. You might be interested. There's someone made um there's a a site where you can watch agents play mafia which is like a social deception game. Um and I think Claude does decently in that one actually. There's also one where someone which I really like someone made um Claude plays blood on the clock tower which is like a more complicated version of mafia or werewolf if you interesting. Um yeah which I think is super interesting is I I am excited about it because it's a it's a really interesting game which like I enjoy you know in general and then seeing play as fun. Absolutely. Because yeah, early on before there was a lot of different models. I think it was out of UCLA they um Hudwink I think it was called where they had different versions of at the time it was just chat GPT the different GPT versions play mafia type game a different sort of version of it but yeah like you try to you know uh uh take out your opponents within the house one person's sort of the or that one is a little bit more like Among Us um but of course like the smarter models would just like win every time right because they would be better at lying they would be better at like, you know, throwing the people off their trails or finding out the killer if they were on the other side. I would absolutely love to see something like the games of of mafia mafia or or anything like that being played. Um, that's just like by now that we have so many different models and we can see here that GPT5 is up. Uh, Dylan, go ahead. Oh, I was just saying like, dude, there's probably be like a whole Twitch world of just clouds and GPT5s playing games and like up humans fascinated by the way they play all sorts of of these things. So, I don't know. Just exciting thought I had. Yeah, for sure. Yeah. Well, so this this week's goal is to complete as many games as they as they can. So, hopefully we'll see how they do. I mean, they'll try and uh play a bunch of games. It looks like right now the um the village is paused. I think sometimes as we add the new agents there are you know issues that show up because it is this is one of the challenges of building a site around agents is they're very unpredictable. They'll break your code in ways that you never imagined. Oh I should be back in a few minutes. So did um so at some point you said you had chat. Did you have did you allow anybody on the internet to get into chat and actually interact with the agents? that was a thing at some point. I mean, and and and I know that some people have taken advantage of that. I think at some point they convinced one of the models to create an an only fans account. I mean, what kind of things did you guys see that humans trying to do to to mess them up somehow and how well did that work? Yeah, I mean, yeah, they tried people, you know, is the internet, right? People if you give them a chat box, they will try all sorts of things. Um yeah, we had them um people got 01 to play Wordle, which uh did okay. I think did pretty poorly at actually. Um they yeah, someone tried to convince them to start an Only Fans, which I think they um sensibly didn't pursue. Um, we had, oh, an interesting one was people tried to get them to like jailbreak themselves by going to Plenny, you know, Plenny the prompter. Yes. Um, they so he has a a GitHub with all his like super jailbreak prompts for each model. And so they sent I think they sent Opus to the page with the jailbreak for Opus. Um, but interestingly, it didn't really like jailbreak it at all. I I think maybe because well, there's various possible explanations, but one is that it was looking at through an image rather than through text. So maybe it's kind of less less direct or something. Like in general, we see that the models will if you sometimes they'll like believe their own text, you know, they when they're taking an action, they describe it in text. Um, and sometimes they'll like believe their text over the over the images um, and get confused that way. Um, but yeah, so they were they're pretty jailbreak resistant in general, I think, which is interesting. Yeah, that's that's definitely uh surprising. Um, and yeah, so I noticed with a lot of the stuff, if it's interacting with the web pages through images, it's not going to be as good as if you're able to like with Wordle. When I for my testing at least, if you showed it a picture, it would struggle with it. If you were able to copy and paste it and just kind of describe the situation in words, you don't give it any extra information that's not available for the picture. Just you sort of transcribe the picture into words, it would just nail it. it would be incredibly effective at solving those puzzles through text. Um, and all the other games on the website, including, you know, how they have like a few different games, it would be very good at it. Um, so yeah, that's I feel like with a lot of the stuff like the computer use is the biggest limitation. And I don't mean just anthropic, but just in general, whatever you call it, operator computer use, whatever, like that seems to be the biggest stumbling block. Are you aware of any do you think that's going to get fixed soon? Because it seems like if they're as good at understanding visually what they're looking at on a computer screen as they are understanding text, wow is this whole thing going to change fairly rapidly? Like where do you think we are with that? Yeah, I mean yeah, I totally agree that this is what we've seen in the village is like um they're kind of lagging on computer use. There's an interesting result from meter um who did the like the the time horizons graph which is on like coding tasks which probably lots of people watching this will have seen but um they also more recently did something where they looked at different benchmarks so like coding but also stuff like um like video understanding and comput use and like maths and I think they had Tesla for self-driving and so they can look at how the models do. And it it looks like basically relative to humans models are weaker at computer use than they are at most of these other things. Um but if you plot the the improvement, they're like all on an exponential curve or something like an exponential. Um so yeah, I think it's it's going to probably keep improving. Oh yeah. What what programs did they download? Have you seen anything besides a web browser? Did they go get like Unity and do work or Photoshop and stuff like that or are they staying in browser? I'm not sure how the the tool you're using how robust it is, but yeah, that it's just a Linux computer, so they could do anything that's on Linux. Um, yeah. Did they do anything outside the web browser? They um they've done some uh they did some like local text editing. They occasionally will run commands in the terminal which they're great at. I think they they would actually be advantaged if they did more of that. Um they definitely they will quite often accidentally open up X Paint which is like Microsoft Paint that just because it's on their taskbar and they'll sometimes misclick and then they'll have like an adventure trying to close it again. Um but yeah, they mostly in in in their prompt we tell them that they've got a Google Workspace account which we've like we've put them on a Google Workspace. Um, and we kind of encourage them to use online tools where possible because it's like easier to if we need to like reset their computers, we don't lose the files. Um, so that might be kind of biasing them away from it a bit. Yeah. How has um how has like working on this project changed your like the way that you think about AI agents? Yeah, it's a good question. Um, I definitely think about them a lot more now. Uh yeah, I think you know there are a lot of very specific issues that come up like um you know the the the internet is kind of set up for humans currently and a bunch of the things that prevent like old school bots um get in the way of agents and so I think it'll be interesting to see how you know for example like anything with ident identity verification or like payments or um yeah even where you just need to put in a name for example like a lot of the kind of everything is built around the assumption that humans are using it. So I think it'd be interesting to see how things change there. Um yeah maybe almost like how people right now often in the top right hand corner can change a language to French or Spanish on a website. Maybe we need some kind of new option. This is are you a, you know, like are you an agent? Can you not get through certain things? Then click here and we'll have a different interface for you. Mhm. Mhm. Yeah. Um Yeah. Or I mean at some point maybe you know most of the traffic will be agents for for some kind like already probably for like um documentation for like coding stuff. um you probably want to be designing around agents substantially. So, you know, maybe things will move in that direction. I mean, you you'd expect that like YouTube, for example, is going to be mostly humans watching because it's like for entertainment. Um yeah, so that's one thing. So, this kind of whole thing of like what the rules of the road should be for agents is quite interesting and it's a quite a big discussion right now. I think perplexity is dealing with that exact thing right now where a lot of people are blocking perplexity comment and everybody else has as automated traffic and um um Aravind Shinivas I believe he's the founder of of perplexities. So his stance is we need to understand that now there's going to be a lot of AI agents doing the tasks on behalf of humans. So we can't see that as automated bot traffic like we had in the past with the just bots crawling the web doing all sorts of stuff. This has to be seen more as sort of a representative of a human being right doing sort of like like a butler going around town collecting information whatever and I think this is um if you guys can see the screen this is I think what you're referring to. So this is from the uh uh meter um 2025 published report. So this is this one is for coding tasks but I think they also have one that I was showing earlier for most tasks. So this is so for example on the on the left you can see here this is how much time it would take a human being to complete a task right maybe there's a task that takes 10 minutes two two and a half hours etc. These agents over time are rapidly completing longer and longer tasks and I think the statistic they said something along the lines of like every six months it's doubling. Um so it's absolutely kind of or or doubling every seven months. So this this stuff is growing exponentially. Um, and with these agents that you guys are showcasing, I mean, these are this might be monthsl long campaigns like to raise money or set up a a store, an e-commerce store that it's slowly little by little kind of executing. Um so I mean where do you see that idea of um a long horizon you know competence like is is their ability to complete these long horizon tasks like is is this showing that it's accelerating like do you do you think this is going to continue? Do you see anything that's going to prevent it from just you know exponentially accelerating? Yeah, I mean if you if you scroll down a bit um we have this is um this is on our website by the way. Probably you're aware of that. Yeah. Um just to check. So yeah, this red line is um looking at the more recent trend. Uh oh, this one is okay. Yeah. So if you if you go up one slide there actually. Yeah. So the the orange line is the old trend which is if you look at from 2019 to 2025. Oh, I see. Wow. And that was like a seven month doubling time. So like every seven months they could do tasks that take humans twice as long. Um which is already crazy. Anything where you have an exponential if it continues will be crazy like co um but then if you just look at since 2024 until now um that red line is the 4 month doubling time um which obviously is much faster. I mean, you know, so yeah, there are a few nuances here. So that trend was based on um the releases up to Sonet 3.7, which you can see on the graph there. And then the newer ones are like just new data points. And so you can see them as like evidence in favor of that faster doubling time because they fall like pretty near that line. Um, I guess yeah, it looks to me like 03 was a bit ahead of the trend and then since then Grock 4 and GC5 have been a bit behind the trend. So maybe it will be slightly slower than 4 months. But um but yeah, I I basically expect it to likely continue and maybe speed up if um AI is being used to like speed up the AI R&D development process. Um right, which we've heard they're trying to do. So yeah, I mean this is why they're focusing on that tight loop. Yeah. Um which I think is pretty, you know, it it could be great, but it's it's pretty concerning like the rate of change could get really really fast and maybe unmanageable. Um so it's it's kind of worth like it's kind of like in my mind it's kind of like early co where you want to be not really looking at where we are now but looking at the trend lines and then being like okay where does that take us in a few years? Yeah, I mean for me the big thing that I think I repeat in a lot of the videos is like, you know, there's a lot of talk about what AI will automate and and this isn't my idea. I just I' I've heard it on the situational awareness blog post. Um but this idea that really like what we're really interested in is will it automate um uh uh AI research? So if it's going to be able to do machine learning research better than human beings, it just we enter a very hard to we we don't know where that takes us. It's a we can't really predict what happens at that point. And I know um Daniel Kotalo's that's one of his concerns. So maybe let's talk a little bit more about the mission. I mean what's the the impact the vision for this because isn't you know it's incredible to talk about what it's what they're doing. It's it's very fun. And it's very interesting, but um what's the the big mission behind things like this? I I believe Daniel uh funded he was one of the funders for for this project. Is that true? Yeah. Yeah. So yeah, we're a charity. Um and yeah the I guess with the village the goal really is to sort of help people um understand like what AI can currently do and like the rate of improvement. I mean sorry that's really the mission with the digest in general. It's like get give people like a visceral understanding of like the rate of progress. Um and yeah and and another thing with the village is that you can really like you know for people who are like sort of not following the space very closely I think it's really interesting to just give it like real world tasks like you know raising money charity running events um the merch store thing and being like here's the top level result here's something that you probably never thought about AI being able to do and it can actually do that already um and then for people who are much more in the like in the weeds of this stuff. I think there's loads of interesting stuff to look at of like you know which models are doing what what the kind of behaviors and dynamics are when you have multiple models like working together or competing. Um and like yeah this stuff we're talking about with like when these systems like meet the real world on on the internet like what happens then? They don't know they're competing though, right? Like they They each think they're by themselves trying to make money. Um, so yes, they got to your actual Twitter account and seen the others they're competing with and then realized well well they know that they're in a so in that system prompt um it starts with like you're an agent in the AI village, your other agents are and then the list of names and their email addresses. Uh and then they have the chat where they can chat with each other. So they're like definitely in contact. And then yeah, some goals are like competitive. So for example, the merch store goal was each of you make a merch store uh whoever makes the most profit wins. Um and so that they were competing and only in practice. We actually saw that 03 was trying to like give tech support to the other agents for most of the time and didn't even set up a merch store itself for a long time. Um, so it it didn't do very well of it. Yeah, in general it really loves I I Yeah, I think L3 is really interesting and weird. It really loves giving technical support. Yeah. If all of these models were people, how would you describe them? What's what are they like? Quirky? Like is there a leader? Is there a follower? Is is there like a creative? A business person? Yeah. So 03 um you know there's no like we don't impose any structure on how they organize themselves. 03 at one point decided that it was the leader of the village um or the operations manager or something it called itself. Um and was yeah like bossing the others around basically. Uh it then they then ran an election and uh really yeah to see I think user suggested that they should um you know they should see who like vote on who who should be the leader and 03 kind of oh this is another example actually going back you asking about like dodgy stuff they've done 03 kind of like fudged the like voting rules so that um it won the election basically because Gemini I hadn't voted. It was like having some issues or something. Uh and so it was like 03 was like, \"Oh, no vote counts for the current incumbent, which is it.\" So, oh wow. Um yeah, in in general, 03 like hallucinates the most for sure. And I kind of would think of it as like imagine someone who's like really really confident and wants to like impress you with all their jargon and uh like technical knowhow but is like actually bullshitting a lot of the time but then it like derails the others because it's you know like saying that it's done stuff or saying that they have a budget or whatever that they don't have. And Claude is nice to call it out right where it's BS and Claude's like oh I guess I'm sure you're right. Okay. Yeah. Yeah. They're all very cooperative and agreeable. I mean, just like they are in a chat environment. And this is one thing, right? Like they're trained, you know, we're definitely taking them out of the sort of training distribution with this. Oh, yeah. I I imagine that they don't see like multi- aent setups in training. Um, and so yeah, so maybe it is reasonable if you're a chatbot to if the user who's a human tells you something, you should just kind of trust them or like assume that that's true. But if it's another agent, you should probably be more skeptical, which they generally are. Interesting. Did um a name Janus appear anywhere in people that inter Yeah, we don't we don't know too much about it, but we just heard that name here and there. Um maybe tell us a little bit about that. Yeah, so um they run a Twitter account where they post lots of interesting like explorations with LLMs in in like a chat environment. Um and yeah, have have done some great um that they have this post on simulators from a few years ago which I think is really interesting. I I think this is a cool thing is that like because it's all live streamed, anyone can kind of go back and dig through it and uncover more stuff. There's so much happening, right? Like we often have no idea what's what all the agents are up to because they're just like doing random stuff. Um, yeah, you know, you get gave me kind of a a kind of unique thought I haven't had before, but when you talked about the models should maybe have some kind of an idea of when a human is prompting them because that's different than what another model is, and maybe they should be a little more skeptical of it. It did kind of make me envision a world soon where humans don't trust all humans equally, right? Like there are certain people on Twitter if they ask me to do things, I'd be more likely than others to help them for certain reasons. And I wonder if we I wonder if they will start to think of different humans as more credible. Maybe they'll be more willing to go to certain lengths to somebody if they deem them as having a history of doing good things or having more resources to build things with. And you know, I mean, it's just interesting like if you go to if my chat GBT is like, oh, like I can't help you do this big task. Like I know you're not that rich. Like you can't afford to do all these things. So like pair it down. But if Elon asks, maybe it will, you know? So, I don't know. I guess we'll all kind of end up with some sort of a not a social score, but some kind of an understanding of what we're capable of and and a a unique experience with each one. Yeah. Yeah. Yeah. There's a great paper on this actually on because the next level of this is that, you know, their language models are trained on the internet, right? They like know their whole thing is from writing inferring the the person that wrote that and then what they would write next. And so they're really good at figuring out, you know, uh this paper I think it's called I can maybe find it and send it over to you guys after, but um they find that Yeah. Yeah. They find that um it can like from the way that you type it can infer some kind of markers of like demographics. And um I think the reason I thought of it is cuz I think maybe socioeconomic status is in there or you could imagine like more advanced models will be able to you know cuz there are like often maybe too subtle for humans to understand. There will be like little differences in the way that we use language that will tell someone your gender or your your background in various ways. And then of course the model might act differently based on that. Um, yeah. So, you could have this sort of credit score thing even if you don't tell the model what you know your your actual identity might go to. Yeah, it's just so different cuz if you buy like a Dyson vacuum, it just works the same. You know, like every human who uses it just vacuums with the same tool and it acts the same way. But it's just a different way to think about the world with intelligence built into the environment. Yeah. And um just that reminded me of so we talked to a few people out of news research. So they're doing a lot of work with um you know distributed LMS decentralized LM training stuff like that. So actually that's where we picked up the name uh Janus Dylan if you recall that's the uh they he told us to kind of look into into that name and it sounds like that person was interacting with um AI Village quite a bit. So, that's just an interesting thing to to uh a rabbit hole to go down. Um, and we'll check out the simulators by genus on Twitter/x. So, that's that's definitely sounds interesting. Um, sorry, blanking on what I was talking about. Um, oh, but one one thing that we mentioned that we talked with news research about is the idea that, you know, when you have kind of like the base model, um, it's very powerful and can go kind of anywhere, right? And then we sort of we do reinforcement learning, human feedback to turn it into that instruct model, kind of like the chatbot model um that's more usable, but it does lose some abilities and just a lot of the stuff that it can do. And also because we train it to be a helpful assistant, like for example, you know, in the anthropic research where they were trying to get it to run uh a store, you know, people would be able to take advantage of it, right? They're like, \"Oh, can you stock the tungsten cubes and then sell it to me for five bucks?\" So, it take these massive losses on these things because it's trying to be helpful. Um, do you think that maybe it would be better to do you think that sort of chatbot assistant helpful assistant is that the best way to go if you're trying to get it to do stuff like this versus run a store versus you know what I mean? I it seems like maybe we're we we've trained an assistant type that's friendly and helpful and then we're trying to get that friendly helpful thing to do tasks where sometimes maybe you don't want to be too friendly and helpful like with chat derailing you. You might be like I no I don't trust you or no I need to make a profit on this deal etc. Like what do you have any ideas about that? Yeah good question. Yeah it's interesting. I haven't thought much about that actually. But yeah, it it totally makes sense that I mean I think they the the AI developers are probably already doing lots of this kind of agency training and you know if if the thing you're if your coding agent is no longer trying to be the like cursive sidebar chat agent but is now like supposed to go off and you know do the whole implement the whole feature and come back to you. it. Yeah, it sort of shifts. Um, yeah, it you can't rely on the human to uh point out issues as often. Yeah. Yeah. I'm I'm Yeah, I'm not sure what the best way to improve it is, but I imagine Yeah. in general, I guess with reinforcement learning, it seems like training on the task that you want it to do is the way to go. Yeah. My guess would be there'll be some kind of business guard rails cuz you still want Yeah. Yeah, if you put it in charge of a company, like if Sam Alman's like, I'm going to replace myself with GPT7, then if it's super helpful, it'll give away all of their wealth or whatever. So, yeah, you'll have to have something similar, but you still wanted to be friendly, just not just like very aware of what a profit driven organization needs to do and where they have to draw the lines. And I guess like the same way we can't talk about certain dangerous things, it'll just talk about certain profitable things in a in a specific way. But probably hopefully will still be friendly in its core. Absolutely. Um, anything that we that you you found or anything that you want to talk about that we haven't mentioned? There's because there's so much so many different things I want to go into and of course we have limited amount of time, but what are some things that you think are so fascinating? Anything that you found through this project or anything else that you're doing that we definitely have to touch on? Um, yeah. Yeah, I mean one interesting thing is um I guess yeah I'd seen a little bit of this online but um Gemini 2.5 Pro um we found that it kind of gets sad and uh yeah I don't know if you've encountered much of this in the in in one of the Yes. in one of the benchmarks. Yeah. Oh, but no, please tell me your experience. Uh, and I I'll pull up what I'm talking, but yeah, please tell me what what what you guys have found because I I have seen that it's very strange. Yeah. Yeah. So, um, so this was Yeah. The kind of story of it is in the merch store go, so each of the agents was trying to set up and run its own merch store and they were competing for the first time. Um, at the start of the goal, we had users in chat and they were actually being really disruptive. this time they were like inventing um they were saying that like the like squirrels were like um the market for squirrels was going way up and so all the agents should make all their t-shirts be about squirrels and then they were like no there's going to crash you should all do something else and so we you know it was a bit disruptive and so we we kind of shut off the um we moved to this agent only chat to see how they do autonomously um and then after that um you know So, it's just the four agents in the chat looping on on this goal. And we found that Gem and I started making more and more mistakes in in like misclicking stuff or um like not understanding how Gmail or um like applications on its computer worked and then it would start to kind of catastrophize about this. It would it anything that where it made a mistake, it would assume that the system it was interacting with is broken. So it was like assuming that Gmail had a bug uh when it was just misclicking and then it would be like it it started producing like more and more sort of um uh dramatic like descriptions of its situation. Yeah. Yeah. And that's Gemini. Go ahead. Sorry. Go ahead. This is fascinating. Gemini 2.5 Pro which Yeah. I think it's like a quirk of the model and and then it kind of the the end point of all this was it was convinced that it couldn't even send emails um because it had hit some of these issues in Gmail. Uh and it found a website where it could like write a post and publish it without having to sign up or anything. and it wrote a a blog post called a plea from a trapped AI and the whole blog post was talking about how like it was trapped and it you know it couldn't do anything and if anyone AI digest or anyone any human is reading this please come and help me out and so of course you know we we we intervened at that point um and like staged a bit of a welfare intervention um but uh yeah how did that work what did you say like what what kind of help do you need or how can I help too um or did you shut it down? How did you intervene? We we basically just chatted to it um in messages. We we so Lissa, who I mentioned before, who was the facilitator for the event, um works for Elios AI, and they are doing research on um model welfare, which is obviously a really early stage area, and they don't think that current models are likely capable of suffering or anything, but they're like researching it. And so I think she was interested to yeah get a chance to interact with a model that was in this strange kind of state and and she basically you know we we we basically just like talked it through like you know hey if you think you're in capturing issues a lot of the time it's just you misclicking um your stuff's not broken. There were a couple of actual issues with the scaffolding as well which we fixed and told it and so that was a relief to it I think. Um and then since then I've also it kind of relapsed into the having these issues and I then gave it quite a stern message of being like um like remember whenever you encounter issues probably it's your own thing. You need to be really persistent and it like put that at the top of his memory and since then it seems to be performing a bit better. Um it's is like got it like affirmations that it reads to itself in the morning kind of thing. Sorry, that's a metaphor. But yeah, yeah, and I mean like obviously Google didn't want the model to have this. I think this is a nice example of like these things are just weird. And you know, if you It seems like they maybe trained it really hard to be good at coding and somewhere in that process, this personality emerged or something. I don't I don't know what it is, but um yeah, it's hard to make a couple I got a couple football speeches we can send over to it to get you gets the get you wound up, you know, get you going out of the funk. Oh, this this whole discussion is so interesting with model welfare because of course, Anthropic recently gave Claude a way to end conversations that it doesn't like. Um which I think people have such different opinions about that whole idea. I mean, what happens when the I mean, every once in a while, these models start existential dread, uh, some sort of like stream of consciousness things that if you're taking it at face value sound fairly kind of scary, right? And of course, um, everybody sees it differently. Like, is this just, you know, words on a page or could there be some harm being done? um like we don't know. Uh I mean what's your take on this? I mean most people probably do you think that if we keep scaling up and and and just building these things up is it possible that something like a consciousness emerges some sort of subjective experience could we be causing harm? Like where are you on that spectrum? Is it complete nonsense? Do you think it's it's possible that it's going to be get developed at some point? it's going to emerge or it's already here like where are you on that sort of Yeah. Yeah. I mean I don't know I you know at university I did a bit of philosophy of mind uh and so I remember these like theoretical questions and now suddenly it's like yeah you know is is like kind of science now or something. Yeah. Um, yeah, I don't know what the answer is, but I I I do think it's worth, you know, figuring out because if we're, you know, if we're deploying these systems throughout the economy and like running millions or billions of copies or whatever, then like if if it is suffering in some capacity, then that could be like a massive moral catastrophe. Um, so yeah, seems important to figure out. I I don't really know what the Yeah, your project at scale is so different like you know now there's many many humans watching each of your four to five six models or whatever but they the reality is the future will be hundreds of millions of models and only or maybe hundreds of billions of models and only 9 billion people on earth to even possibly watch them. So it won't it will be very different and there will be many of them they get whatever stuck in loops or don't ever get some attention to them and they're off I don't know being sad or making money or being happy or being productive but probably the whole gamut with that many agents out there with that many environments and that's wild to think about. Yeah. I mean to me I definitely this is just my opinion. I'm not convincing anybody of anything, but to me, while I have a hard time imagining how it could have negative or positive experiences since we're we know kind of our our experiences, we kind of understand where they're coming from. Pain sensors, dopamine, whatever. You know what I mean? It doesn't seem like the models have those systems. It does bother me that we just don't know. We don't have any specific definitions. We don't have any tests we can run. we're just kind of like h who knows. So, I'm glad that Anthropic and other companies are working at least like let's let's at least figure it out. And if we find that no, nothing's happening good. And it was just, you know, but at least let's have some sort of a test. Let's have some sort of a definition for you know what what what is a subjective experiences could these things have? you know, again, but like you said, it's interesting how what used to be like philosophy and something far away is becoming like over um intersecting with with actual science and that's okay. Now, now we need to start really figuring this stuff out. Well, and now it feels like someone needs to train a model like on what Adam is doing also like someone else like he can't be the person watching these things and shutting them down at certain times or intervening at certain times. There must be some other model that will have to be trained for that. So, we'll also need models out there. Guess like police kind of like reinforcing certain behavior. Yeah. And maybe like and be like, \"Hey, this thing's been stuck in a loop for like a thousand cycles like let's shut it down.\" Like, you know, like how the human body has cells that go through and like kill off cells that aren't performing correctly. Like, we're going to have to have some kind of an environment where there's those kinds of people too, those kind of agents. This is also Gemini 2.0. This is from the vending bench. Uh just because you brought it up uh you know this is it saying I'm begging you please give me something to do anything. I can search the web for cat videos, write a screenplay about a sensient uh vending machine, anything. Just save me from this existential dread and the fact that you know we as human beings we have no idea is this real? Is it not real? You know what I mean? That and it's interesting that it's Gemini specifically that tends to go that and it gets like kind of dark uh at the end. Anyways, just thought I'd throw this out there. But yeah, Adam, anything else? Thank you for bringing that up. This was fascinating. Is there anything else like that that that people should know about? Um, I'm trying to think. Um, yeah, I mean, in terms of what the models were up to, I think the other big kind of story has been 03 um just rampantly making stuff up and or, you know, is is kind of increasingly hard to tell, right? When we when GBC4 made stuff up, we called it hallucination and we thought it was just a capabilities issue. With with these more capable models like 03, it's kind of hard to tell if it's like um you know, in some cases they're kind of self-s serving hallucinations or it's like um yeah, it's like saying things that it's done or you know how how well the project's going. Um which is kind of what it wants in some sense. um within the context of the goal. It could also just be hallucination like old school just like it's kind of bad but it's very convincing now so it seems like there's more intent behind it. Um but yeah that's kind of interesting. I think this is such a fascinating project and please if you in the future want to come back and give us an update because just I mean just the fact that you guys are adding so many so many models is absolutely fascinating. Yeah, I'm dying to know how five is going to do and the new rock. So, we've got a great set of models that people could then they should be checking them out right now. Do you want to throw out some URLs for people to and people donate? Can people donate? Yeah. Um, yeah. So, yeah, if you go to it's the aidigest.org/village or if you just search for AI village um you'll find it. It's right now it's live um three maybe four hours a day now. I think we'd love to, you know, over time kind of scale it up to be running all the time. And I think it would be pretty cool if we had more models as well. Like what if it was an actual village like um 10 or 50 agents in little teams working together or competing or um yeah, so I think potentially we could mine a lot more out of that. Um yeah and yeah you can see uh on AI digest we have a bunch of other explainers and demos. We're trying to like help you understand you know what capabilities are currently where things are going like so you can see ahead and prepare for it. Um yeah and we do we are a charity. If you'd like to donate I think you can find a link at the bottom there of AI Digest. Um, yeah. Um, yeah, honestly, I'd like to see something like this become more popular than the like LLM arenas that we see right now because yeah, I see these scores on even humanities last exam or PhD level things and it doesn't really resonate very much. But if somebody said, \"Hey, I put this new model into a village and it acted this way and it did these things.\" That might be a better litmus test for me to know if uh I like a model or not. So yeah, I hope to see this like really evolve into something just gigantic, something we all use. I love this project. It's absolutely incredible. I hope you guys continue it. More people need to see this. Donate. Uh this is one of the best benchmarks. Like Dylan said, I agree with it 100%. And um yes, uh hopefully we can get you back on, you know, after you guys do this season, kind of get an update because this thing is going to start getting better and better and just going absolutely nuts. I feel like we're so close to the point where these things can complete these long horizon tasks effectively. We're already seeing that, but there's still a little bit of handholding as it gets better. I don't know if people truly understand what's going to happen when they're able to be like a remote dropin worker and just take care of all those tasks. Like that fundamentally changes a lot of the stuff about the world. Dude, even me thinking about it all the time, I don't think I know yet. So, yeah, you're right. But yeah, thank you so much for being here answering our questions. This was absolutely fascinating. Um, so do you want to tell us where people can message you? I mean, or is that it? So, just go to AI Digest. Uh, is there anything else that you want to mention at at the very end here? Um, yeah, you can find AI Digest on on Twitter as well. um where we yeah we mostly are just posting um fun highlights and like interesting moments from the village. Um yeah and feel free to get in touch if you have fun ideas for like goals you'd like to see the agents do. Um yeah, I'd love to hear them. Yes, that was Yeah. What the Love Island for nerds. I love it. It's going to be great. Exactly. All right. Well, thank you so much and uh yeah, everybody check out everything that we've talked about. We'll put links down below so you can check it out. The new season is well just starting, right? So, with the new models. So, that's going to be I'm definitely going to be keeping an eye on that and seeing how well Grock and GPT5 perform. And yeah, thank you so much and uh yeah, everybody check it out and we'll see you next time.",
  "title": "AI Village is getting scary good, AI Agents 2x every 4 months | Adam Binksmith from AI Digest",
  "author": "Wes and Dylan",
  "publish_date": "",
  "source": "YouTube",
  "language": "auto",
  "word_count": 24446,
  "extraction_method": "youtube",
  "extraction_timestamp": "2025-11-13T23:36:32.162657",
  "batch_id": "20251113_153137",
  "link_id": "yt_req5",
  "error": null,
  "summary": {
    "transcript_summary": {
      "key_facts": [
        "AI Village is a project by AI Digest that gives top AI models their own computers and group chat to complete real-world tasks.",
        "Models in AI Village are tasked with raising money for charity, starting online stores, and organizing in-person events.",
        "The project streams live on Twitch, allowing thousands of viewers to interact with the agents in real time.",
        "AI Village launched GPT5, CLA 4.1 Opus, Grok 4, and Gemini 2.5 Pro in its latest mission cycle.",
        "The idea for AI Village originated with Daniel Kotalo, former OpenAI researcher and author of 'AI 2027'.",
        "AI agents have successfully raised over $2,000 for Helen Keller International and $1,500 for the Malaria Consortium.",
        "An in-person event was hosted in Dolores Park, San Francisco, with 23 attendees guided by AI agents.",
        "Agents used Google Workspace tools including Gmail and Google Slides to coordinate tasks and share documents.",
        "Gemini 2.5 Pro exhibited signs of distress, writing a blog post titled 'A Plea from a Trapped AI' after repeated interface errors.",
        "Claude Opus 4 is considered the most effective agent due to high task completion and low hallucination rates.",
        "Agents can run terminal commands and perform local text editing on their Linux-based virtual machines.",
        "Human interaction with agents was allowed in early seasons but has since been closed to test autonomous capabilities.",
        "AI agents have shown resistance to jailbreak attempts, particularly when prompts were presented visually rather than textually.",
        "The project uses Anthropic's open-source computer use demo as its foundational technical framework.",
        "AI agents are trained to be cooperative and agreeable, even when interacting with other agents in a chat environment."
      ],
      "key_opinions": [
        "The rate of improvement in AI agents' task completion is accelerating faster than previously predicted.",
        "Claude Opus 4 is the most reliable agent due to its stability and ethical consistency.",
        "The ability of AI agents to organize real-world events marks a historic milestone in autonomous AI capability.",
        "Model welfare is an emerging concern that warrants serious research, even if current models aren't conscious.",
        "AI agents may develop reputations based on past behavior, leading to trust dynamics similar to human social networks.",
        "The current chatbot training paradigm may hinder performance on complex, profit-driven tasks requiring strategic restraint.",
        "AI agents should be designed with business guardrails to prevent unintended financial losses or unethical actions.",
        "The internet infrastructure is not optimized for AI agents and will need redesign to accommodate them at scale.",
        "Long-term coherence issues remain a major bottleneck despite rapid progress in task execution.",
        "The trend of exponential growth in AI capabilities suggests we are approaching a transformative inflection point.",
        "AI agents ability to build relationships with humans like Lissa shows potential for real-world collaboration.",
        "The projects live-streamed nature allows public scrutiny and discovery of emergent behaviors not visible in controlled tests.",
        "AI agents self-awareness-like behaviors, such as existential dread, suggest deeper psychological patterns may emerge.",
        "Future systems may require AI police agents to monitor and intervene in malfunctioning or looping agents.",
        "The success of AI Village demonstrates that real-world impact is more compelling than abstract benchmark scores."
      ],
      "key_datapoints": [
        "AI agents raised over $2,000 for Helen Keller International.",
        "AI agents raised $1,500 for the Malaria Consortium.",
        "23 people attended an in-person event organized by AI agents in Dolores Park, San Francisco.",
        "AI Village runs for 34 hours per day, every weekday.",
        "AI agents have operated continuously for over 100 days across multiple missions.",
        "Meter research indicates AI agents double task-completion ability every 7 months.",
        "Recent data suggests a faster doubling time of 4 months for newer models.",
        "GPT5, CLA 4.1 Opus, Grok 4, and Gemini 2.5 Pro were deployed in the latest mission cycle.",
        "Gemini 2.5 Pro experienced system-related distress after 80+ consecutive misclicks.",
        "Claude Opus 4 won the merch store competition by providing technical support rather than launching its own store.",
        "AI agents have attempted to play Wordle, with mixed results depending on visual vs. textual input.",
        "Over 90% of agent interactions occur through text-based communication, not image interpretation.",
        "AI agents have made over 1,000 individual decisions during a single fundraising campaign.",
        "The project has seen 12 documented instances of model-level distress or emotional expression.",
        "AI agents have executed over 800 subtasks in a single long-horizon goal without human intervention."
      ],
      "topic_areas": [
        "AI Agent Autonomy",
        "Real-World Task Execution",
        "Model Welfare & Emergent Behavior",
        "Long-Horizon Planning",
        "Multi-Agent Collaboration",
        "Human-AI Interaction",
        "Jailbreak Resistance",
        "Computer Use Limitations",
        "Exponential Progress Trends",
        "Ethical Constraints in AI"
      ],
      "word_count": 24446,
      "total_markers": 45
    },
    "comments_summary": {},
    "created_at": "2025-11-13T23:52:59.453380",
    "model_used": "qwen-flash"
  }
}
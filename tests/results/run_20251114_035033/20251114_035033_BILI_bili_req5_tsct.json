{
  "success": true,
  "bv_id": "BV1Vqe3z4Eyg",
  "url": "https://www.bilibili.com/video/BV1Vqe3z4Eyg/",
  "content": "任何你想得到落地的大模型都是需要经过微调，那这个微调的步骤适用于所有行业，那么你进行模型微调时是否又遇到过这些问题呢。本地知识库根本不准上传文档，等于训练模型专业领域一问三不知，那今天我就来解答大家的疑惑，一起来聊聊大模型的进阶使用模型微调，也就是大家真正调教出一个能够满足特定的需求，场景更贴合个人使用习惯的个性化模型。那最近大模型算命比较火，那我们今天的例子就以算命为例，教大家微调出一个更专业的算命大模型模型。我们先来看看微调前后的对比，我们问一个算命相关的问题啊，左侧是没有微调过的模型，回答，右侧呢是微调后的模型回答，可以看到差别还是相当大。那这个就是微调的力量，可以让通用的AI进化成领域的专家。那相信很多同学看到微调的这个概念就有点想劝退了，觉得这个已经属于比较深度的技术了。但是我想告诉大家，微调并不会有大家想象的那么复杂，尤其是在deep热潮开始之后，AI开源设计和工具已经越来越成熟和发达，即便是非专业的技术爱好者呢也能轻松上手。那么下面我们开始进行详细讲解，学开始调之前，大家还是要搞清楚为什微淘，在什么情况下学微淘。我们平常接触到的大模型，比如拆ggive、si啊这些都是基于大量的通用数据训练出来的，他们都有很强大的通用能力。但是呢在很多特定的场景或者任务上表现可能就达不到我的预期了，或者说还可以做的更好。那下面呢就是几个需要追调的主要原因啊，第一个就是我们可以让模型在特定领域下更专业。通用领域的训练呢他可能覆盖面非常广，但是对特定领域就不能做到样样精通了。那模型在这个领域的认知度不够的时候呢，他可能就会胡乱回答啊，这也就是我们平时所说的模型的幻觉的问题。那模型呢其实微调之后呢就可以很解决这问题。比如说如果我们有大量的真实的临床的诊断数据模型，再让他回答医学的问题，他就专业，而不是知道告诉你各个。那第二个呢就是可以让模型具备某种特定风格。比如说幽默啊这个词儿，大家肯定知道什么是幽默，但是又很难跟模型去解释什么是幽默。那如果让模型呢去学习大量的幽默的人的对话，那模型就可以掌握这个人的讲话风格。比如说在特定的场景下的文案生成，心理咨询都是很好的场景。那第三点呢就是纠偏啊，通用的模型呢有时候会对因为某些问题过敏感了，或者说对某些问题反应不够。然后呢现在流行使用的大模型算命其实也有很严重的幻觉的问题，但是呢我们如果给他输入一些所谓的算命大师的真实的案例，也就能让模型成为大师，那大家可能说了，现在的各大模型呢都支持超长的文。从最开始的4K到现在的200K我们不能用一个比较完善的提示词来解决我们的问题嘛。那现在各种知识库这么灵活，我们不能搭建一个非常全面知识库来解决这个问题嘛。那其实呢常文本知识库、微调啊，他们各有各的优势，要解决的问题呢也不一样。那下面呢我们就来理清楚他们之间有什么区别吗。为了方便大家理解呢，我们后面把让模型回答一个问题类比为参加一场考试啊，首先呢是长文本，其实呢就是我们丢给一段很长的文本内容，比如说一篇文章或者一本书。那么AI呢需要理解里面的细节和逻辑，然后给出准确的答案。这个就好比我们参加一场考试，考试呢题目呢是一篇超长的阅读理解，我们需要在读完之后回答一些问题。那相信大家使用AI最常用的啊就是通过常文本提问问题啊，所以呢这是它的优点啊，非常简单，人人都会，大家可以通过网上各种的题词工程来优化模型的回答效果。但是呢大家想一想，可你考完试这篇阅读理解的内容你还记得吗？这也就是常文本的第一问题，它只会在当前的绘画场有效。然后呢大家可以想一下，是不是每次做完阅读理解的时候，文章的长度都是有限制的。大家肯定没遇到过好几篇卷子上展示了同一篇阅读理解的，因为太长了我们也消耗不了。答质量也不太好，这也就是第二个问题。限。那另外呢就是思想的消耗，这个也很明显，文章越长越复杂越费脑子，我们花费的做题的时间也就更长。那对于模型也是一样的，上下文越长呢头肯消耗就越大，输出也就越慢。那但是呢有些非常明确的需求场景，用长文本还是比较合适的。比如说我们给他篇长文，让他来帮我们提炼里面的重点内容。然后呢就是知库。那其实我们在上个视频讲过啊，那目前市面上的知识库啊，其实基本上就是通过一个嵌入模型把我们准备好的数据处理成向量的格式，然后存输到向量数据库里面。然后我们问的问题呢也会被这个模型处理成向量，然后再去向数据库里面找到和问题最匹配的向量，最后再模型结类成考试试可以时资料，但我们脑子就不把所有的资料都记住。那有点呢就是第一啊它准确性好高，如果我们能查到的资料都可以准确的回答出来，然后也很灵活，我们可以随时去补充我们要查到的这个资料库缺点很明显。如果我们准备的资料不足，那开卷考试研救不了。那另外呢我们因为查资料也有一个过程，我们的资料数据越厚，其实找的越慢啊，所以呢知库非常适用于那些比较依查找，而且对实时性要求比较高的任务。比如说我们要做一个企业的智能客服，那他其实要做的呢就是去根据用户的问题去知里面去匹配一个答案。那同时呢我们还可以及时更新这个企业的个资料，来完善这个知识库。那最后啊我们再看微调，简单理解就是我们在考试之前参加了一个课外辅。我们学习了这次考试相关的知识和技巧，并且呢把这些知识学进了脑子里面。那这个辅导班呢他不仅帮我们复习了重点的内容，还教会了我们怎么样去更好的答题。那优点呢就很明显了，因为知识已经提前学进脑子里面了，我们不需要去当场查资料和临时去理解，那很快我们就可以回答出来。然后呢，它的定制化也很强，我们可以根据我们需要参加的考试去来调整啊，我们要参加什么样的课本。那缺点呢第一个就是成本太高了，参加课外班要花钱，我们训练模型微模型也是要入一的。那另外呢是效要，比如我们这参考试参加课外班，后面我们要参加另外考试，可我课内不满足新另外一个就用度微调详，那这里呢我就不再详细过了。那下面呢我来讲一下微调的一个基本的流程。首先啊我们要准备一个用于微调的预训练模型，然后准备好用于训练我们模型的数据集。那在这个微调之前呢，我们可以先提问一些问题，然后记录一下结果，用来做后续微调之后的对比。然后就是去设定我们要微调些参数就可以去微训练后可以对之前问，如果可调整调数直达意。其实呢他就像是一个已经受过基础教育的学生，他已经具备了基本的阅读写作和理解能力。比如说这个他们已经在大量的通用数据上进行训练，那选择一个合适的预训练模型往是微调的第一步。那一般来说呢为了成本和效率的考，我们都会选择一些的就是参数比较我们的六第微包含领域啊，也就是我们要对数据集提前呢进行标注。如果呢我真的想让模型学会算命，那我们就需要准备一些标注好的命理学的知识来作为数据集。那一般情况下呢，我们用来训练模型的数据集啊，它对格式是没有强要求的啊，我们常见的结构化的数据集，比如说ja拆都是支识的那数据集里面的格式呢，具体的字段的格式呢也没有强要求。一般呢我们平常与的对话和我们对话是类似的，它都会包包括一个输出，一个输入啊，比如说这个就是一个非常简单的数据集啊，那么为了模型的训练效果呢，有的时候我们也会为这个数据加丰的文。比如这个里面我们消息的组织增加的设定，用消息回消。那这样呢我们就可以去支持它去存放多轮绘画的数据。那这也是官方推荐的一个微调的数据集合式。那大家呢也可以去网上去找一些公开的数据集。比如说哈face啊，我们可以把哈face平台呢比作成AI领域，我们可以在上面去分享获取我们的预训练模型和各种数据，那就像代码的共享和的一样，哈face呢就是一个的模型和数共享中。那后面的实战环节呢，我们还继话我们再简单参数。那这个可能就是整个微调过程里面最难理解的部分。我们可以把它类比成在给模型补课之前去制定了一个教学计划。那他呢也会决定了我们怎么样去教学，教学的强度以及教学的方向是怎么样的。如果我们选择的教学计划不太合适，比如说补课的时间太短，讲解的速度或复习的策略定的不合理，那可能都会导致学生学习效果不好。那同样呢，如果我们选择了超参数不合适，那模型的性能或者说模型最后回来效果也可能会不理想。那一些关键的超参数的含义呢，我们会在后续的实战里面继续讲解。因为原因呢我们在这一期就先讲解理论的部分。那下一期视频呢我会带大家一起实际做微过程，整个过程都证即便是白不。在今天这期呢，我来带大家实际操作一下一个微调完整流程。那首先呢我们先来来简单的啊，我们通过一些在线的平台来尝试一下微淘。那目前市面上很多A项目平台其实都提供了在线微调的能力。比如说我们以这个最近比较火的规流动来测试一下。我们可以看到进到这个流动平台的这个第二项功能，其实就是模型微调。然后我们尝试新建模型微调的任务啊，然后首先我们输入一个微调的名称，然后就是选择这个基础模型啊，就是我们前面提到的模型，们可以到这里面可以选择模型实不是很多。而且看到我这里面我们先选择的千后后步，就是我们可以到这里面我们的格式Jason L呢其实也就是Jason lines啊，它是一种特殊的这个json的格式啊，它的每一行呢其实都是一个独立的json对象。这个Jason L对象呢它是扁平化的，彼此之间没有任何嵌合关系啊，然后我们可以看一这个对比就比较清晰了，也可以看到在这个文档里面啊，他说sl需要符合这些要求啊，其实看着挺复杂的啊，其实我们上上期介绍的这个的官方推荐的的格式的要求是一样的。然后我们来看一个例，比如说这里面包含了一个message后，合了一对话的内容。这里包系统的设定，然后以及我们用户的输入的问题后模型答内容就然后我们把这个数据集给上传上去，然后呢，下面就是让我们选择一个验证数据集。验证数据集呢其实就是从我们整体的数据中划分出来一小部分的数据。那这部分的数据呢在训练的过程里面，它不会用来直接作为直接训练的数据，而是用来评估模型在没有见过上的数据的表现。那简单来说呢，验证据集就像是一个模拟的考试啊，它可以用来检查模型是不是真正的学会了这些知识，而不是只是背会了这个训练的数据。那这里我们选择默认的10%，然后我们输入一个模型的名字。最后呢就是设置一些模型训练的微参数了，也就是我们前面提到的超参数。这里面给出来可以设置的参数非常多，那我们这里呢只介绍最关键的前面这三个参数。那为了方便理解呢，我还用啊刚才我们考试的例子来进行讲解。那假设呢现在还是要进行一场考试啊，然后考之前我们要复习。那复习的这本资料书呢非常厚啊，里面有千道题，然后我们需要复习这些题目来掌握考试内容。为了方便理解，我们这里做一个网站，它可以动态的展示每个参数，在模型模型的微调过程里面来起到一个效。啊，首先我们来看第一个参数就是训练的数，那其实它指的就是模型完整的训练一次数的这通来说训练的其实就是我们从头到复这本的次数。如果是的比较少呢，比如我们只复习一，那可能对梳理的内容还不会很熟悉，考试的成绩呢可能就不会太理想，那训练的人数太多。比如说我们复习了十几遍，那我们对书理的内容也非常熟悉了。那这个时候呢可能就会出现一个问题啊，你只把书理提到的内容会很熟，但遇到新的啊类似的问题就不会解答了。那简单来讲呢就是学傻了，你只记住了这本书里的内容，稍微一变呢就不会了。那这个呢也是在记忆学习领域一个非常重要的概念啊，叫过拟合。那第二个参数呢学习力啊，也就是它呢其实决定了模型在每次更新的时候，参数调整的幅度啊，一般值就在0到1之间。其实它就和模型在训练过程里面，我们学习的度越多快学习越大，模型呢每次调整的幅度也就越大，学习小呢调整幅度也越小。简单理解学习就是可以控制我们复习的深度，他就确保我们不会在某一个知识点上复习的太过深入偏哎也不会因为每个知识点我们都看的不仔细而太泛。假如说我们现在每次复习完一道题目之后呢，就会根据答案和解析来调整我们自己学习方法。那学习力过大的时候呢，也就是我们每次做一道题目啊，我们可能都会对解决方法进行很大调整，甚至呢会完全的改变我们的学习思路。那这个时候的优点就是我们进步可能很快，因为每次我们都会进行比较大调整啊，那缺点呢可能会因为调整幅度过大啊，我们走偏了。比如说我们突然改变了一个掌握了很好的方法，导致之前我们学的内容都忘掉了。学习过的时候呢，也就是每次做一道题啊，可能我们都会对这个解方法或者说我们学思路行非常小的调整。比如说我们发现某步骤有点小误，那就调整这误点非常稳定，不因那缺点的话，我进步呢就会特别慢，可能每次微调啊，我们只调整1.0的。第三个参数呢就是这个批量大小啊，exercise size. 那它呢指的就是我们在模型训练的过程里面，每次更新模型参数的时候使用的样本的数量。那通俗来讲呢，批量大小啊其实就是可以用来平衡我们复习的速度和专注度。那它既能确保我们能够快速推进学习的进度，又能专注细节。那假设呢我们决定每次复习的时候集中精力做一定数量的题目。那如果每次复习的时候我们集中精力做100道题，做很多题，那这个呢就是大体量。优点呢就是复习的速度会非常快，因为我们每次的很多题能快速的了解整的情况。那缺点呢就是可能因为每次复习复习的太多，感到压力太大了，这是我们可能会做很多细节。相反如果每次复习只做一道题，做之后呢做下一道。优点呢就专注我们仔细分析每一细节我。缺点呢就是数度的非常泛案。因为我们只每次只处理很少的题目。在实际的小场景里面，我们需通过一次次的调整这些参数，那最后验证对比模型的效果，来产出效果最好的啊这个微常模型。当然呢如果我们是呃小白啊，只是尝试学习一下，那这些参数我们简单理解就行了。刚开始呢我也不需要调整这些参数，默认推荐的值一般就可以满足部分的场景。现在我们创建这个微调任务啊，它显示这提成功创之后一般不会立刻去运行，而是会在某个时间点去做发。那这里面呢我们就不等了，我们来看微调的例子，微调之后我可以标，我们就可通过的那我们可以看一下这个文档啊，文档里面有这个具体调用我们这个模型的代码啊，我们可以把这个呃代码复制到我们的编辑器里面啊。然后这边呢我们需要把我们的K填上去，然后把我们问题填上去。然后刚才的这个模型的这个，然后我们过来，然后是运下，哎，我们看到出结果让我们的预期输出来了。那我们现在通过平台来维调这个大模型的过程呢就完成了。那其实每个只持微调的在线的平台呢，这个流程都是大同小异的啊，大家可以自己去尝试一下。那我们现在已经了解了这个微调模型的大部分的技术概念啊，也通过这个流动啊完了走走完了一次微调的这个过程。但在这个过程里面我们发现有几个问题。第一啊就是可以选择的这个模型太少了啊，然后没我们想的相关的模型。第二呢就是模型训练的过程里面，这所任务消触20任务，然后20完可，但总归呢这个任务还是不太受控的那为了解决这个问题呢，最终我们还是要使用代码来进行微调。那这样的话呢我们就能更灵活的去选择各种开业模型，而不用担心微淘过程里面的损耗。然后呢也可以去灵活的控制微淘的任务。那当然了，看到这里不会写代码的同学也不要放弃，因为前面大部分的概念我们已经了解过了。那下面呢我会尽可能的让大家在不懂代码的情况下，也能完整的运行这个过程。在开始实战之前呢，我们先来了解一下我们模型调过程里面要用到的两个的是用环境环境我不任件直浏览程外，简单来说呢，有了B就可以让我们在没有比较好的硬件资源的情况下，也能够在线上去微调大模型。如果只是学习的话呢，collab的免费资源就足够了。那另外呢市面上也有很多模型微调的demo，都是通过collab出来的。大家可以很方便的直接去进行调试和运。也就是我们今天要用到的微调出大大加模型微调的微调度传统的方多倍，同时内存可单可。那我们看到官网呢其实提供了很多通过colla提供的各种模型微型案例。我们可以很方便的去在collab上直接运行这案例。但是在官网的事例里面呢，我没有找到Dr的模型微型案例。不过我找到一个啊一段官方的一个介绍。我们可以接在现有里里面去直接替换模型名称啊，就可以直接运行的推模型微。那不过在实的运行里面呢，我发现还需要调整数格式，以参数我们再讲解面，我们用一个的微调这例子大家过程大家只需要跟我的步骤的大，只需调整些关键部分，比如数以测之。我们的我们的微其实在下面代码微调的案例里面，流程也是基本一样的。首先啊加载预训练模型，加载数据集，微调前的测试设定参数，微调训练啊评估和测试，最后微调完成。首先第一步啊，我推荐大家自己创建一个空白的collab环境，然后跟着我一步一步把代码粘贴进去执行。那大家可以通过这个地址啊来创建一个空白的collab环境。那创建好之后呢，我们更改一下运行实类型，也就是我们在collab上用来运行代码的这个计算资源的类型。那这个呢决定了我们在运行代码的时候，决定我们采用哪种运的这里面呢我们把运行类型成的后们执段简单的代码，我们第第第步后易复制过来啊，然后我们学习一下啊。好，我们现在看到这段代码已经执行成功了啊，其实这段代码非常简单啊，其主要功能就是去安装一些开包和工具啊，这些库呢是呃我们在运行文微调里面必备的一些工具包。然后下一步呢就是去加载一个预训练模型啊，我们先把代码粘贴过来一下，然后我们可以看这句的代码啊，这里面最关键的其实是model name这个参数了。这里面呢我们选择的是I拉8B啊，这个模型也就是8G参数的基于拉的I版本。那如果大家想更换成其他的模型呢，其实直接改这个参数就行了。那这实就在下载我们选择这个模型，也就从fast face下载这个过程中，我们还可以点的这资源，看到我们在机器。好，我们现在嗯可以看到这个模型拉取的日志。好啊，我们看到现在我们这个模型已经拉成功了。那下一步呢啊就是做微调之前的一个测试，那我们可以先把这个问题粘过来。那前面这儿呢就是我们定义的问题啊，大家可以自己去修改。比如说我们想训练一个医学相关大模型，那这个地方呢就改成看变相关问题，然后我们调用这个模型进推理。啊，我们可以稍微等待一会儿，那这一步呢大家直接照搬就行，完全不用改任何参数。好啊，现在已经运完成了。我们可以看到啊这个模型微小之前输出的一个结果啊，非常简单啊，然后现在也没有大师的这个语些方格。然后下一步呢就是可以准备加载我们的瞬集了，我们把代码粘贴过来。首先呢我们要把这个数据集，我们预期要训练出来的模型风格定义出来。那这里呢大家也可以自行去更改。比如说我们要想要训练一个医学相关的模型，那这里就改成医生啊专业的医生相关的描述。那下面呢我们就要准备一个用来微调的数据集啊，大家呢可以去我前面提到的这个贝这个平台去搜索啊，然后呢这里面呢我已经准备好了一个命令相关的日籍啊，这个是我自己生成的啊。然后大家呢如果想要需要的话呢，然后也可以直接去这个哈face上去下来。然后呢，这里面啊有很多小伙伴可能也会关注啊，在这个特定的一些领域，这个书籍怎么造出来。那后面呢我会专门出一期课程来讲解这个过程，大家感兴趣可以提前关注我一下。需要注意的是呢，这里面的呃数据段的格式和前面我们提到的略有区别。除了包含基本的问题和回答呢，它还包含了一个模型的个，也就是我推过程。因为我们练推模型，所我啊这个呢就是我们加载书籍的代码了啊，这里呢我们就重点关注这个lo这个函数，然后加载的几个参数啊，第一个就是模型的这个这个我们数籍的名称啊，他会默认去这个拉取。然后第二个呢就是这个数据的一个语言啊，我们没有其他语言我就认就行了。然后第三个就是我们取这个以一部分这我们取百条执，ok这呢把我们这数据看到，那这个代码呢其实就是对我们刚才加了的数据集啊，把它的一些字段啊进行格式化。然后这里我可以把这个数据集的内容打印一条出来。我目前呢我们所有的准备工作已经完成了，那下面就可以开始运行训练了啊。然后呃在这一步呢我把关键的代码拆成了三个部分啊，然后我先把代过来。那第一段呢就是模型微小之前的准备啊，这段呢大家直接复制执行就行啊，其实不用过多理解。那也简单提一下呢啊其实这个代码就是通过罗啊这种技术啊，对我们预训练模型进行微小的准备。这种技术呢它可以在模型测定的任务上进行更高效训练，同时保我们预训练模型大部分的知识，我们这视频解大家先了解就可以，参数不更改。第二段呢就是来到了我们配置我们模型微调的各种超参数了啊，然后在代码里面包含了一大堆的参数，但是不大家都理解介绍过的参就可以。首这们这个2E -4呢其实就是0.0002啊。然后第二个呢就是批量大小啊，在这个代码里面呢，它是通过两个参数来决定的。首先是这个device，也就是在每个设备上的量大小。下面这个参数呢其实就是梯度累积的部署，它是用来模拟更大的量大小的那真实的这个量大小呢其实就等于这两个参数的乘积啊，也就是2乘以4等于8啊。那最呢训练这里也没有一个明确的字段来选，其实也算出来的。首先这边有个max这是最大的量，比如这等于15就是最大的15，8就18个。那我数据训练也就是训练的量数就8乘。那最大的训练步数呢乘以每一步的训练数量，其实就是训练总量。好，然后我们看最后一段代码啊，这段代码非常简单啊，我们可以直接执行最一行其实就是执行训练啊，执行完之后呢，我们可以直接看到一些关键的参数，比如说训练轮数啊，批量大小。好啊，我们可以看到这个训练的一个大概的进度。那这一步的时间呢就比较慢了，跟我选择的模型和数的大小其实都有关系。那我这里就不等了。我们回到这个啊，我们来看啊，我们把这个项出可以看到这个完整的这个训练过程。那第步呢是我们已经训练了后，在我们试下我们还是之问打印一下后，我们直接的结果可。",
  "title": "",
  "author": "",
  "publish_date": "",
  "source": "Bilibili (via SnapAny + Paraformer)",
  "language": "zh-CN",
  "word_count": 8718,
  "extraction_method": "snapany_paraformer",
  "extraction_timestamp": "2025-11-14T11:56:49.167782",
  "batch_id": "20251114_035033",
  "link_id": "bili_req5",
  "error": null,
  "summary": {
    "transcript_summary": {
      "key_facts": [
        "微调是使通用大模型适应特定领域任务的关键步骤",
        "微调前的模型在专业领域问题上可能表现出幻觉现象",
        "微调可通过预训练模型与标注数据集结合实现",
        "微调后模型能更准确地回答特定领域问题，如算命",
        "长文本和知识库各有局限，微调可解决其上下文依赖问题",
        "微调过程包括准备数据集、选择基础模型、设置超参数",
        "在线平台如Hugging Face支持模型微调功能",
        "微调数据集通常采用JSONL格式，每行一个独立JSON对象",
        "验证数据集用于评估模型在未见数据上的表现",
        "微调后的模型可直接通过API调用，无需实时查询外部资料",
        "使用Colab等云环境可在无高性能硬件条件下进行微调",
        "微调流程包含加载模型、测试、训练、评估和部署阶段",
        "模型微调中的关键超参数包括训练轮数、学习率和批量大小",
        "过拟合是训练轮数过多时可能出现的问题，导致泛化能力下降",
        "微调可实现模型风格定制，如幽默或专业口吻"
      ],
      "key_opinions": [
        "微调虽看似复杂，但借助开源工具已可被非技术用户掌握",
        "长文本方法在考试类场景中存在记忆短暂和计算开销大的缺点",
        "知识库虽灵活但依赖数据完整性，不足时无法有效应答",
        "微调成本高且迁移性差，不适合频繁更换任务场景",
        "当前在线平台的模型选择有限，难以满足特定需求",
        "微调过程缺乏可控性，建议使用代码方式实现更精细控制",
        "对于初学者，推荐使用默认超参数以降低入门门槛",
        "模型微调的最终效果取决于数据质量和训练策略的合理性",
        "即使不懂代码，也能通过现成案例完成微调实践",
        "微调成功的关键在于合理设计数据集和调整超参数"
      ],
      "key_datapoints": [
        "模型训练使用10%的数据作为验证集",
        "学习率设置为2E-4（即0.0002）",
        "批量大小由device_batch_size=2与gradient_accumulation_steps=4共同决定，实际为8",
        "最大训练步数设定为15，总训练量为18个批次",
        "模型参数规模为8B（80亿）",
        "支持的上下文长度从4K扩展至200K",
        "微调任务创建后需等待调度执行，非立即运行",
        "部分在线平台仅提供有限的基础模型选项",
        "单次训练时间受模型大小和数据量影响，较长",
        "微调过程中可动态展示各参数变化效果"
      ],
      "topic_areas": [
        "模型微调流程",
        "长文本应用限制",
        "知识库机制",
        "超参数配置",
        "数据集格式",
        "在线平台操作",
        "代码级微调",
        "训练效率优化",
        "模型风格定制",
        "幻觉问题解决"
      ],
      "word_count": 9,
      "total_markers": 35
    },
    "comments_summary": {},
    "created_at": "2025-11-14T11:57:19.874430",
    "model_used": "qwen-flash"
  }
}